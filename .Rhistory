mean_degree_full_target <- feather::read_feather("Data/mean_degree_full_target_lyon.feather")
mean_degree_full_actual <- feather::read_feather("Data/mean_degree_full_actual_lyon.feather")
#
global_network <- globalthresholds_AOP_lyon %>%
rename("PAQ_val" = "degree") %>%
dplyr::select(-age, -threshold)
mean_degree_full <- rbind(mean_degree_full_actual, mean_degree_full_target)
comparison_data <- read_csv("Data/comparison_data_lyon.csv") %>%
distinct(Gloss, Speaker, .keep_all=T) %>%
dplyr::select(Gloss, Speaker, Targetphon, nsyl_target) %>%
rename("gloss1" = "Gloss")
global_network_split <- global_network %>%
pivot_wider(names_from = data_type, values_from = PAQ_val) %>%
rename("PAQ_target" = "target",
"PAQ_actual" = "actual")
regression_data <- mean_degree_full %>% left_join(global_network_split) %>%
group_by(Speaker, gloss1, data_type) %>%
mutate(learned_next = ifelse(age == AOP-1, 1, 0)) %>%
filter(age != AOP) %>%
left_join(comparison_data) %>%
left_join(vocabsize_lyon) %>%
ungroup() %>%
mutate(AOP_scaled = c(scale(AOP, center = TRUE, scale = TRUE)),
length_scaled = c(scale(Targetphon, center = TRUE, scale = TRUE)),
PAT_weighted = PAT_val/vocab_agg,
PAQ_weighted = PAQ_target/vocab_agg) %>%
group_by(Speaker) %>%
mutate(PAT_scaled = c(scale(PAT_val, center = TRUE, scale = TRUE)),
PAT_scaled_m = c(scale(PAT_val_m, center = TRUE, scale = TRUE)),
PAT_vocab_scaled = c(scale(PAT_weighted, center = TRUE, scale = TRUE)),
PAQ_vocab_scaled = c(scale(PAQ_weighted, center = T, scale = T)),
PAQ_scaled_target = c(scale(PAQ_target, center = TRUE, scale = TRUE)),
PAQ_scaled_actual = c(scale(PAQ_actual, center = TRUE, scale = TRUE)))
session_data <- read_csv("Data/comparison_data_lyon.csv") %>%    # need to add ordinal session numbers for GAMMs
group_by(Speaker, age) %>%
tally() %>%
filter(n > 1) %>%
dplyr::select(Speaker, age) %>%
group_by(Speaker, age) %>%
tally() %>%
mutate(session_ordinal = row_number()) %>%
dplyr::select(-n)
freq_lyon <- read_csv("Data/freq_lyon.csv") %>%
mutate(Speaker = ifelse(Speaker == "Theotime", "Tim", Speaker))
word_cat <- feather::read_feather("Data/FULLsample_Lyon.feather") %>%
distinct(Gloss, .keep_all = T) %>%
dplyr::select(Gloss, category) %>%
rename("gloss1" = "Gloss") %>%
mutate(category = as.factor(category),
category = fct_collapse(category,
object_word = c("animals", "body_parts", "clothing", "food_drink", "furniture_rooms",
"household", "people", "outside", "places", "toys", "vehicles"),
verbs = c("action_words", "helping_verbs")))
FULLsample_var <- feather::read_feather("Data/FULLsample_Lyon.feather") %>%
group_by(Speaker, Gloss) %>%
tally() %>%
# left_join(word_cat) %>%
rename("gloss1" = "Gloss",
"n_tokens" = "n")   # how many tokens of each word included in the data
regression_data <- regression_data %>%
left_join(freq_lyon) %>%
left_join(word_cat) %>%
left_join(FULLsample_var) %>%
left_join(session_data) %>%
mutate(total_freq = ifelse(is.na(total_freq), 0, total_freq)) %>%
mutate(freq_scaled = c(scale(total_freq, center = TRUE, scale = TRUE)),
vocab_scaled = c(scale(vocab_agg, center = TRUE, scale = TRUE)),
tokens_scaled = c(scale(n_tokens, center = TRUE, scale = TRUE))) %>%
mutate(corpus = "French",
age_scaled = c(scale(age, center = T, scale = T)),
category = as.factor(category),
data_type = as.factor(data_type),
Speaker = as.factor(Speaker),
corpus = as.factor(corpus))
regression_data$category = relevel(regression_data$category, ref="object_word")
feather::write_feather(regression_data, "Data/regression_data_lyon.feather")
globalthresholds_AOP_lyon <- feather::read_feather("Data/globalthresholds_AOP_lyon.feather") %>%
filter(threshold == 0.25)
globalthresholds_AOP_providence <- feather::read_feather("Data/globalthresholds_AOP_providence.feather") %>%
filter(threshold == 0.25) %>%
mutate(corpus = "English")  ## added to prep data, re-run and then remove in final script (don't remove threshold filter)
globalthresholds_AOP <- rbind(globalthresholds_AOP_lyon, globalthresholds_AOP_providence)
feather::write_feather(globalthresholds_AOP, "Data/repofiles/globalthresholds_AOP.feather")
full_lyon <- feather::read_feather("Data/globalthresholds_AOP_lyon.feather") %>%
filter(threshold == .99)
full_providence <- feather::read_feather("Data/globalthresholds_AOP_providence.feather") %>%
filter(threshold == .99)
full_thresholds <- rbind(full_lyon, full_providence)
feather::write_feather(full_thresholds, "Data/repofiles/full_thresholds.feather")
globalthresholds_AOP_lyon <- feather::read_feather("Data/globalthresholds_AOP_lyon.feather") %>%
filter(threshold == 0.25)
globalthresholds_AOP_providence <- feather::read_feather("Data/globalthresholds_AOP_providence.feather") %>%
filter(threshold == 0.25) %>%
mutate(corpus = "English")  ## added to prep data, re-run and then remove in final script (don't remove threshold filter)
globalthresholds_AOP <- rbind(globalthresholds_AOP_lyon, globalthresholds_AOP_providence)
feather::write_feather(globalthresholds_AOP, "Data/repofiles/globalthresholds_AOP.feather")
full_lyon <- feather::read_feather("Data/globalthresholds_AOP_lyon.feather") %>%
filter(threshold == .99)
full_providence <- feather::read_feather("Data/globalthresholds_AOP_providence.feather") %>%
filter(threshold == .99)
full_thresholds <- rbind(full_lyon, full_providence)
feather::write_feather(full_thresholds, "Data/repofiles/full_thresholds.feather")
globaldistance_Providence_actual <- feather::read_feather("Data/globaldistance_Providence.feather") %>% filter(data_type == "actual")
# install.packages("stringi")
# install.packages("ggplot2")
# install.packages("stringr")
# install.packages("tibble")
# install.packages("ggpubr")
# install.packages("lmerTest")
# install.packages("papaja")
# install.packages("tidyverse")
# install.packages("dplyr")
# install.packages("tibble")
# install.packages("afex")
# install.packages("citr")
# install.packages("glmmTMB")
# install.packages("janitor")
#install.packages("linguisticsdown")
#install.packages("ggraph")
#install.packages("wesanderson")
# install.packages("effects")
# install.packages("reshape2")
library(tidyverse)
library(stringi)
library(stringr)
library(ggplot2)
library(tibble)
library(lmerTest)
library(papaja)
library(tidyverse)
library(dplyr)
#library(citr)
library(feather)
library(ggthemes)
#library(effects)
library(nlme)
library(glmmTMB)
library(broom)
library(kableExtra)
library(knitr)
library(interactions)
library(janitor)
library(ggraph)
library(data.table)
library(linguisticsdown)
library(ggridges)
library(wesanderson)
library(igraph)
library(reshape2)
library(tidyr)
options("encoding" = "UTF-8")
globaldistance_Providence_actual <- feather::read_feather("Data/globaldistance_Providence.feather") %>% filter(data_type == "actual")
View(globaldistance_Providence_actual)
globaldistance_lyon_actual <- feather::read_feather("Data/globaldistance_Lyon.feather") %>%
filter(data_type == "actual")
View(globaldistance_lyon_actual)
View(globaldistance_Providence_actual)
# Updated 26th May 2023
source("0_prelims.R")
options("encoding" = "UTF-8")
kLogFileName <- "parser.log"
log <- function(msg="") {
con <- file(kLogFileName, "a")
tryCatch({
cat(iconv(msg, to="UTF-8"), file=con, sep="\n")
},
finally = {
close(con)
})
}
sample_Nathan <- read_csv("Data/Phon_outputs/Report_Nathan.csv")
sample_Nathan <- read_csv("Data/Phon_outputs/Report_Nathan.csv")
sample_Theotime <- read_csv("Data/Phon_outputs/Report_Theotime.csv")
sample_Marie <- read_csv("Data/Phon_outputs/Report_Marie.csv")
sample_Anais1 <- read_csv("Data/Phon_outputs/Report_Anais_1.csv") %>% mutate(`Exact Match` = NA) # add extra column that was missing from Phon report; re-run report later!
sample_Anais2 <- read_csv("Data/Phon_outputs/Report_Anais_2.csv")
sample_Anais3 <- read_csv("Data/Phon_outputs/Report_Anais_3.csv")
remove.list <- paste(c(            # Create a list of tokens to remove from the dataset, which is called using grepl further down
'@l',       # remove all tokens of alphabetic letters - these all have very similar prosodic structures
'@wp',      # remove word play tokens since these don't have a real target form (n=241). I am keeping onomatopoeia and child words, however
'&',        # remove all interjections & hesitations (n=90)
'@b',       # remove babytalk words that don't have a clear adult target
"@si",      # remove singing
"@i",       # remove interjections
'@c'),       # not sure what @c refers to but remove these as well as they are made-up forms
collapse = '|')
FULLsample_Lyon <- rbind(sample_Nathan,
sample_Theotime,
sample_Marie,
sample_Anais1,
sample_Anais2,
sample_Anais3) %>%
dplyr::select(Speaker,
Age,
Session,
Orthography,
`IPA Target`,
`IPA Actual`,
`Exact Match`,
`IPA Target CV`,
`IPA Actual CV`,
`CV Match`,
`IPA Target Syllable Count`,
`IPA Actual Syllable Count`,
`Syllable Count Match`) %>%
rename(
"IPAtarget" = `IPA Target`,
"IPAactual" = `IPA Actual`,
"IPAmatch" = `Exact Match`,
"TargetCV" = `IPA Target CV`,
"ActualCV" = `IPA Actual CV`,
"CVmatch" = `CV Match`,
"Targetphon" = `IPA Target Syllable Count`,
"Actualphon" = `IPA Actual Syllable Count`,
"Sylmatch" = `Syllable Count Match`,
"Gloss" = "Orthography"
) %>%
filter(Gloss != "xxx" &
Gloss != "xxx:" &
Gloss != "yyy" &
Gloss != "(.)" &
IPAtarget != "*" &
IPAactual != "*" &
IPAactual != "(.)" &
Speaker %in% c("Anais", "Marie", "Nathan", "Tim")) %>%
mutate(Gloss = factor(Gloss),
TargetCV = factor(TargetCV),
ActualCV = factor(ActualCV)) %>%
tibble::rowid_to_column("ID") %>%
filter(Gloss != "(..)" & Gloss != "(...)") %>%
filter(!grepl(remove.list, Gloss))
FULLsample_Lyon$Gloss <- gsub('[<>]', '', FULLsample_Lyon$Gloss)
FULLsample_Lyon$Gloss <- gsub('@o', '', FULLsample_Lyon$Gloss)
FULLsample_Lyon$IPAtarget <- gsub('*', '', FULLsample_Lyon$IPAtarget)
ws_fr <- read_csv("additional_files/french_CDI.csv") %>% dplyr::select(item_definition, category, Gloss) %>%
rename("gloss1" = "Gloss",
"Gloss" = "item_definition")
FULLsample_Lyon_all <- FULLsample_Lyon
View(FULLsample_Lyon_all)
FULLsample_Lyon <- FULLsample_Lyon %>% left_join(ws_fr, by = "Gloss") %>%
filter(!is.na(gloss1)) %>%
dplyr::select(-Gloss) %>%
rename("Gloss" = "gloss1")
FULLsample_Lyon_all <- FULLsample_Lyon %>% group_by(Speaker, Gloss) %>% tally()
FULLsample_Lyon <- FULLsample_Lyon %>% left_join(ws_fr, by = "Gloss") %>%
filter(!is.na(gloss1)) %>%
dplyr::select(-Gloss) %>%
rename("Gloss" = "gloss1")
FULLsample_Lyon_CDI <- FULLsample_Lyon %>% group_by(Speaker, Gloss) %>% tally()
FULLsample_Lyon <- FULLsample_Lyon %>% left_join(ws_fr, by = "Gloss") %>%
filter(!is.na(gloss1)) %>%
dplyr::select(-Gloss) %>%
rename("Gloss" = "gloss1")
FULLsample_Lyon_CDI <- FULLsample_Lyon %>% group_by(Speaker, Gloss) %>% tally()
View(FULLsample_Lyon_CDI)
View(FULLsample_Lyon_all)
FULLsample_Lyon <- rbind(sample_Nathan,
sample_Theotime,
sample_Marie,
sample_Anais1,
sample_Anais2,
sample_Anais3) %>%
dplyr::select(Speaker,
Age,
Session,
Orthography,
`IPA Target`,
`IPA Actual`,
`Exact Match`,
`IPA Target CV`,
`IPA Actual CV`,
`CV Match`,
`IPA Target Syllable Count`,
`IPA Actual Syllable Count`,
`Syllable Count Match`) %>%
rename(
"IPAtarget" = `IPA Target`,
"IPAactual" = `IPA Actual`,
"IPAmatch" = `Exact Match`,
"TargetCV" = `IPA Target CV`,
"ActualCV" = `IPA Actual CV`,
"CVmatch" = `CV Match`,
"Targetphon" = `IPA Target Syllable Count`,
"Actualphon" = `IPA Actual Syllable Count`,
"Sylmatch" = `Syllable Count Match`,
"Gloss" = "Orthography"
) %>%
filter(Gloss != "xxx" &
Gloss != "xxx:" &
Gloss != "yyy" &
Gloss != "(.)" &
IPAtarget != "*" &
IPAactual != "*" &
IPAactual != "(.)" &
Speaker %in% c("Anais", "Marie", "Nathan", "Tim")) %>%
mutate(Gloss = factor(Gloss),
TargetCV = factor(TargetCV),
ActualCV = factor(ActualCV)) %>%
tibble::rowid_to_column("ID") %>%
filter(Gloss != "(..)" & Gloss != "(...)") %>%
filter(!grepl(remove.list, Gloss))
FULLsample_Lyon$Gloss <- gsub('[<>]', '', FULLsample_Lyon$Gloss)
FULLsample_Lyon$Gloss <- gsub('@o', '', FULLsample_Lyon$Gloss)
FULLsample_Lyon$IPAtarget <- gsub('*', '', FULLsample_Lyon$IPAtarget)
ws_fr <- read_csv("additional_files/french_CDI.csv") %>% dplyr::select(item_definition, category, Gloss) %>%
rename("gloss1" = "Gloss",
"Gloss" = "item_definition")
View(FULLsample_Lyon)
FULLsample_Lyon_all <- FULLsample_Lyon %>% group_by(Speaker, Gloss) %>% tally()
FULLsample_Lyon <- FULLsample_Lyon %>% left_join(ws_fr, by = "Gloss") %>%
filter(!is.na(gloss1)) %>%
dplyr::select(-Gloss) %>%
rename("Gloss" = "gloss1")
FULLsample_Lyon_CDI <- FULLsample_Lyon %>% group_by(Speaker, Gloss) %>% tally()
feather::write_feather(FULLsample_Lyon, "Data/FULLsample_Lyon.feather")
feather::write_feather(FULLsample_Lyon_all, "Data/FULLsample_Lyon_all.feather")
lexicon <- read_csv("additional_files/english_CDI.csv") %>%
rename("Gloss" = "word") %>%
distinct(Gloss, .keep_all = TRUE)
options("encoding" = "UTF-8")
kLogFileName <- "parser.log"
log <- function(msg="") {
con <- file(kLogFileName, "a")
tryCatch({
cat(iconv(msg, to="UTF-8"), file=con, sep="\n")
},
finally = {
close(con)
})
}
sample_Alex <- read_csv("Data/Phon_outputs/Report_Alex.csv")
sample_Lily <- read_csv("Data/Phon_outputs/Report_Lily.csv")
sample_Violet <- read_csv("Data/Phon_outputs/Report_Violet.csv")
sample_William <- read_csv("Data/Phon_outputs/Report_William.csv")
sample_Naima18 <- read_csv("Data/Phon_outputs/Report_Naima18.csv") # Naima's data was too big to import in one go, so it is separated into 6 files (!)
sample_Naima24 <- read_csv("Data/Phon_outputs/Report_Naima24.csv") %>% dplyr::select(-`IPA Target Stress`, -`IPA Actual Stress`, -`Stress Match`)
sample_Naima27 <- read_csv("Data/Phon_outputs/Report_Naima27.csv")
sample_Naima30 <- read_csv("Data/Phon_outputs/Report_Naima30.csv")
remove.list <- paste(c(            # Create a list of tokens to remove from the dataset, which is called using grepl further down
'@l',       # remove all tokens of alphabetic letters - these all have very similr prosodic structures (n=1492)
'@wp',      # remove word play tokens since these don't have a real target form (n=241). I am keeping onomatopoeia and child words, however
'&',        # remove all interjections & hesitations (n=1384)
'@b',       # remove babytalk words that don't have a clear adult target
'@c',       # not sure what @c refers to but remove these as well as they are made-up forms
'r',
'S',
"A", "B", "C", "D", "E", "F", "G", "H", "J", "K", "L", "M", "N", "O", "P", "Q", "R", "S", "T", "U", "V", "W", "X", "Y", "Z"), # these tokens are alphabetic letters but haven't been coded as @l
collapse = '|')
FULLsample <- rbind(sample_Alex,
sample_Lily,
sample_Violet,
sample_William,
sample_Naima18,
sample_Naima24,
sample_Naima27,
sample_Naima30) %>%
dplyr::select(Speaker,
Age,
Session,
Orthography,
`IPA Target`,
`IPA Actual`,
`Exact Match`,
`IPA Target CV`,
`IPA Actual CV`,
`CV Match`,
`IPA Target Syllable Count`,
`IPA Actual Syllable Count`,
`Syllable Count Match`) %>%
rename(
"IPAtarget" = `IPA Target`,
"IPAactual" = `IPA Actual`,
"IPAmatch" = `Exact Match`,
"TargetCV" = `IPA Target CV`,
"ActualCV" = `IPA Actual CV`,
"CVmatch" = `CV Match`,
"Targetphon" = `IPA Target Syllable Count`,
"Actualphon" = `IPA Actual Syllable Count`,
"Sylmatch" = `Syllable Count Match`,
"Gloss" = "Orthography"
) %>%
filter(Gloss != "xxx" &
Gloss != "xxx:" &
Gloss != "yyy" &
Gloss != "(.)" &
IPAtarget != "*" &
IPAactual != "*" &
IPAactual != "(.)") %>%
mutate(Gloss = factor(Gloss),
TargetCV = factor(TargetCV),
ActualCV = factor(ActualCV)) %>%
tibble::rowid_to_column("ID") %>%
filter(!grepl(remove.list, Gloss))
FULLsample$Gloss <- gsub("(@).*", "\\1", FULLsample$Gloss)
FULLsample$Gloss <- str_replace_all(FULLsample$Gloss, "[^[:alnum:]]", "")
FULLsample_Providence_all <- FULLsample %>% group_by(Speaker, Gloss) %>% tally()
FULLsample <- FULLsample %>% left_join(lexicon, by = "Gloss") %>%
filter(inCDI == TRUE) %>%
dplyr::select(-Gloss) %>%
rename("Gloss" = "gloss1")
FULLsample_Providence_CDI <- FULLsample %>% group_by(Speaker, Gloss) %>% tally()
feather::write_csv(FULLsample_Providence_all, "Data/FULLsample_Providence_all.csv")
write_csv(FULLsample_Providence_all, "Data/FULLsample_Providence_all.csv")
options("encoding" = "UTF-8")
kLogFileName <- "parser.log"
log <- function(msg="") {
con <- file(kLogFileName, "a")
tryCatch({
cat(iconv(msg, to="UTF-8"), file=con, sep="\n")
},
finally = {
close(con)
})
}
# In Phon: Specialized > WordMatch
#  Untick: Stress pattern, Include length diacritics, Include stress markers
#  Tick: Exact match, Syllable count, Ignore diacritics, Include syllable boundaries
# Data is imported as Excel file; before importing into R, go through each file and save as a .csv
# then open each file individually in Excel and go through the following processes to make the data readable in this script:
# (this doesn't work in R as far as I can tell)
# - stress markersˈˌ
# - length marker ː
# - nasalized vowels ̃
# - syllabic consonants ̩
# - aspiration ʰ (be sure to match case)
# - rhoticity ˞
# - Not sure:
# - dark /l/: ɫ
# - Also replaced IPA /g/ with keyboard <g> as it wasn't reading for some reason
# - and r with <r> as also wasn't reading
# # I started by manually removing diacritics from the .csv file - all syllabic markers, length markers and aspiration. I also removed any glottal stops that were in
# # consonant clusters. The code will then run properly as it can read all other IPA symbols.
# Finally, aggregate into one large file:
sample_Nathan <- read_csv("Data/Phon_outputs/Report_Nathan.csv")
sample_Theotime <- read_csv("Data/Phon_outputs/Report_Theotime.csv")
sample_Marie <- read_csv("Data/Phon_outputs/Report_Marie.csv")
sample_Anais1 <- read_csv("Data/Phon_outputs/Report_Anais_1.csv") %>% mutate(`Exact Match` = NA) # add extra column that was missing from Phon report; re-run report later!
sample_Anais2 <- read_csv("Data/Phon_outputs/Report_Anais_2.csv")
sample_Anais3 <- read_csv("Data/Phon_outputs/Report_Anais_3.csv")
remove.list <- paste(c(            # Create a list of tokens to remove from the dataset, which is called using grepl further down
'@l',       # remove all tokens of alphabetic letters - these all have very similar prosodic structures
'@wp',      # remove word play tokens since these don't have a real target form (n=241). I am keeping onomatopoeia and child words, however
'&',        # remove all interjections & hesitations (n=90)
'@b',       # remove babytalk words that don't have a clear adult target
"@si",      # remove singing
"@i",       # remove interjections
'@c'),       # not sure what @c refers to but remove these as well as they are made-up forms
collapse = '|')
FULLsample_Lyon <- rbind(sample_Nathan,
sample_Theotime,
sample_Marie,
sample_Anais1,
sample_Anais2,
sample_Anais3) %>%
dplyr::select(Speaker,
Age,
Session,
Orthography,
`IPA Target`,
`IPA Actual`,
`Exact Match`,
`IPA Target CV`,
`IPA Actual CV`,
`CV Match`,
`IPA Target Syllable Count`,
`IPA Actual Syllable Count`,
`Syllable Count Match`) %>%
rename(
"IPAtarget" = `IPA Target`,
"IPAactual" = `IPA Actual`,
"IPAmatch" = `Exact Match`,
"TargetCV" = `IPA Target CV`,
"ActualCV" = `IPA Actual CV`,
"CVmatch" = `CV Match`,
"Targetphon" = `IPA Target Syllable Count`,
"Actualphon" = `IPA Actual Syllable Count`,
"Sylmatch" = `Syllable Count Match`,
"Gloss" = "Orthography"
) %>%
filter(Gloss != "xxx" &
Gloss != "xxx:" &
Gloss != "yyy" &
Gloss != "(.)" &
IPAtarget != "*" &
IPAactual != "*" &
IPAactual != "(.)" &
Speaker %in% c("Anais", "Marie", "Nathan", "Tim")) %>%
mutate(Gloss = factor(Gloss),
TargetCV = factor(TargetCV),
ActualCV = factor(ActualCV)) %>%
tibble::rowid_to_column("ID") %>%
filter(Gloss != "(..)" & Gloss != "(...)") %>%
filter(!grepl(remove.list, Gloss))
FULLsample_Lyon$Gloss <- gsub('[<>]', '', FULLsample_Lyon$Gloss)
FULLsample_Lyon$Gloss <- gsub('@o', '', FULLsample_Lyon$Gloss)
FULLsample_Lyon$IPAtarget <- gsub('*', '', FULLsample_Lyon$IPAtarget)
## read in CDI data. Note that this was imported in raw form from http://wordbank.stanford.edu/.
# For the French data, all word types in Fullsample_Lyon$Gloss were translated, first using a script in Google translate, and then checked by the researcher, with any errors or missing datapoints manually translated
# The list of word types was then coded for its 'basic level' form (e.g. "wouf wouf wouf" was coded as "wouf" to match the CDI form)
# Anything not related to a CDI word was coded as blank
# this was then saved as its own document so that the CDI and the type as produced in the corpus are kept in one separate document
ws_fr <- read_csv("additional_files/french_CDI.csv") %>% dplyr::select(item_definition, category, Gloss) %>%
rename("gloss1" = "Gloss",
"Gloss" = "item_definition")
FULLsample_Lyon_all <- FULLsample_Lyon %>% group_by(Speaker, Gloss) %>% tally()
FULLsample_Lyon <- FULLsample_Lyon %>% left_join(ws_fr, by = "Gloss") %>%
filter(!is.na(gloss1)) %>%
dplyr::select(-Gloss) %>%
rename("Gloss" = "gloss1")
FULLsample_Lyon_CDI <- FULLsample_Lyon %>% group_by(Speaker, Gloss) %>% tally()
feather::write_feather(FULLsample_Lyon, "Data/FULLsample_Lyon.feather")
write_csv(FULLsample_Lyon_all, "Data/FULLsample_Lyon_all.csv")
