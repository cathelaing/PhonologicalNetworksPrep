tokens_scaled*AOP_scaled +
(1|Speaker)',
'Combined', 'Individual'))
coefs_agg_all_LN <- bind_rows(coef_agg_target_LN, coef_agg_actual_LN)
}
plot_agg <- ggplot(coefs_agg_all, aes(x = predictor, y = Estimate)) +
geom_pointrange(aes(ymin = X2.5.., ymax = X97.5.., y = Estimate, col = predictor),
position = position_dodge(width = .9),
size = 2,
fatten = 2) +
geom_hline(yintercept = 0, color = "grey", linetype = "dashed", size = 1)+
facet_wrap(~measure)  +
scale_x_discrete(labels = c('Freq','Length','PAQ', 'PAT')) +
coord_flip() +
guides(colour=FALSE) +
scale_colour_solarized() +
theme_bw(base_size = 18) +
theme(aspect.ratio = 0.7,
text = element_text(size=30))
plot_agg <- ggplot(coefs_agg_all, aes(x = predictor, y = Estimate)) +
geom_pointrange(aes(ymin = X2.5.., ymax = X97.5.., y = Estimate, col = predictor),
position = position_dodge(width = .9),
linewidth = 2,
fatten = 2) +
geom_hline(yintercept = 0, color = "grey", linetype = "dashed", size = 1)+
facet_wrap(~measure)  +
scale_x_discrete(labels = c('Freq','Length','PAQ', 'PAT')) +
coord_flip() +
guides(colour=FALSE) +
scale_colour_solarized() +
theme_bw(base_size = 18) +
theme(aspect.ratio = 0.7,
text = element_text(size=30))
plot_agg
coefs_agg_all
pat_formula_LN <- as.formula("learned_next ~ PAT_scaled + (1|Speaker)")
paq_formula_LN <- as.formula("learned_next ~ PAQ_scaled_target + (1|Speaker)")
all_formula_LN <- as.formula("learned_next ~
PAT_scaled*AOP_scaled +
PAQ_scaled_target*AOP_scaled +
#length_scaled*AOP_scaled +
freq_scaled*AOP_scaled +
vocab_scaled*AOP_scaled +
tokens_scaled*AOP_scaled +
(1|Speaker)")
formulas <- list(pat_formula_LN,  paq_formula_LN, all_formula_LN)
coefs_agg_all_LN <- data.frame()
for (formula in formulas){
reg_agg_target_LN <- glmer(formula, data=subset(regression_data, data_type == "target"
#& corpus == "English"
), family = binomial())
reg_agg_actual_LN <- glmer(formula,  data=subset(regression_data, data_type == "actual"
# & corpus == "English"
), family = binomial())
#Extract coeficnet and confidence intervals
coef_agg_fun <- function (model, meas_name) {
conf <- confint(model, method ="Wald")
conf <- data.frame(predictor = row.names(conf), conf) %>%
dplyr::filter(!(predictor %in% c('.sig01', '.sigma', '(Intercept)')))
coef <- coef(summary(model))
data.frame(predictor = row.names(coef), coef) %>%
dplyr::filter(predictor !='(Intercept)') %>%
left_join(conf) %>%
mutate(measure = meas_name)
}
coef_agg_target_LN <- coef_agg_fun(reg_agg_target_LN, 'target')
coef_agg_actual_LN <- coef_agg_fun(reg_agg_actual_LN, 'actual')
coef_agg_form_LN <- coef_agg_target_LN %>%
bind_rows(coef_agg_actual_LN) %>%
mutate(Test = ifelse(toString(formula[3])=='
PAT_scaled*AOP_scaled +
PAQ_scaled_target*AOP_scaled +
#length_scaled*AOP_scaled +
freq_scaled*AOP_scaled +
vocab_scaled*AOP_scaled +
tokens_scaled*AOP_scaled +
(1|Speaker)',
'Combined', 'Individual'))
coefs_agg_all_LN <- bind_rows(coef_agg_target_LN, coef_agg_actual_LN)
}
plot_agg <- ggplot(coefs_agg_all, aes(x = predictor, y = Estimate)) +
geom_pointrange(aes(ymin = X2.5.., ymax = X97.5.., y = Estimate, col = predictor),
position = position_dodge(width = .9),
linewidth = 2,
fatten = 2) +
geom_hline(yintercept = 0, color = "grey", linetype = "dashed", size = 1)+
facet_wrap(~measure)  +
scale_x_discrete(labels = c('Freq','Length','PAQ', 'PAT')) +
coord_flip() +
guides(colour=FALSE) +
scale_colour_solarized() +
theme_bw(base_size = 18) +
theme(aspect.ratio = 0.7,
text = element_text(size=30))
plot_agg
plot_agg <- ggplot(coefs_agg_all_LN, aes(x = predictor, y = Estimate)) +
geom_pointrange(aes(ymin = X2.5.., ymax = X97.5.., y = Estimate, col = predictor),
position = position_dodge(width = .9),
linewidth = 2,
fatten = 2) +
geom_hline(yintercept = 0, color = "grey", linetype = "dashed", size = 1)+
facet_wrap(~measure)  +
scale_x_discrete(labels = c('Freq','Length','PAQ', 'PAT')) +
coord_flip() +
guides(colour=FALSE) +
scale_colour_solarized() +
theme_bw(base_size = 18) +
theme(aspect.ratio = 0.7,
text = element_text(size=30))
plot_agg
plot_agg <- ggplot(coefs_agg_all_LN, aes(x = predictor, y = Estimate)) +
geom_pointrange(aes(ymin = X2.5.., ymax = X97.5.., y = Estimate, col = predictor),
position = position_dodge(width = .9),
linewidth = 2,
fatten = 2)
plot_agg
plot_agg <- ggplot(coefs_agg_all_LN, aes(x = predictor, y = Estimate)) +
geom_pointrange(aes(ymin = X2.5.., ymax = X97.5.., y = Estimate, col = predictor),
position = position_dodge(width = .9),
linewidth = 2,
fatten = 2) +
geom_hline(yintercept = 0, color = "grey", linetype = "dashed", size = 1)+
facet_wrap(~measure)
plot_agg
plot_agg <- ggplot(coefs_agg_all_LN, aes(x = predictor, y = Estimate)) +
geom_pointrange(aes(ymin = X2.5.., ymax = X97.5.., y = Estimate, col = predictor),
position = position_dodge(width = .9),
linewidth = 2,
fatten = 2) +
geom_hline(yintercept = 0, color = "grey", linetype = "dashed", size = 1)+
facet_wrap(~measure)  +
#scale_x_discrete(labels = c('Freq','Length','PAQ', 'PAT')) +
coord_flip() +
guides(colour=FALSE) +
scale_colour_solarized() +
theme_bw(base_size = 18) +
theme(aspect.ratio = 0.7,
text = element_text(size=30))
plot_agg
plot_agg <- ggplot(coefs_agg_all_LN, aes(x = predictor, y = Estimate)) +
geom_pointrange(aes(ymin = X2.5.., ymax = X97.5.., y = Estimate, col = predictor),
position = position_dodge(width = .9),
linewidth = 2,
fatten = 2) +
geom_hline(yintercept = 0, color = "grey", linetype = "dashed", size = 1)+
facet_wrap(~measure)  +
#scale_x_discrete(labels = c('Freq','Length','PAQ', 'PAT')) +
coord_flip() +
#guides(colour=FALSE) +
#scale_colour_solarized() +
theme_bw(base_size = 18) +
theme(aspect.ratio = 0.7,
text = element_text(size=30))
plot_agg
plot_agg <- ggplot(coefs_agg_all_LN, aes(x = predictor, y = Estimate)) +
geom_pointrange(aes(ymin = X2.5.., ymax = X97.5.., y = Estimate, col = predictor),
position = position_dodge(width = .9),
linewidth = 2,
fatten = 2) +
geom_hline(yintercept = 0, color = "grey", linetype = "dashed", size = 1)+
facet_wrap(~measure)  +
#scale_x_discrete(labels = c('Freq','Length','PAQ', 'PAT')) +
coord_flip() +
#guides(colour=FALSE) +
#scale_colour_solarized() +
theme_bw(base_size = 18) +
theme(aspect.ratio = 0.7,
text = element_text(size=30),
legend.position = NA)
plot_agg
plot_agg <- ggplot(coefs_agg_all_LN, aes(x = predictor, y = Estimate)) +
geom_pointrange(aes(ymin = X2.5.., ymax = X97.5.., y = Estimate, col = predictor),
position = position_dodge(width = .9),
linewidth = 2,
fatten = 2) +
geom_hline(yintercept = 0, color = "grey", linetype = "dashed", size = 1)+
facet_wrap(~measure)  +
#scale_x_discrete(labels = c('Freq','Length','PAQ', 'PAT')) +
coord_flip() +
#guides(colour=FALSE) +
#scale_colour_solarized() +
theme_bw(base_size = 18) +
theme(aspect.ratio = 0.7,
text = element_text(size=30),
legend.position = "")
plot_agg
plot_agg <- ggplot(coefs_agg_all_LN, aes(x = predictor, y = Estimate)) +
geom_pointrange(aes(ymin = X2.5.., ymax = X97.5.., y = Estimate, col = predictor),
position = position_dodge(width = .9),
linewidth = 2,
fatten = 2) +
geom_hline(yintercept = 0, color = "grey", linetype = "dashed", size = 1)+
facet_wrap(~measure)  +
scale_x_discrete(labels = c('Vocab','n Tokens','PAT*Age', 'PAT', "PAQ", "Freq", "Age*Vocab", "Age*Tokens", "Age*PAQ", "Age*Freq", "Age")) +
coord_flip() +
#guides(colour=FALSE) +
#scale_colour_solarized() +
theme_bw(base_size = 18) +
theme(aspect.ratio = 0.7,
text = element_text(size=30),
legend.position = "")
plot_agg
regression_data_1 <- regression_data %>% filter(learned_next == 1)
pat_formula_AOP <- as.formula("AOP_scaled ~ PAT_scaled + (1|Speaker)")
paq_formula_AOP <- as.formula("AOP_scaled ~ PAQ_scaled_target + (1|Speaker)")
all_formula_AOP <- as.formula("AOP_scaled ~ PAT_scaled + PAQ_scaled_target + length_scaled + freq_scaled + vocab_scaled + tokens_scaled +
length_scaled:PAT_scaled + length_scaled:PAQ_scaled_target + vocab_scaled:PAT_scaled + vocab_scaled:PAQ_scaled_target +
freq_scaled:PAT_scaled + freq_scaled:PAQ_scaled_target + tokens_scaled:PAT_scaled + tokens_scaled:PAQ_scaled_target +
(1|Speaker)")
formulas <- list(pat_formula_AOP,  paq_formula_AOP, all_formula_AOP)
coefs_agg_all <- data.frame()
for (formula in formulas){
reg_agg_target_AOP <- lmer(formula, data=subset(regression_data, data_type == "target"))
reg_agg_actual_AOP <- lmer(formula,  data=subset(regression_data, data_type == "actual"))
#Extract coeficnet and confidence intervals
coef_agg_fun <- function (model, meas_name) {
conf <- confint(model, method ="Wald")
conf <- data.frame(predictor = row.names(conf), conf) %>%
dplyr::filter(!(predictor %in% c('.sig01', '.sigma', '(Intercept)')))
coef <- coef(summary(model))
data.frame(predictor = row.names(coef), coef) %>%
dplyr::filter(predictor !='(Intercept)') %>%
left_join(conf) %>%
mutate(measure = meas_name)
}
coef_agg_target_AOP <- coef_agg_fun(reg_agg_target_AOP, 'target')
coef_agg_actual_AOP <- coef_agg_fun(reg_agg_actual_AOP, 'actual')
coef_agg_form_AOP <- coef_agg_target_AOP %>%
bind_rows(coef_agg_actual_AOP) %>%
mutate(Test = ifelse(toString(formula[3])=='PAT_scaled + PAQ_scaled_target + length_scaled + freq_scaled + vocab_scaled + tokens_scaled +
length_scaled:PAT_scaled + length_scaled:PAQ_scaled_target + vocab_scaled:PAT_scaled + vocab_scaled:PAQ_scaled_target +
freq_scaled:PAT_scaled + freq_scaled:PAQ_scaled_target + tokens_scaled:PAT_scaled + tokens_scaled:PAQ_scaled_target +
(1|Speaker)', 'Combined', 'Individual'))
coefs_agg_all_AOP <- bind_rows(coef_agg_target_AOP, coef_agg_actual_AOP)
}
plot_agg <- ggplot(coefs_agg_all_AOP, aes(x = predictor, y = Estimate)) +
geom_pointrange(aes(ymin = X2.5.., ymax = X97.5.., y = Estimate, col = predictor),
position = position_dodge(width = .9),
linewidth = 2,
fatten = 2) +
geom_hline(yintercept = 0, color = "grey", linetype = "dashed", size = 1)+
facet_wrap(~measure)  +
scale_x_discrete(labels = c('Vocab','n Tokens','PAT*Age', 'PAT', "PAQ", "Freq", "Age*Vocab", "Age*Tokens", "Age*PAQ", "Age*Freq", "Age")) +
coord_flip() +
#guides(colour=FALSE) +
#scale_colour_solarized() +
theme_bw(base_size = 18) +
theme(aspect.ratio = 0.7,
text = element_text(size=30),
legend.position = "")
plot_agg <- ggplot(coefs_agg_all_AOP, aes(x = predictor, y = Estimate)) +
geom_pointrange(aes(ymin = X2.5.., ymax = X97.5.., y = Estimate, col = predictor),
position = position_dodge(width = .9),
linewidth = 2,
fatten = 2) +
geom_hline(yintercept = 0, color = "grey", linetype = "dashed", size = 1)+
facet_wrap(~measure)  +
#  scale_x_discrete(labels = c('Vocab','n Tokens','PAT*Age', 'PAT', "PAQ", "Freq", "Age*Vocab", "Age*Tokens", "Age*PAQ", "Age*Freq", "Age")) +
coord_flip() +
#guides(colour=FALSE) +
#scale_colour_solarized() +
theme_bw(base_size = 18) +
theme(aspect.ratio = 0.7,
text = element_text(size=30),
legend.position = "")
plot_agg
globalthresholds_AOP_lyon <- feather::read_feather("Data/globalthresholds_AOP_lyon.feather") %>%
filter(threshold == 0.25)
source("prelims.R")
source("0_prelims.R")
globalthresholds_AOP_lyon <- feather::read_feather("Data/globalthresholds_AOP_lyon.feather") %>%
filter(threshold == 0.25)
View(globalthresholds_AOP_lyon)
globalthresholds_AOP_providence <- feather::read_feather("Data/globalthresholds_AOP_providence.feather") %>%
filter(threshold == 0.25) %>%
mutate(corpus = "English")  ## added to prep data, re-run and then remove in final script (don't remove threshold filter)
globalthresholds_AOP <- rbind(globalthresholds_AOP_lyon, globalthresholds_AOP_providence)
full_lyon <- feather::read_feather("Data/globalthresholds_AOP_lyon.feather") %>%
filter(threshold == .99)
full_providence <- feather::read_feather("Data/globalthresholds_AOP_providence.feather") %>%
filter(threshold == .99)
full_thresholds <- rbind(full_lyon, full_providence)
regression_data_lyon <- feather::read_feather("Data/regression_data_lyon.feather")
regression_data_providence <- feather::read_feather("Data/regression_data_providence.feather")
regression_data <- rbind(regression_data_lyon, regression_data_providence)
regression_data$category = relevel(regression_data$category, ref="object_word")
comparison_data_P <- read_csv("Data/comparison_data_providence.csv")
comparison_data_L <- read_csv("Data/comparison_data_lyon.csv")
comparison_data <- rbind(comparison_data_P, comparison_data_L)
feather::write_feather(globalthresholds_AOP, "Data/repofiles/globalthresholds_AOP")
feather::write_feather(full_thresholds, "Data/repofiles/full_thresholds")
feather::write_feather(regression_data, "Data/repofiles/regression_data")
write_csv(comparison_data, "Data/repofiles/comparison_data")
feather::write_feather(globalthresholds_AOP, "Data/repofiles/globalthresholds_AOP.feather")
feather::write_feather(full_thresholds, "Data/repofiles/full_thresholds.feather")
feather::write_feather(regression_data, "Data/repofiles/regression_data.feather")
write_csv(comparison_data, "Data/repofiles/comparison_data.csv")
write_feather(comparison_data, "Data/repofiles/comparison_data.feather")
feather::write_feather(regression_data, "Data/regression_data_lyon.feather")
global_distance_providence <- feather::read_feather("Data/globaldistance_Providence.feather")
# global_distance_providence %>%
#   filter(Speaker == "Violet" & (gloss1 == "medicine" | gloss2 == "medicine")) %>%
#   group_by(age) %>% tally()
globalthresholds_providence <- feather::read_feather("Data/globalthresholds_providence.feather")
# globalthresholds_providence %>%
#   filter(Speaker == "Violet" & gloss1 == "medicine") %>%
#   group_by(age) %>% tally()
globalthresholds_AOP_providence <- feather::read_feather("Data/globalthresholds_AOP_providence.feather") %>%
filter(threshold == 0.25)
# globalthresholds_AOP_providence %>%
#   filter(Speaker == "Violet" & gloss1 == "medicine") %>%
#   group_by(age) %>% tally()
vocabsize_providence <- feather::read_feather("Data/globalthresholds_AOP_providence.feather") %>%
filter(threshold == 0.99, data_type == "target") %>%  # use 0.99 as threshold to make sure all new words are incorporated.
#filter(age == 30) %>%
group_by(Speaker, AOP) %>%
tally() %>%
rename("vocab_month" = "n") %>%
mutate(vocab_agg = cumsum(vocab_month))
# need to start with full list of all words by age, global_network$gloss1
ages <- global_distance_providence %>% filter(data_type == "target") %>% distinct(Speaker, gloss1, age)
vocabsize_sub <- vocabsize_providence %>% distinct(Speaker, AOP, vocab_month)
mean_degree_full_target <- feather::read_feather("Data/mean_degree_full_target_providence.feather")
mean_degree_full_actual <- feather::read_feather("Data/mean_degree_full_actual_providence.feather")
global_network <- globalthresholds_AOP_providence %>%
rename("PAQ_val" = "degree") %>%
dplyr::select(-age, -threshold)
mean_degree_full <- rbind(mean_degree_full_actual, mean_degree_full_target)
comparison_data <- read_csv("Data/comparison_data_providence.csv") %>%
distinct(Gloss, Speaker, .keep_all=T) %>%
dplyr::select(Gloss, Speaker, Targetphon, nsyl_target) %>%
rename("gloss1" = "Gloss")
global_network_split <- global_network %>%
pivot_wider(names_from = data_type, values_from = PAQ_val) %>%
rename("PAQ_target" = "target",
"PAQ_actual" = "actual")
regression_data <- mean_degree_full %>% left_join(global_network_split) %>%
group_by(Speaker, gloss1, data_type) %>%
mutate(learned_next = ifelse(age == AOP-1, 1, 0)) %>%
filter(age != AOP) %>%
left_join(comparison_data) %>%
left_join(vocabsize_providence) %>%
ungroup() %>%
mutate(AOP_scaled = c(scale(AOP, center = TRUE, scale = TRUE)),
length_scaled = c(scale(Targetphon, center = TRUE, scale = TRUE)),
PAT_weighted = PAT_val/vocab_agg,
PAQ_weighted = PAQ_target/vocab_agg) %>%
group_by(Speaker) %>%
mutate(PAT_scaled = c(scale(PAT_val, center = TRUE, scale = TRUE)),
PAT_scaled_m = c(scale(PAT_val_m, center = TRUE, scale = TRUE)),
PAT_vocab_scaled = c(scale(PAT_weighted, center = TRUE, scale = TRUE)),
PAQ_vocab_scaled = c(scale(PAQ_weighted, center = T, scale = T)),
PAQ_scaled_target = c(scale(PAQ_target, center = TRUE, scale = TRUE)),
PAQ_scaled_actual = c(scale(PAQ_actual, center = TRUE, scale = TRUE)))
chi_freq <- read_csv("Data/freq_providence.csv")
session_data <- read_csv("Data/comparison_data_providence.csv") %>%    # need to add ordinal session numbers for GAMMs
group_by(Speaker, age) %>%
tally() %>%
filter(n > 1) %>%
dplyr::select(Speaker, age) %>%
group_by(Speaker, age) %>%
tally() %>%
mutate(session_ordinal = row_number()) %>%
dplyr::select(-n)
word_cat <- feather::read_feather("Data/FULLsample_Providence.feather") %>%
distinct(Gloss, .keep_all = T) %>%
dplyr::select(Gloss, category) %>%
rename("gloss1" = "Gloss") %>%
mutate(category = as.factor(category),
category = fct_collapse(category,
object_word = c("animals", "body_parts", "clothing", "food_drink", "furniture_rooms",
"household", "people", "outside", "places", "toys", "vehicles"),
verbs = c("action_words", "helping_verbs")))
FULLsample_var <- feather::read_feather("Data/FULLsample_Providence.feather") %>%
group_by(Speaker, Gloss) %>%
tally() %>%
rename("gloss1" = "Gloss",
"n_tokens" = "n")   # how many tokens of each word included in the data
regression_data <- regression_data %>%
left_join(chi_freq) %>%
left_join(word_cat) %>%
left_join(FULLsample_var) %>%
left_join(session_data) %>%
mutate(total_freq = ifelse(is.na(total_freq), 0, total_freq)) %>%
mutate(freq_scaled = c(scale(total_freq, center = TRUE, scale = TRUE)),
vocab_scaled = c(scale(vocab_agg, center = TRUE, scale = TRUE)),
tokens_scaled = c(scale(n_tokens, center = TRUE, scale = TRUE))) %>%
mutate(corpus = "English",
age_scaled = c(scale(age, center = T, scale = T)),
category = as.factor(category),
data_type = as.factor(data_type),
Speaker = as.factor(Speaker),
corpus = as.factor(corpus))
regression_data$category = relevel(regression_data$category, ref="object_word")
feather::write_feather(regression_data, "Data/regression_data_providence.feather")
regression_data <- feather::read_feather("Data/regression_data_providence.feather")
# need to start with full list of all words by age, global_network$gloss1
global_distance_lyon <- feather::read_feather("Data/globaldistance_lyon.feather")
globalthresholds_lyon <- feather::read_feather("Data/globalthresholds_lyon.feather")
globalthresholds_AOP_lyon <- feather::read_feather("Data/globalthresholds_AOP_lyon.feather") %>%
filter(threshold == 0.25)
vocabsize_lyon <- feather::read_feather("Data/globalthresholds_AOP_lyon.feather") %>%
filter(threshold == 0.99, data_type == "target") %>%  # use 0.99 as threshold to make sure all new words are incorporated.
#filter(age == 30) %>%
group_by(Speaker, AOP) %>%
tally() %>%
rename("vocab_month" = "n") %>%
mutate(vocab_agg = cumsum(vocab_month))
ages <- global_distance_lyon %>% filter(data_type == "target") %>% distinct(Speaker, gloss1, age)
vocabsize_sub <- vocabsize_lyon %>% distinct(Speaker, AOP, vocab_month)
mean_degree_full_target <- feather::read_feather("Data/mean_degree_full_target_lyon.feather")
mean_degree_full_actual <- feather::read_feather("Data/mean_degree_full_actual_lyon.feather")
#
global_network <- globalthresholds_AOP_lyon %>%
rename("PAQ_val" = "degree") %>%
dplyr::select(-age, -threshold)
mean_degree_full <- rbind(mean_degree_full_actual, mean_degree_full_target)
comparison_data <- read_csv("Data/comparison_data_lyon.csv") %>%
distinct(Gloss, Speaker, .keep_all=T) %>%
dplyr::select(Gloss, Speaker, Targetphon, nsyl_target) %>%
rename("gloss1" = "Gloss")
global_network_split <- global_network %>%
pivot_wider(names_from = data_type, values_from = PAQ_val) %>%
rename("PAQ_target" = "target",
"PAQ_actual" = "actual")
regression_data <- mean_degree_full %>% left_join(global_network_split) %>%
group_by(Speaker, gloss1, data_type) %>%
mutate(learned_next = ifelse(age == AOP-1, 1, 0)) %>%
filter(age != AOP) %>%
left_join(comparison_data) %>%
left_join(vocabsize_lyon) %>%
ungroup() %>%
mutate(AOP_scaled = c(scale(AOP, center = TRUE, scale = TRUE)),
length_scaled = c(scale(Targetphon, center = TRUE, scale = TRUE)),
PAT_weighted = PAT_val/vocab_agg,
PAQ_weighted = PAQ_target/vocab_agg) %>%
group_by(Speaker) %>%
mutate(PAT_scaled = c(scale(PAT_val, center = TRUE, scale = TRUE)),
PAT_scaled_m = c(scale(PAT_val_m, center = TRUE, scale = TRUE)),
PAT_vocab_scaled = c(scale(PAT_weighted, center = TRUE, scale = TRUE)),
PAQ_vocab_scaled = c(scale(PAQ_weighted, center = T, scale = T)),
PAQ_scaled_target = c(scale(PAQ_target, center = TRUE, scale = TRUE)),
PAQ_scaled_actual = c(scale(PAQ_actual, center = TRUE, scale = TRUE)))
session_data <- read_csv("Data/comparison_data_lyon.csv") %>%    # need to add ordinal session numbers for GAMMs
group_by(Speaker, age) %>%
tally() %>%
filter(n > 1) %>%
dplyr::select(Speaker, age) %>%
group_by(Speaker, age) %>%
tally() %>%
mutate(session_ordinal = row_number()) %>%
dplyr::select(-n)
freq_lyon <- read_csv("Data/freq_lyon.csv") %>%
mutate(Speaker = ifelse(Speaker == "Theotime", "Tim", Speaker))
word_cat <- feather::read_feather("Data/FULLsample_Lyon.feather") %>%
distinct(Gloss, .keep_all = T) %>%
dplyr::select(Gloss, category) %>%
rename("gloss1" = "Gloss") %>%
mutate(category = as.factor(category),
category = fct_collapse(category,
object_word = c("animals", "body_parts", "clothing", "food_drink", "furniture_rooms",
"household", "people", "outside", "places", "toys", "vehicles"),
verbs = c("action_words", "helping_verbs")))
FULLsample_var <- feather::read_feather("Data/FULLsample_Lyon.feather") %>%
group_by(Speaker, Gloss) %>%
tally() %>%
# left_join(word_cat) %>%
rename("gloss1" = "Gloss",
"n_tokens" = "n")   # how many tokens of each word included in the data
regression_data <- regression_data %>%
left_join(freq_lyon) %>%
left_join(word_cat) %>%
left_join(FULLsample_var) %>%
left_join(session_data) %>%
mutate(total_freq = ifelse(is.na(total_freq), 0, total_freq)) %>%
mutate(freq_scaled = c(scale(total_freq, center = TRUE, scale = TRUE)),
vocab_scaled = c(scale(vocab_agg, center = TRUE, scale = TRUE)),
tokens_scaled = c(scale(n_tokens, center = TRUE, scale = TRUE))) %>%
mutate(corpus = "French",
age_scaled = c(scale(age, center = T, scale = T)),
category = as.factor(category),
data_type = as.factor(data_type),
Speaker = as.factor(Speaker),
corpus = as.factor(corpus))
regression_data$category = relevel(regression_data$category, ref="object_word")
feather::write_feather(regression_data, "Data/regression_data_lyon.feather")
globalthresholds_AOP_lyon <- feather::read_feather("Data/globalthresholds_AOP_lyon.feather") %>%
filter(threshold == 0.25)
globalthresholds_AOP_providence <- feather::read_feather("Data/globalthresholds_AOP_providence.feather") %>%
filter(threshold == 0.25) %>%
mutate(corpus = "English")  ## added to prep data, re-run and then remove in final script (don't remove threshold filter)
globalthresholds_AOP <- rbind(globalthresholds_AOP_lyon, globalthresholds_AOP_providence)
feather::write_feather(globalthresholds_AOP, "Data/repofiles/globalthresholds_AOP.feather")
full_lyon <- feather::read_feather("Data/globalthresholds_AOP_lyon.feather") %>%
filter(threshold == .99)
full_providence <- feather::read_feather("Data/globalthresholds_AOP_providence.feather") %>%
filter(threshold == .99)
full_thresholds <- rbind(full_lyon, full_providence)
feather::write_feather(full_thresholds, "Data/repofiles/full_thresholds.feather")
globalthresholds_AOP_lyon <- feather::read_feather("Data/globalthresholds_AOP_lyon.feather") %>%
filter(threshold == 0.25)
globalthresholds_AOP_providence <- feather::read_feather("Data/globalthresholds_AOP_providence.feather") %>%
filter(threshold == 0.25) %>%
mutate(corpus = "English")  ## added to prep data, re-run and then remove in final script (don't remove threshold filter)
globalthresholds_AOP <- rbind(globalthresholds_AOP_lyon, globalthresholds_AOP_providence)
feather::write_feather(globalthresholds_AOP, "Data/repofiles/globalthresholds_AOP.feather")
full_lyon <- feather::read_feather("Data/globalthresholds_AOP_lyon.feather") %>%
filter(threshold == .99)
full_providence <- feather::read_feather("Data/globalthresholds_AOP_providence.feather") %>%
filter(threshold == .99)
full_thresholds <- rbind(full_lyon, full_providence)
feather::write_feather(full_thresholds, "Data/repofiles/full_thresholds.feather")
