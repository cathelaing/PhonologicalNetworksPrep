library(papaja)
library(tidyverse)
library(dplyr)
#library(citr)
library(feather)
library(ggthemes)
#library(effects)
library(nlme)
library(glmmTMB)
library(broom)
library(kableExtra)
library(knitr)
library(interactions)
library(janitor)
library(ggraph)
library(data.table)
library(linguisticsdown)
library(ggridges)
library(wesanderson)
library(igraph)
connected_degree_actual_melted <- feather::read_feather("Data/connected_degree_actual_melted_providence.feather")
actual_global_degree <- globalthresholds_providence %>%
filter(data_type == "actual") %>%
dplyr::select(Speaker, age, gloss1, degree) %>%
mutate(age = as.numeric(age))
global_distance_providence <- feather::read_feather("Data/globaldistance_Providence.feather")
# global_distance_providence %>%
#   filter(Speaker == "Violet" & (gloss1 == "medicine" | gloss2 == "medicine")) %>%
#   group_by(age) %>% tally()
globalthresholds_providence <- feather::read_feather("Data/globalthresholds_providence.feather")
# globalthresholds_providence %>%
#   filter(Speaker == "Violet" & gloss1 == "medicine") %>%
#   group_by(age) %>% tally()
globalthresholds_AOP_providence <- feather::read_feather("Data/globalthresholds_AOP_providence.feather") %>%
filter(threshold == 0.25)
# globalthresholds_AOP_providence %>%
#   filter(Speaker == "Violet" & gloss1 == "medicine") %>%
#   group_by(age) %>% tally()
vocabsize_providence <- feather::read_feather("Data/globalthresholds_AOP_providence.feather") %>%
filter(threshold == 0.99, data_type == "target") %>%  # use 0.99 as threshold to make sure all new words are incorporated.
#filter(age == 30) %>%
group_by(Speaker, AOP) %>%
tally() %>%
rename("vocab_month" = "n") %>%
mutate(vocab_agg = cumsum(vocab_month))
# need to start with full list of all words by age, global_network$gloss1
ages <- global_distance_providence %>% filter(data_type == "target") %>% distinct(Speaker, gloss1, age)
AOP_summ_actual <- globalthresholds_AOP_providence %>%
mutate(Speaker_AOP = paste(Speaker, AOP, sep="_"),
AOP = as.numeric((AOP))) %>%
filter(data_type == "actual")
AOP_summ_target <- globalthresholds_AOP_providence %>%
mutate(Speaker_AOP = paste(Speaker, AOP, sep="_"),
AOP = as.numeric((AOP))) %>%
filter(data_type == "target")
AOP_summ <- rbind(AOP_summ_actual, AOP_summ_target) %>% distinct(Speaker, gloss1, .keep_all = T)
AOP_list <- AOP_summ %>%
split(., f = .$Speaker_AOP)
global_distance_summ <- global_distance_providence %>%
mutate(Speaker_AOP = paste(Speaker, age, sep="_"))
gloss_summ <- globalthresholds_AOP_providence %>%
filter(data_type == "actual") %>%
mutate(Speaker_gloss = paste(Speaker, gloss1, sep="_"))
gloss_list <- gloss_summ %>%        # create a list of all words connected to the speaker who produces them
split(., f = .$Speaker_gloss)
AOP_summ_red <- AOP_summ %>% dplyr::select(Speaker, gloss1, AOP)
vocabsize_sub <- vocabsize_providence %>% distinct(Speaker, AOP, vocab_month)
mean_degree_full_actual_init <- melt(known_words_degree_actual) %>%      # establish mean degree for each word at each timepoint
group_by(L1, variable) %>%
mutate(rn = row_number()) %>%
pivot_wider(names_from = variable, values_from = value) %>%
separate(L1, into = c("remove", "gloss1"), sep = "_") %>%
dplyr::select(-remove, -L2, -rn)
actual_global_degree <- globalthresholds_providence %>%
filter(data_type == "actual") %>%
dplyr::select(Speaker, age, gloss1, degree) %>%
mutate(age = as.numeric(age))
known_degree_list <- vector("list", length(gloss_list))
known_words_degree_actual <-lapply(gloss_list, FUN = function(element) {
connections <- connected_degree_actual_melted %>%
filter(Speaker_gloss == element$Speaker_gloss)
min_age <- ages %>% filter(Speaker == element$Speaker & age == min(age))
degrees <- actual_global_degree %>%
filter(gloss1 %in% connections$known_word & (age < element$AOP) & Speaker == element$Speaker) %>%
group_by(Speaker, age) %>%
summarise(PAT_val = median(degree),
PAT_val_m = mean(degree))
known_degree_list <- list(degrees)    # should be degrees
})
AOP_summ_red <- AOP_summ %>% dplyr::select(Speaker, gloss1, AOP)
vocabsize_sub <- vocabsize_providence %>% distinct(Speaker, AOP, vocab_month)
mean_degree_full_actual_init <- melt(known_words_degree_actual) %>%      # establish mean degree for each word at each timepoint
group_by(L1, variable) %>%
mutate(rn = row_number()) %>%
pivot_wider(names_from = variable, values_from = value) %>%
separate(L1, into = c("remove", "gloss1"), sep = "_") %>%
dplyr::select(-remove, -L2, -rn)
min_ages <- ages %>% group_by(Speaker) %>% summarise(min_age = min(age)) %>%    # establish minimum age for each infant in the dataset
mutate(min_age = as.numeric(min_age))
all_mean_degree_data_actual <- vector("list", length(2151))    # create an empty list for the missing datapoints
for (i in unique(mean_degree_full_actual_init$Speaker)) {
mean_degree_full_actual_missing <- mean_degree_full_actual_init %>%
filter(Speaker == i) %>%                                                         # for each speaker
group_by(gloss1) %>%                                                             # identify the words
complete(gloss1, age = (min_ages$min_age[which(min_ages$Speaker == i)]):         # that don't have an initial timepoint at
(AOP_summ$(AOP-1[which(AOP_summ$Speaker == i & AOP_summ$gloss1 == gloss1)]))) %>%           # the child's minimum age, and complete the gaps
mutate(remove = ifelse(!(age %in% AOP_summ$AOP[which(AOP_summ$Speaker == i)]), T, F)) %>%  # remove ages that don't have recordings
filter(remove != T) %>%
ungroup() %>%
mutate(PAT_val = ifelse(is.na(PAT_val), 0, PAT_val),                            # create PAT vals for these missing data points
PAT_val_m = ifelse(is.na(PAT_val_m), 0, PAT_val_m)) %>%                  # these are 0 by default as they don't connect to anything
fill(Speaker, .direction = "down") %>%                                          # fill in the Speaker info
fill(Speaker, .direction = "up")
all_mean_degree_data_actual[[i]] <- mean_degree_full_actual_missing
}
for (i in unique(mean_degree_full_actual_init$Speaker)) {
mean_degree_full_actual_missing <- mean_degree_full_actual_init %>%
filter(Speaker == i) %>%                                                         # for each speaker
group_by(gloss1) %>%                                                             # identify the words
complete(gloss1, age = (min_ages$min_age[which(min_ages$Speaker == i)]):         # that don't have an initial timepoint at
(AOP_summ$(AOP-1)[which(AOP_summ$Speaker == i & AOP_summ$gloss1 == gloss1)])) %>%           # the child's minimum age, and complete the gaps
mutate(remove = ifelse(!(age %in% AOP_summ$AOP[which(AOP_summ$Speaker == i)]), T, F)) %>%  # remove ages that don't have recordings
filter(remove != T) %>%
ungroup() %>%
mutate(PAT_val = ifelse(is.na(PAT_val), 0, PAT_val),                            # create PAT vals for these missing data points
PAT_val_m = ifelse(is.na(PAT_val_m), 0, PAT_val_m)) %>%                  # these are 0 by default as they don't connect to anything
fill(Speaker, .direction = "down") %>%                                          # fill in the Speaker info
fill(Speaker, .direction = "up")
all_mean_degree_data_actual[[i]] <- mean_degree_full_actual_missing
}
all_mean_degree_data_actual <- vector("list", length(2151))    # create an empty list for the missing datapoints
for (i in unique(mean_degree_full_actual_init$Speaker)) {
mean_degree_full_actual_missing <- mean_degree_full_actual_init %>%
filter(Speaker == i) %>%                                                         # for each speaker
group_by(gloss1) %>%                                                             # identify the words
complete(gloss1, age = (min_ages$min_age[which(min_ages$Speaker == i)]):         # that don't have an initial timepoint at
(AOP_summ$AOP-1[which(AOP_summ$Speaker == i & AOP_summ$gloss1 == gloss1)])) %>%         # the child's minimum age, and complete the gaps
mutate(remove = ifelse(!(age %in% AOP_summ$AOP[which(AOP_summ$Speaker == i)]), T, F)) %>%  # remove ages that don't have recordings
filter(remove != T) %>%
ungroup() %>%
mutate(PAT_val = ifelse(is.na(PAT_val), 0, PAT_val),                            # create PAT vals for these missing data points
PAT_val_m = ifelse(is.na(PAT_val_m), 0, PAT_val_m)) %>%                  # these are 0 by default as they don't connect to anything
fill(Speaker, .direction = "down") %>%                                          # fill in the Speaker info
fill(Speaker, .direction = "up")
all_mean_degree_data_actual[[i]] <- mean_degree_full_actual_missing
}
for (i in unique(mean_degree_full_actual_init$Speaker)) {
mean_degree_full_actual_missing <- mean_degree_full_actual_init %>%
filter(Speaker == i) %>%                                                         # for each speaker
group_by(gloss1) %>%                                                             # identify the words
complete(gloss1, age = (min_ages$min_age[which(min_ages$Speaker == i)]):         # that don't have an initial timepoint at
(AOP_summ$AOP[which(AOP_summ$Speaker == i & AOP_summ$gloss1 == gloss1)])) %>%         # the child's minimum age, and complete the gaps
mutate(remove = ifelse(!(age %in% AOP_summ$AOP[which(AOP_summ$Speaker == i)]), T, F)) %>%  # remove ages that don't have recordings
filter(remove != T) %>%
ungroup() %>%
mutate(PAT_val = ifelse(is.na(PAT_val), 0, PAT_val),                            # create PAT vals for these missing data points
PAT_val_m = ifelse(is.na(PAT_val_m), 0, PAT_val_m)) %>%                  # these are 0 by default as they don't connect to anything
fill(Speaker, .direction = "down") %>%                                          # fill in the Speaker info
fill(Speaker, .direction = "up")
all_mean_degree_data_actual[[i]] <- mean_degree_full_actual_missing
}
mean_degree_full_target <- feather::read_feather("Data/mean_degree_full_target_providence.feather")
mean_degree_full_actual <- feather::read_feather("Data/mean_degree_full_actual_providence.feather")
global_network <- globalthresholds_AOP_providence %>%
rename("PAQ_val" = "degree") %>%
dplyr::select(-age, -threshold)
mean_degree_full <- rbind(mean_degree_full_actual, mean_degree_full_target)
comparison_data <- read_csv("Data/comparison_data_providence.csv") %>%
distinct(Gloss, Speaker, .keep_all=T) %>%
dplyr::select(Gloss, Speaker, Targetphon, nsyl_target) %>%
rename("gloss1" = "Gloss")
global_network_split <- global_network %>%
pivot_wider(names_from = data_type, values_from = PAQ_val) %>%
rename("PAQ_target" = "target",
"PAQ_actual" = "actual")
regression_data <- mean_degree_full %>% left_join(global_network_split) %>%
group_by(Speaker, gloss1, data_type) %>%
mutate(learned_next = ifelse(age == max(age), 1, 0)) %>%
left_join(comparison_data) %>%
left_join(vocabsize_sub) %>%
ungroup() %>%
mutate(AOP_scaled = c(scale(AOP, center = TRUE, scale = TRUE)),
length_scaled = c(scale(Targetphon, center = TRUE, scale = TRUE))) %>%
#PAT_weighted = PAT_val/vocab_month) %>%
group_by(Speaker) %>%
mutate(PAT_scaled = c(scale(PAT_val, center = TRUE, scale = TRUE)),
PAT_scaled_m = c(scale(PAT_val_m, center = TRUE, scale = TRUE)),
PAQ_scaled_target = c(scale(PAQ_target, center = TRUE, scale = TRUE)),
PAQ_scaled_actual = c(scale(PAQ_actual, center = TRUE, scale = TRUE)))
chi_freq <- read_csv("Data/freq_providence.csv")
FULLsample_var <- feather::read_feather("Data/FULLsample_Providence.feather") %>%
group_by(Speaker, Gloss) %>%
tally() %>%
rename("gloss1" = "Gloss",
"n_tokens" = "n")   # how many tokens of each word included in the data
View(regression_data)
global_distance_providence <- feather::read_feather("Data/globaldistance_Providence.feather")
# global_distance_providence %>%
#   filter(Speaker == "Violet" & (gloss1 == "medicine" | gloss2 == "medicine")) %>%
#   group_by(age) %>% tally()
globalthresholds_providence <- feather::read_feather("Data/globalthresholds_providence.feather")
# globalthresholds_providence %>%
#   filter(Speaker == "Violet" & gloss1 == "medicine") %>%
#   group_by(age) %>% tally()
globalthresholds_AOP_providence <- feather::read_feather("Data/globalthresholds_AOP_providence.feather") %>%
filter(threshold == 0.25)
# globalthresholds_AOP_providence %>%
#   filter(Speaker == "Violet" & gloss1 == "medicine") %>%
#   group_by(age) %>% tally()
vocabsize_providence <- feather::read_feather("Data/globalthresholds_AOP_providence.feather") %>%
filter(threshold == 0.99, data_type == "target") %>%  # use 0.99 as threshold to make sure all new words are incorporated.
#filter(age == 30) %>%
group_by(Speaker, AOP) %>%
tally() %>%
rename("vocab_month" = "n") %>%
mutate(vocab_agg = cumsum(vocab_month))
# need to start with full list of all words by age, global_network$gloss1
ages <- global_distance_providence %>% filter(data_type == "target") %>% distinct(Speaker, gloss1, age)
AOP_summ_actual <- globalthresholds_AOP_providence %>%
mutate(Speaker_AOP = paste(Speaker, AOP, sep="_"),
AOP = as.numeric((AOP))) %>%
filter(data_type == "actual")
AOP_summ_target <- globalthresholds_AOP_providence %>%
mutate(Speaker_AOP = paste(Speaker, AOP, sep="_"),
AOP = as.numeric((AOP))) %>%
filter(data_type == "target")
AOP_summ <- rbind(AOP_summ_actual, AOP_summ_target) %>% distinct(Speaker, gloss1, .keep_all = T)
target_actual_diff <- rbind(AOP_summ_actual, AOP_summ_target) %>% group_by(Speaker, gloss1) %>% tally() %>% filter(n == 1)
AOP_list <- AOP_summ %>%
split(., f = .$Speaker_AOP)
global_distance_summ <- global_distance_providence %>%
mutate(Speaker_AOP = paste(Speaker, age, sep="_"))
gloss_summ <- globalthresholds_AOP_providence %>%
filter(data_type == "actual") %>%
mutate(Speaker_gloss = paste(Speaker, gloss1, sep="_"))
gloss_list <- gloss_summ %>%        # create a list of all words connected to the speaker who produces them
split(., f = .$Speaker_gloss)
connected_degree_list <- vector("list", length(gloss_list))
connected_degree_actual_melted <- feather::read_feather("Data/connected_degree_actual_melted_providence.feather")
actual_global_degree <- globalthresholds_providence %>%
filter(data_type == "actual") %>%
dplyr::select(Speaker, age, gloss1, degree) %>%
mutate(age = as.numeric(age))
known_degree_list <- vector("list", length(gloss_list))
known_words_degree_actual <-lapply(gloss_list, FUN = function(element) {
connections <- connected_degree_actual_melted %>%
filter(Speaker_gloss == element$Speaker_gloss)
min_age <- ages %>% filter(Speaker == element$Speaker & age == min(age))
degrees <- actual_global_degree %>%
filter(gloss1 %in% connections$known_word & (age < element$AOP) & Speaker == element$Speaker) %>%
group_by(Speaker, age) %>%
summarise(PAT_val = median(degree),
PAT_val_m = mean(degree))
known_degree_list <- list(degrees)    # should be degrees
})
AOP_summ_red <- AOP_summ %>% dplyr::select(Speaker, gloss1, AOP)
vocabsize_sub <- vocabsize_providence %>% distinct(Speaker, AOP, vocab_month)
mean_degree_full_actual_init <- melt(known_words_degree_actual) %>%      # establish mean degree for each word at each timepoint
group_by(L1, variable) %>%
mutate(rn = row_number()) %>%
pivot_wider(names_from = variable, values_from = value) %>%
separate(L1, into = c("remove", "gloss1"), sep = "_") %>%
dplyr::select(-remove, -L2, -rn)
min_ages <- ages %>% group_by(Speaker) %>% summarise(min_age = min(age)) %>%    # establish minimum age for each infant in the dataset
mutate(min_age = as.numeric(min_age))
all_mean_degree_data_actual <- vector("list", length(2151))    # create an empty list for the missing datapoints
for (i in unique(mean_degree_full_actual_init$Speaker)) {
mean_degree_full_actual_missing <- mean_degree_full_actual_init %>%
filter(Speaker == i) %>%                                                         # for each speaker
group_by(gloss1) %>%                                                             # identify the words
complete(gloss1, age = (min_ages$min_age[which(min_ages$Speaker == i)]):         # that don't have an initial timepoint at
(AOP_summ$AOP[which(AOP_summ$Speaker == i & AOP_summ$gloss1 == gloss1)])) %>%         # the child's minimum age, and complete the gaps
mutate(remove = ifelse(!(age %in% AOP_summ$AOP[which(AOP_summ$Speaker == i)]), T, F)) %>%  # remove ages that don't have recordings
filter(remove != T) %>%
ungroup() %>%
mutate(PAT_val = ifelse(is.na(PAT_val), 0, PAT_val),                            # create PAT vals for these missing data points
PAT_val_m = ifelse(is.na(PAT_val_m), 0, PAT_val_m)) %>%                  # these are 0 by default as they don't connect to anything
fill(Speaker, .direction = "down") %>%                                          # fill in the Speaker info
fill(Speaker, .direction = "up")
all_mean_degree_data_actual[[i]] <- mean_degree_full_actual_missing
}
mean_degree_full_actual <- bind_rows(all_mean_degree_data_actual) %>%
left_join(AOP_summ_red) %>%
dplyr::select(-remove) %>%
mutate(data_type = "actual")
feather::write_feather(mean_degree_full_actual, "Data/mean_degree_full_actual_providence.feather")
connected_words_melted_target <- feather::read_feather("Data/connected_words_melted_target_providence.feather") %>% mutate(age = as.numeric(age))
gloss_summ <- globalthresholds_AOP_providence %>%
filter(data_type == "target") %>%
mutate(Speaker_gloss = paste(Speaker, gloss1, sep="_"))
gloss_list <- gloss_summ %>%        # create a list of all words connected to the speaker who produces them
split(., f = .$Speaker_gloss)
connected_degree_list <- vector("list", length(gloss_list))
connected_degree_target <-lapply(gloss_list, FUN = function(element) {
AOP_data <- AOP_summ %>% filter(Speaker == element$Speaker & gloss1 == element$gloss1)
first_prod <- AOP_data$AOP
connections <- global_distance_providence %>%
filter(Speaker == element$Speaker  & data_type == "target" &
(gloss1  == element$gloss1 | gloss2 == element$gloss1) &
distance_norm <= 0.25) %>%
mutate(keep_meA = ifelse(gloss1 != element$gloss1 & (gloss1 %in% AOP_summ$gloss1[which(AOP_summ$AOP < first_prod)]),"y", "n")) %>%
mutate(keep_meB = ifelse(gloss2 != element$gloss1 & (gloss2 %in% AOP_summ$gloss1[which(AOP_summ$AOP < first_prod)]),"y", "n")) %>%
filter(keep_meA == "y" | keep_meB == "y") %>%
distinct(word_pair, Speaker, distance, .keep_all = T) %>%
mutate(known_word = ifelse(gloss1 == element$gloss1, gloss2, gloss1))
connected_degree_list <- list(connections)
})
connected_degree_target_melted <- feather::read_feather("Data/connected_degree_target_melted_providence.feather")
target_global_degree <- globalthresholds_providence %>%
filter(data_type == "target") %>%
dplyr::select(Speaker, age, gloss1, degree) %>%
mutate(age = as.numeric(age))
known_degree_list <- vector("list", length(gloss_list))
known_words_degree_target <-lapply(gloss_list, FUN = function(element) {
connections <- connected_degree_target_melted %>%
filter(Speaker_gloss == element$Speaker_gloss)
min_age <- ages %>% filter(Speaker == element$Speaker & age == min(age))
degrees <- target_global_degree %>%
filter(gloss1 %in% connections$known_word & (age < element$AOP) & Speaker == element$Speaker) %>%
group_by(Speaker, age) %>%
summarise(PAT_val = median(degree),
PAT_val_m = mean(degree))
known_degree_list <- list(degrees)    # should be degrees
})
mean_degree_full_target_init <- melt(known_words_degree_target) %>%      # establish mean degree for each word at each timepoint
group_by(L1, variable) %>%
mutate(rn = row_number()) %>%
pivot_wider(names_from = variable, values_from = value) %>%
separate(L1, into = c("remove", "gloss1"), sep = "_") %>%
dplyr::select(-remove, -L2, -rn)
all_mean_degree_data_target <- vector("list", length(2151))    # create an empty list for the missing datapoints
for (i in unique(mean_degree_full_target_init$Speaker)) {
mean_degree_full_target_missing <- mean_degree_full_target_init %>%
filter(Speaker == i) %>%                                                         # for each speaker
group_by(gloss1) %>%                                                             # identify the words
complete(gloss1, age = (min_ages$min_age[which(min_ages$Speaker == i)]):         # that don't have an initial timepoint at
(AOP_summ$AOP[which(AOP_summ$Speaker == i & AOP_summ$gloss1 == gloss1)])) %>%           # the child's minimum age, and complete the gaps
mutate(remove = ifelse(!(age %in% AOP_summ$AOP[which(AOP_summ$Speaker == i)]), T, F)) %>%  # remove ages that don't have recordings
filter(remove != T) %>%
ungroup() %>%
mutate(PAT_val = ifelse(is.na(PAT_val), 0, PAT_val),                            # create PAT vals for these missing data points
PAT_val_m = ifelse(is.na(PAT_val_m), 0, PAT_val_m)) %>%                  # these are 0 by default as they don't connect to anything
fill(Speaker, .direction = "down") %>%                                          # fill in the Speaker info
fill(Speaker, .direction = "up")
all_mean_degree_data_target[[i]] <- mean_degree_full_target_missing
}
mean_degree_full_target <- bind_rows(all_mean_degree_data_target) %>%
left_join(AOP_summ_red) %>%
dplyr::select(-remove) %>%
mutate(data_type = "target")
feather::write_feather(mean_degree_full_target, "Data/mean_degree_full_target_providence.feather")
global_network <- globalthresholds_AOP_providence %>%
rename("PAQ_val" = "degree") %>%
dplyr::select(-age, -threshold)
mean_degree_full <- rbind(mean_degree_full_actual, mean_degree_full_target)
comparison_data <- read_csv("Data/comparison_data_providence.csv") %>%
distinct(Gloss, Speaker, .keep_all=T) %>%
dplyr::select(Gloss, Speaker, Targetphon, nsyl_target) %>%
rename("gloss1" = "Gloss")
global_network_split <- global_network %>%
pivot_wider(names_from = data_type, values_from = PAQ_val) %>%
rename("PAQ_target" = "target",
"PAQ_actual" = "actual")
# global_network_split %>% filter(is.na(PAQ_target))   # in some cases there are words which don't have connections in the target/actual data
# these are shown as NA in the df, only 7 datapoints
regression_data <- mean_degree_full %>% left_join(global_network_split) %>%
group_by(Speaker, gloss1, data_type)
View(regression_data)
regression_data <- mean_degree_full %>% left_join(global_network_split) %>%
group_by(Speaker, gloss1, data_type) %>%
mutate(learned_next = ifelse(age == AOP-1, 1, 0)) %>%
left_join(comparison_data) %>%
left_join(vocabsize_sub) %>%
ungroup() %>%
mutate(AOP_scaled = c(scale(AOP, center = TRUE, scale = TRUE)),
length_scaled = c(scale(Targetphon, center = TRUE, scale = TRUE))) %>%
#PAT_weighted = PAT_val/vocab_month) %>%
group_by(Speaker) %>%
mutate(PAT_scaled = c(scale(PAT_val, center = TRUE, scale = TRUE)),
PAT_scaled_m = c(scale(PAT_val_m, center = TRUE, scale = TRUE)),
PAQ_scaled_target = c(scale(PAQ_target, center = TRUE, scale = TRUE)),
PAQ_scaled_actual = c(scale(PAQ_actual, center = TRUE, scale = TRUE)))
regression_data <- mean_degree_full %>% left_join(global_network_split) %>%
group_by(Speaker, gloss1, data_type) %>%
mutate(learned_next = ifelse(age == AOP-1, 1, 0)) %>%
filter(age != AOP) %>%
left_join(comparison_data) %>%
left_join(vocabsize_sub) %>%
ungroup() %>%
mutate(AOP_scaled = c(scale(AOP, center = TRUE, scale = TRUE)),
length_scaled = c(scale(Targetphon, center = TRUE, scale = TRUE))) %>%
#PAT_weighted = PAT_val/vocab_month) %>%
group_by(Speaker) %>%
mutate(PAT_scaled = c(scale(PAT_val, center = TRUE, scale = TRUE)),
PAT_scaled_m = c(scale(PAT_val_m, center = TRUE, scale = TRUE)),
PAQ_scaled_target = c(scale(PAQ_target, center = TRUE, scale = TRUE)),
PAQ_scaled_actual = c(scale(PAQ_actual, center = TRUE, scale = TRUE)))
View(min_ages)
regression_data <- mean_degree_full %>% left_join(global_network_split) %>%
group_by(Speaker, gloss1, data_type) %>%
mutate(learned_next = ifelse(age == AOP-1, 1, 0)) %>%
filter(age != AOP) %>%
left_join(comparison_data) %>%
left_join(vocabsize_sub) %>%
ungroup() %>%
mutate(AOP_scaled = c(scale(AOP, center = TRUE, scale = TRUE)),
length_scaled = c(scale(Targetphon, center = TRUE, scale = TRUE))) %>%
#PAT_weighted = PAT_val/vocab_month) %>%
group_by(Speaker) %>%
mutate(PAT_scaled = c(scale(PAT_val, center = TRUE, scale = TRUE)),
PAT_scaled_m = c(scale(PAT_val_m, center = TRUE, scale = TRUE)),
PAQ_scaled_target = c(scale(PAQ_target, center = TRUE, scale = TRUE)),
PAQ_scaled_actual = c(scale(PAQ_actual, center = TRUE, scale = TRUE)))
chi_freq <- read_csv("Data/freq_providence.csv")
FULLsample_var <- feather::read_feather("Data/FULLsample_Providence.feather") %>%
group_by(Speaker, Gloss) %>%
tally() %>%
rename("gloss1" = "Gloss",
"n_tokens" = "n")   # how many tokens of each word included in the data
regression_data <- regression_data %>%
left_join(chi_freq) %>%
left_join(FULLsample_var) %>%
mutate(total_freq = ifelse(is.na(total_freq), 0, total_freq)) %>%
mutate(freq_scaled = c(scale(total_freq, center = TRUE, scale = TRUE)),
vocab_scaled = c(scale(vocab_month, center = TRUE, scale = TRUE)),
tokens_scaled = c(scale(n_tokens, center = TRUE, scale = TRUE))) %>%
mutate(corpus = "Providence",
age_scaled = c(scale(age, center = T, scale = T)))
feather::write_feather(regression_data, "Data/regression_data_providence.feather")
global_distance_lyon <- feather::read_feather("Data/globaldistance_lyon.feather")
globalthresholds_lyon <- feather::read_feather("Data/globalthresholds_lyon.feather")
globalthresholds_AOP_lyon <- feather::read_feather("Data/globalthresholds_AOP_lyon.feather") %>%
filter(threshold == 0.25)
vocabsize_lyon <- feather::read_feather("Data/globalthresholds_AOP_lyon.feather") %>%
filter(threshold == 0.99, data_type == "target") %>%  # use 0.99 as threshold to make sure all new words are incorporated.
#filter(age == 30) %>%
group_by(Speaker, AOP) %>%
tally() %>%
rename("vocab_month" = "n") %>%
mutate(vocab_agg = cumsum(vocab_month))
ages <- global_distance_lyon %>% filter(data_type == "target") %>% distinct(Speaker, gloss1, age)
AOP_summ_actual <- globalthresholds_AOP_lyon %>%
mutate(Speaker_AOP = paste(Speaker, AOP, sep="_"),
AOP = as.numeric((AOP))) %>%
filter(data_type == "actual")
AOP_summ_target <- globalthresholds_AOP_lyon %>%
mutate(Speaker_AOP = paste(Speaker, AOP, sep="_"),
AOP = as.numeric((AOP))) %>%
filter(data_type == "target")
AOP_summ <- rbind(AOP_summ_actual, AOP_summ_target) %>% distinct(Speaker, gloss1, .keep_all = T)
mean_degree_full_target <- feather::read_feather("Data/mean_degree_full_target_lyon.feather")
mean_degree_full_actual <- feather::read_feather("Data/mean_degree_full_actual_lyon.feather")
global_network <- globalthresholds_AOP_lyon %>%
rename("PAQ_val" = "degree") %>%
dplyr::select(-age, -threshold)
mean_degree_full <- rbind(mean_degree_full_actual, mean_degree_full_target)
comparison_data <- read_csv("Data/comparison_data_lyon.csv") %>%
distinct(Gloss, Speaker, .keep_all=T) %>%
dplyr::select(Gloss, Speaker, Targetphon, nsyl_target) %>%
rename("gloss1" = "Gloss")
global_network_split <- global_network %>%
pivot_wider(names_from = data_type, values_from = PAQ_val) %>%
rename("PAQ_target" = "target",
"PAQ_actual" = "actual")
regression_data <- mean_degree_full %>% left_join(global_network_split) %>%
group_by(Speaker, gloss1, data_type) %>%
mutate(learned_next = ifelse(age == AOP-1, 1, 0)) %>%
filter(age != AOP) %>%
left_join(comparison_data) %>%
left_join(vocabsize_sub) %>%
ungroup() %>%
mutate(AOP_scaled = c(scale(AOP, center = TRUE, scale = TRUE)),
length_scaled = c(scale(Targetphon, center = TRUE, scale = TRUE))) %>%
#PAT_weighted = PAT_val/vocab_month) %>%
group_by(Speaker) %>%
mutate(PAT_scaled = c(scale(PAT_val, center = TRUE, scale = TRUE)),
PAT_scaled_m = c(scale(PAT_val_m, center = TRUE, scale = TRUE)),
PAQ_scaled_target = c(scale(PAQ_target, center = TRUE, scale = TRUE)),
PAQ_scaled_actual = c(scale(PAQ_actual, center = TRUE, scale = TRUE)))
vocabsize_sub <- vocabsize_lyon %>% distinct(Speaker, AOP, vocab_month)
vocabsize_sub <- vocabsize_lyon %>% distinct(Speaker, AOP, vocab_month)
regression_data <- mean_degree_full %>% left_join(global_network_split) %>%
group_by(Speaker, gloss1, data_type) %>%
mutate(learned_next = ifelse(age == AOP-1, 1, 0)) %>%
filter(age != AOP) %>%
left_join(comparison_data) %>%
left_join(vocabsize_sub) %>%
ungroup() %>%
mutate(AOP_scaled = c(scale(AOP, center = TRUE, scale = TRUE)),
length_scaled = c(scale(Targetphon, center = TRUE, scale = TRUE))) %>%
#PAT_weighted = PAT_val/vocab_month) %>%
group_by(Speaker) %>%
mutate(PAT_scaled = c(scale(PAT_val, center = TRUE, scale = TRUE)),
PAT_scaled_m = c(scale(PAT_val_m, center = TRUE, scale = TRUE)),
PAQ_scaled_target = c(scale(PAQ_target, center = TRUE, scale = TRUE)),
PAQ_scaled_actual = c(scale(PAQ_actual, center = TRUE, scale = TRUE)))
freq_lyon <- read_csv("Data/freq_lyon.csv")
FULLsample_var <- feather::read_feather("Data/FULLsample_Lyon.feather") %>%
group_by(Speaker, Gloss) %>%
tally() %>%
rename("gloss1" = "Gloss",
"n_tokens" = "n",)   # how many tokens of each word included in the data
regression_data <- regression_data %>%
left_join(freq_lyon) %>%
left_join(FULLsample_var) %>%
mutate(total_freq = ifelse(is.na(total_freq), 0, total_freq)) %>%
mutate(freq_scaled = c(scale(total_freq, center = TRUE, scale = TRUE)),
vocab_scaled = c(scale(vocab_month, center = TRUE, scale = TRUE)),
tokens_scaled = c(scale(n_tokens, center = TRUE, scale = TRUE))) %>%
mutate(corpus = "Lyon",
age_scaled = c(scale(age, center = T, scale = T)))
feather::write_feather(regression_data, "Data/regression_data_lyon.feather")
