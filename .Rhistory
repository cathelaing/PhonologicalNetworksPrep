View(ages)
min_age <- ages %>% filter(Speaker %in% element$Speaker & age == min(age))
degrees <- global_degree_CG %>%
filter(gloss1 %in% connections$target)
View(degrees)
degrees <- global_degree_CG %>%
filter(gloss1 %in% connections$target & Speaker == element$Speaker)
degrees <- global_degree_CG %>%
filter(gloss1 %in% connections$target & (age < element$AOP) & Speaker == element$Speaker)
degrees <- global_degree_CG %>%
filter(gloss1 %in% connections$target & Speaker == element$Speaker)
View(connected_degree_actual_melted)
degrees <- global_degree_CG %>%
filter(gloss1 %in% connections$connected & Speaker == element$Speaker)
degrees <- global_degree_CG %>%
filter(gloss1 %in% connections$connected & Speaker == element$Speaker & (age < element$AOP))
degrees <- global_degree_CG %>%
filter(gloss1 %in% connections$connected & Speaker == element$Speaker & (age < element$AOP)) %>%
group_by(Speaker, age) %>%
summarise(INT_val = median(degree),
INT_val_m = mean(degree))
known_words_degree_CG <-lapply(gloss_list, FUN = function(element) {
connections <- results_gloss_CG %>%
filter(Speaker_gloss %in% element$Speaker_gloss)
degrees <- global_degree_CG %>%
filter(gloss1 %in% connections$connected & Speaker == element$Speaker & (age < element$AOP)) %>%
group_by(Speaker, age) %>%
summarise(INT_val = median(degree),
INT_val_m = mean(degree))
known_degree_list <- list(degrees)
})
View(known_words_degree_CG)
mean_degree_full_CG_init <- melt(known_words_degree_CG)
View(mean_degree_full_CG_init)
mean_degree_full_CG_init <- melt(known_words_degree_CG) %>%      # establish mean degree for each word at each timepoint
group_by(L1, variable) %>%
mutate(rn = row_number()) %>%
pivot_wider(names_from = variable, values_from = value) %>%
separate(L1, into = c("remove", "gloss1"), sep = "_") %>%
dplyr::select(-remove, -L2, -rn)
View(connected_degree_list)
View(ages)
min_ages <- ages %>% group_by(Speaker) %>% summarise(min_age = min(age)) %>%    # establish minimum age for each infant in the dataset
mutate(min_age = as.numeric(min_age))
View(min_ages)
all_mean_degree_data_CG <- vector("list", length(known_words_degree_CG)    # create an empty list for the missing datapoints
all_mean_degree_data_CG <- vector("list", length(known_words_degree_CG))    # create an empty list for the missing datapoints
mean_degree_full_CG_init <- melt(known_words_degree_CG) %>%      # establish mean degree for each word at each timepoint
group_by(L1, variable) %>%
mutate(rn = row_number()) %>%
pivot_wider(names_from = variable, values_from = value) %>%
separate(L1, into = c("remove", "gloss1"), sep = "_") %>%
dplyr::select(-remove, -L2, -rn)
min_ages <- ages %>% group_by(Speaker) %>% summarise(min_age = min(age)) %>%    # establish minimum age for each infant in the dataset
mutate(min_age = as.numeric(min_age))
all_mean_degree_data_CG <- vector("list", length(known_words_degree_CG))    # create an empty list for the missing datapoints
View(AOP_summ)
for (i in unique(mean_degree_full_CG_init$Speaker)) {
mean_degree_full_CG_missing <- mean_degree_full_CG_init %>%
filter(Speaker == i) %>%                                                         # for each speaker
complete(gloss1,
age = (min_ages$min_age[which(min_ages$Speaker == i)]):         # that don't have an initial timepoint at
(AOP_summ$AOP[which(AOP_summ$Speaker == i & AOP_summ$gloss1 == gloss1)])) %>%         # the child's minimum age, and complete the gaps
mutate(remove = ifelse(!(age %in% AOP_summ$AOP[which(AOP_summ$Speaker == i)]), T, F)) %>% # remove ages that don't have recordings
filter(remove != T) %>%
ungroup() %>%
mutate(INT_val = ifelse(is.na(INT_val), 0, INT_val),                            # create INT vals for these missing data points
INT_val_m = ifelse(is.na(INT_val_m), 0, INT_val_m)) %>%                  # these are 0 by default as they don't connect to anything
fill(Speaker, .direction = "down") %>%                                          # fill in the Speaker info
fill(age, .direction = "up") %>%                                          # fill in the Speaker info
fill(Speaker, .direction = "up")
all_mean_degree_data_CG[[i]] <- mean_degree_full_CG_missing
}
for (i in unique(mean_degree_full_CG_init$Speaker)) {
mean_degree_full_CG_missing <- mean_degree_full_CG_init %>%
filter(Speaker == i) %>%                                                         # for each speaker
complete(gloss1,
age = (min_ages$min_age[which(min_ages$Speaker == i)]):         # that don't have an initial timepoint at
(AOP_summ$AOP[which(AOP_summ$Speaker %in% i & AOP_summ$gloss1 %in% gloss1)])) %>%         # the child's minimum age, and complete the gaps
mutate(remove = ifelse(!(age %in% AOP_summ$AOP[which(AOP_summ$Speaker %in% i)]), T, F)) %>% # remove ages that don't have recordings
filter(remove != T) %>%
ungroup() %>%
mutate(INT_val = ifelse(is.na(INT_val), 0, INT_val),                            # create INT vals for these missing data points
INT_val_m = ifelse(is.na(INT_val_m), 0, INT_val_m)) %>%                  # these are 0 by default as they don't connect to anything
fill(Speaker, .direction = "down") %>%                                          # fill in the Speaker info
fill(age, .direction = "up") %>%                                          # fill in the Speaker info
fill(Speaker, .direction = "up")
all_mean_degree_data_CG[[i]] <- mean_degree_full_CG_missing
}
for (i in unique(mean_degree_full_CG_init$Speaker)) {
mean_degree_full_CG_missing <- mean_degree_full_CG_init %>%
filter(Speaker == i) %>%                                                         # for each speaker
complete(gloss1,
age = (min_ages$min_age[which(min_ages$Speaker %in% i)]):         # that don't have an initial timepoint at
(AOP_summ$AOP[which(AOP_summ$Speaker %in% i & AOP_summ$gloss1 %in% gloss1)])) %>%         # the child's minimum age, and complete the gaps
mutate(remove = ifelse(!(age %in% AOP_summ$AOP[which(AOP_summ$Speaker %in% i)]), T, F)) %>% # remove ages that don't have recordings
filter(remove != T) %>%
ungroup() %>%
mutate(INT_val = ifelse(is.na(INT_val), 0, INT_val),                            # create INT vals for these missing data points
INT_val_m = ifelse(is.na(INT_val_m), 0, INT_val_m)) %>%                  # these are 0 by default as they don't connect to anything
fill(Speaker, .direction = "down") %>%                                          # fill in the Speaker info
fill(age, .direction = "up") %>%                                          # fill in the Speaker info
fill(Speaker, .direction = "up")
all_mean_degree_data_CG[[i]] <- mean_degree_full_CG_missing
}
mean_degree_full_CG <- bind_rows(all_mean_degree_data_CG)
View(mean_degree_full_CG)
mean_degree_full_CG <- bind_rows(all_mean_degree_data_CG) %>%
left_join(AOP_summ_red) %>%
dplyr::select(-remove) %>%
filter(age <= AOP)
AOP_summ_red <- AOP_summ %>% dplyr::select(Speaker, gloss1, AOP)
vocabsize_sub <- vocabsize_CG %>% distinct(Speaker, AOP, vocab_month)
mean_degree_full_CG <- bind_rows(all_mean_degree_data_CG) %>%
left_join(AOP_summ_red) %>%
dplyr::select(-remove) %>%
filter(age <= AOP)
feather::write_feather(mean_degree_full_CG, "Data/mean_degree_full_CG.feather")
#mean_degree_full_target <- feather::read_feather("Data/mean_degree_full_target_providence.feather")
mean_degree_full_actual <- feather::read_feather("Data/mean_degree_full_actual_providence.feather")
View(mean_degree_full_actual)
global_network <- globalthresholds_AOP_CG %>%
rename("EXT_val" = "degree") %>%
dplyr::select(-age, -threshold)
View(global_network)
comparison_data <- read_csv("Data/comparison_data_CG.csv") %>%
distinct(Gloss, Speaker, .keep_all=T)
View(comparison_data)
comparison_data <- read_csv("Data/comparison_data_CG.csv") %>%
distinct(Gloss, Speaker, .keep_all=T) %>%
dplyr::select(Gloss, Speaker, nsyl_target) %>%
rename("gloss1" = "Gloss")
regression_data <- mean_degree_full_CG %>% left_join(global_network) %>%
group_by(Speaker, gloss1) %>%
rename("INT_val" = "PAT_val",
"INT_val_m" = "PAT_val_m")
regression_data <- mean_degree_full_CG %>% left_join(global_network) %>%
group_by(Speaker, gloss1) %>%
# rename("INT_val" = "PAT_val",
#        "INT_val_m" = "PAT_val_m") %>%
mutate(learned_next = ifelse(age == AOP-1, 1, 0)) %>%
filter(age != AOP) %>%
left_join(comparison_data) %>%
ungroup()
View(regression_data)
regression_data <- mean_degree_full_CG %>% left_join(global_network) %>%
group_by(Speaker, gloss1) %>%
# rename("INT_val" = "PAT_val",
#        "INT_val_m" = "PAT_val_m") %>%
mutate(learned_next = ifelse(age == AOP-1, 1, 0)) %>%
filter(age != AOP) %>%
left_join(comparison_data) %>%
ungroup() %>%
mutate(AOP_scaled = c(scale(AOP, center = TRUE, scale = TRUE))) %>%
group_by(Speaker, age) %>%
mutate(INT_scaled = c(scale(INT_val, center = TRUE, scale = TRUE)),
INT_scaled_m = c(scale(INT_val_m, center = TRUE, scale = TRUE)),
INT_vocab_scaled = c(scale(INT_weighted, center = TRUE, scale = TRUE)),
EXT_vocab_scaled = c(scale(EXT_weighted, center = T, scale = T)),
EXT_scaled_target = c(scale(EXT_target, center = TRUE, scale = TRUE)),
EXT_scaled_actual = c(scale(EXT_actual, center = TRUE, scale = TRUE))) %>%
ungroup()
regression_data <- mean_degree_full_CG %>% left_join(global_network) %>%
group_by(Speaker, gloss1) %>%
# rename("INT_val" = "PAT_val",
#        "INT_val_m" = "PAT_val_m") %>%
mutate(learned_next = ifelse(age == AOP-1, 1, 0)) %>%
filter(age != AOP) %>%
left_join(comparison_data) %>%
ungroup() %>%
mutate(AOP_scaled = c(scale(AOP, center = TRUE, scale = TRUE))) %>%
group_by(Speaker, age) %>%
mutate(INT_scaled = c(scale(INT_val, center = TRUE, scale = TRUE)),
INT_scaled_m = c(scale(INT_val_m, center = TRUE, scale = TRUE)),
EXT_scaled = c(scale(EXT_val, center = TRUE, scale = TRUE))) %>%
ungroup()
load("C:/Code/PhonologicalNetworksPrep/uni_model_data.RData")
View(uni_model_data)
View(uni_model_data)
as.data.frame(uni_model_data)
freq_data <- as.data.frame(uni_model_data)
View(freq_data)
freq_data <- as.data.frame(uni_model_data) %>% filter(language == "English")
freq_data <- as.data.frame(uni_model_data)
View(freq_data)
freq_data <- as.data.frame(uni_model_data) %>% filter(language == "English (American)")
freq_data <- as.data.frame(uni_model_data) %>% filter(language == "English (American)", measure == "understands")
freq_data <- as.data.frame(uni_model_data) %>%
filter(language == "English (American)", measure == "understands",
prop >= .5)
freq_data <- as.data.frame(uni_model_data) %>%
filter(language == "English (American)", measure == "understands",
prop >= .5) %>%
group_by(uni_lemma) %>%
filter(unscaled_age = min(unscaled_age))
freq_data <- as.data.frame(uni_model_data) %>%
filter(language == "English (American)", measure == "understands",
prop >= .5) %>%
group_by(uni_lemma) %>%
filter(unscaled_age == min(unscaled_age))
freq_data_cdi <- as.data.frame(uni_model_data) %>%
filter(language == "English (American)", measure == "understands",
prop >= .5) %>%
group_by(uni_lemma) %>%
filter(unscaled_age == min(unscaled_age)) %>%
write_csv("Data/cdi_aoa_freq.csv")
freq_data_cdi <- as.data.frame(uni_model_data) %>%
filter(language == "English (American)", measure == "understands",
prop >= .5) %>%
group_by(uni_lemma) %>%
filter(unscaled_age == min(unscaled_age)) %>%
write_csv("Data/cdi_aoa_freq_eng.csv")
freq_data_cdi_eng <- as.data.frame(uni_model_data) %>%
filter(language == "English (American)", measure == "understands",
prop >= .5) %>%
group_by(uni_lemma) %>%
filter(unscaled_age == min(unscaled_age)) %>%
write_csv("Data/cdi_aoa_freq_eng.csv")
freq_data_cdi <- as.data.frame(uni_model_data)
View(freq_data)
freq_data_cdi <- as.data.frame(uni_model_data)
View(freq_data_cdi)
freq_data_cdi_fr <- as.data.frame(uni_model_data) %>%
filter(language == "French (Quebec)", measure == "understands",
prop >= .5) %>%
group_by(uni_lemma) %>%
filter(unscaled_age == min(unscaled_age)) %>%
write_csv("Data/cdi_aoa_freq_fr.csv")
input_freq <- read_csv("Data/childes_english.csv")
View(input_freq)
aoa_data <- read_csv("Data/cdi_aoa_freq_eng.csv")
FULLsample_var <- feather::read_feather("Data/FULLsample_CG.feather") %>%
group_by(Speaker, Gloss) %>%
tally() %>%
rename("gloss1" = "Gloss",
"n_tokens" = "n")   # how many tokens of each word included in the data
FULLsample_var <- read_csv("Data/FULLsample_CG.csv") %>%
group_by(Speaker, Gloss) %>%
tally() %>%
rename("gloss1" = "Gloss",
"n_tokens" = "n")   # how many tokens of each word included in the data
regression_data <- regression_data %>%
left_join(input_freq)
View(regression_data)
input_freq <- read_csv("Data/childes_english.csv") %>%
rename(gloss1 = word)
aoa_data <- read_csv("Data/cdi_aoa_freq_eng.csv") %>%
rename(gloss1 = word)
View(aoa_data)
aoa_data <- read_csv("Data/cdi_aoa_freq_eng.csv") %>%
rename(gloss1 = uni_lemma)
regression_data <- regression_data %>%
left_join(input_freq)
regression_data %>% filter(is.na(word.count))
regression_data %>% filter(is.na(word_count))
regression_data <- regression_data %>%
left_join(input_freq) %>%
left_join(aoa_data)
regression_data <- regression_data %>%
#left_join(input_freq) %>%
left_join(aoa_data)
regression_data <- regression_data %>%
#left_join(input_freq) %>%
left_join(aoa_data, by = "gloss1")
regression_data <- mean_degree_full_CG %>% left_join(global_network) %>%
group_by(Speaker, gloss1) %>%
mutate(learned_next = ifelse(age == AOP-1, 1, 0)) %>%
filter(age != AOP) %>%
left_join(comparison_data) %>%
ungroup() %>%
mutate(AOP_scaled = c(scale(AOP, center = TRUE, scale = TRUE))) %>%
group_by(Speaker, age) %>%
mutate(INT_scaled = c(scale(INT_val, center = TRUE, scale = TRUE)),
INT_scaled_m = c(scale(INT_val_m, center = TRUE, scale = TRUE)),
EXT_scaled = c(scale(EXT_val, center = TRUE, scale = TRUE))) %>%
ungroup()
regression_data <- regression_data %>%
#left_join(input_freq) %>%
left_join(aoa_data, by = "gloss1")
regression_data <- mean_degree_full_CG %>% left_join(global_network) %>%
group_by(Speaker, gloss1) %>%
mutate(learned_next = ifelse(age == AOP-1, 1, 0)) %>%
filter(age != AOP) %>%
left_join(comparison_data) %>%
ungroup() %>%
mutate(AOP_scaled = c(scale(AOP, center = TRUE, scale = TRUE))) %>%
group_by(Speaker, age) %>%
mutate(INT_scaled = c(scale(INT_val, center = TRUE, scale = TRUE)),
INT_scaled_m = c(scale(INT_val_m, center = TRUE, scale = TRUE)),
EXT_scaled = c(scale(EXT_val, center = TRUE, scale = TRUE))) %>%
ungroup()
regression_data <- regression_data %>%
left_join(input_freq) %>%
left_join(aoa_data, by = "gloss1")
regression_data <- mean_degree_full_CG %>% left_join(global_network) %>%
group_by(Speaker, gloss1) %>%
mutate(learned_next = ifelse(age == AOP-1, 1, 0)) %>%
filter(age != AOP) %>%
left_join(comparison_data) %>%
ungroup() %>%
mutate(AOP_scaled = c(scale(AOP, center = TRUE, scale = TRUE))) %>%
group_by(Speaker, age) %>%
mutate(INT_scaled = c(scale(INT_val, center = TRUE, scale = TRUE)),
INT_scaled_m = c(scale(INT_val_m, center = TRUE, scale = TRUE)),
EXT_scaled = c(scale(EXT_val, center = TRUE, scale = TRUE))) %>%
ungroup()
regression_data <- regression_data %>%
left_join(input_freq) %>%
left_join(aoa_data, by = "gloss1") %>%
left_join(FULLsample_var) %>%
mutate(word_count = ifelse(is.na(word_count), 0, total_freq)) %>%
mutate(freq_scaled = c(scale(word_count, center = TRUE, scale = TRUE)),
vocab_scaled = c(scale(vocab_agg, center = TRUE, scale = TRUE)),
tokens_scaled = c(scale(n_tokens, center = TRUE, scale = TRUE))) %>%
mutate(corpus = "English",
age_scaled = c(scale(age, center = T, scale = T)),
category = as.factor(category),
data_type = as.factor(data_type),
Speaker = as.factor(Speaker),
corpus = as.factor(corpus))
regression_data <- regression_data %>%
left_join(input_freq) %>%
left_join(aoa_data, by = "gloss1") %>%
left_join(FULLsample_var) %>%
mutate(word_count = ifelse(is.na(word_count), 0, word_count)) %>%
mutate(freq_scaled = c(scale(word_count, center = TRUE, scale = TRUE)),
vocab_scaled = c(scale(vocab_agg, center = TRUE, scale = TRUE)),
tokens_scaled = c(scale(n_tokens, center = TRUE, scale = TRUE))) %>%
mutate(corpus = "English",
age_scaled = c(scale(age, center = T, scale = T)),
category = as.factor(category),
data_type = as.factor(data_type),
Speaker = as.factor(Speaker),
corpus = as.factor(corpus))
regression_data <- regression_data %>%
left_join(input_freq) %>%
left_join(aoa_data, by = "gloss1") %>%
left_join(FULLsample_var) %>%
mutate(word_count = ifelse(is.na(word_count), 0, word_count)) %>%
mutate(freq_scaled = c(scale(word_count, center = TRUE, scale = TRUE)),
tokens_scaled = c(scale(n_tokens, center = TRUE, scale = TRUE))) %>%
mutate(corpus = "English",
age_scaled = c(scale(age, center = T, scale = T)),
Speaker = as.factor(Speaker))
regression_data <- regression_data %>%
left_join(input_freq) %>%
left_join(aoa_data, by = "gloss1") %>%
left_join(FULLsample_var) %>%
mutate(word_count = ifelse(is.na(word_count), 0, word_count)) %>%
mutate(freq_scaled = c(scale(word_count, center = TRUE, scale = TRUE)),
tokens_scaled = c(scale(n_tokens, center = TRUE, scale = TRUE))) %>%
mutate(age_scaled = c(scale(age, center = T, scale = T)),
Speaker = as.factor(Speaker))
regression_data <- regression_data %>%
left_join(input_freq) %>%
left_join(aoa_data, by = "gloss1") %>%
left_join(FULLsample_var)
View(FULLsample_var)
regression_data <- mean_degree_full_CG %>% left_join(global_network) %>%
group_by(Speaker, gloss1) %>%
mutate(learned_next = ifelse(age == AOP-1, 1, 0)) %>%
filter(age != AOP) %>%
left_join(comparison_data) %>%
ungroup() %>%
mutate(AOP_scaled = c(scale(AOP, center = TRUE, scale = TRUE))) %>%
group_by(Speaker, age) %>%
mutate(INT_scaled = c(scale(INT_val, center = TRUE, scale = TRUE)),
INT_scaled_m = c(scale(INT_val_m, center = TRUE, scale = TRUE)),
EXT_scaled = c(scale(EXT_val, center = TRUE, scale = TRUE))) %>%
ungroup()
regression_data <- regression_data %>%
left_join(input_freq) %>%
left_join(aoa_data, by = "gloss1") %>%
mutate(word_count = ifelse(is.na(word_count), 0, word_count))
aoa_data <- read_csv("Data/cdi_aoa_freq_eng.csv") %>%
select(-age) %>%
rename(gloss1 = uni_lemma)
regression_data <- regression_data %>%
left_join(input_freq) %>%
left_join(aoa_data, by = "gloss1") %>%
mutate(word_count = ifelse(is.na(word_count), 0, word_count)) %>%
mutate(freq_scaled = c(scale(word_count, center = TRUE, scale = TRUE)),
tokens_scaled = c(scale(n_tokens, center = TRUE, scale = TRUE))) %>%
mutate(age_scaled = c(scale(age, center = T, scale = T)),
Speaker = as.factor(Speaker))
regression_data <- regression_data %>%
left_join(input_freq) %>%
left_join(aoa_data, by = "gloss1") %>%
mutate(word_count = ifelse(is.na(word_count), 0, word_count)) %>%
mutate(freq_scaled = c(scale(word_count, center = TRUE, scale = TRUE))) %>%
mutate(age_scaled = c(scale(age, center = T, scale = T)),
Speaker = as.factor(Speaker))
regression_data <- regression_data %>%
left_join(input_freq) %>%
left_join(aoa_data, by = "gloss1") %>%
mutate(word_count = ifelse(is.na(word_count), 0, word_count)) %>%
mutate(freq_scaled = c(scale(word_count, center = TRUE, scale = TRUE)))
aoa_data <- read_csv("Data/cdi_aoa_freq_eng.csv") %>%
select(-age) %>%
rename(gloss1 = uni_lemma)
regression_data <- regression_data %>%
left_join(input_freq) %>%
left_join(aoa_data, by = "gloss1")
regression_data <- mean_degree_full_CG %>% left_join(global_network) %>%
group_by(Speaker, gloss1) %>%
mutate(learned_next = ifelse(age == AOP-1, 1, 0)) %>%
filter(age != AOP) %>%
left_join(comparison_data) %>%
ungroup() %>%
mutate(AOP_scaled = c(scale(AOP, center = TRUE, scale = TRUE))) %>%
group_by(Speaker, age) %>%
mutate(INT_scaled = c(scale(INT_val, center = TRUE, scale = TRUE)),
INT_scaled_m = c(scale(INT_val_m, center = TRUE, scale = TRUE)),
EXT_scaled = c(scale(EXT_val, center = TRUE, scale = TRUE))) %>%
ungroup()
regression_data <- regression_data %>%
left_join(input_freq) %>%
left_join(aoa_data, by = "gloss1")
aoa_data <- read_csv("Data/cdi_aoa_freq_eng.csv")
aoa_data <- read_csv("Data/cdi_aoa_freq_eng.csv") %>%
select(uni_lemma, age) %>%
rename(gloss1 = uni_lemma,
aoa_comp = age)
input_freq <- read_csv("Data/childes_english.csv") %>%
rename(gloss1 = word) %>%
select(gloss1, word_count)
aoa_data <- read_csv("Data/cdi_aoa_freq_eng.csv") %>%
select(uni_lemma, age) %>%
rename(gloss1 = uni_lemma,
aoa_comp = age)
regression_data <- regression_data %>%
left_join(input_freq) %>%
left_join(aoa_data, by = "gloss1") %>%
mutate(word_count = ifelse(is.na(word_count), 0, word_count)) %>%
mutate(freq_scaled = c(scale(word_count, center = TRUE, scale = TRUE))) %>%
mutate(age_scaled = c(scale(age, center = T, scale = T)),
Speaker = as.factor(Speaker)) %>%
select()
regression_data <- mean_degree_full_CG %>% left_join(global_network) %>%
group_by(Speaker, gloss1) %>%
mutate(learned_next = ifelse(age == AOP-1, 1, 0)) %>%
filter(age != AOP) %>%
left_join(comparison_data) %>%
ungroup() %>%
mutate(AOP_scaled = c(scale(AOP, center = TRUE, scale = TRUE))) %>%
group_by(Speaker, age) %>%
mutate(INT_scaled = c(scale(INT_val, center = TRUE, scale = TRUE)),
INT_scaled_m = c(scale(INT_val_m, center = TRUE, scale = TRUE)),
EXT_scaled = c(scale(EXT_val, center = TRUE, scale = TRUE))) %>%
ungroup()
input_freq <- read_csv("Data/childes_english.csv") %>%
rename(gloss1 = word) %>%
select(gloss1, word_count)
aoa_data <- read_csv("Data/cdi_aoa_freq_eng.csv") %>%
select(uni_lemma, age) %>%
rename(gloss1 = uni_lemma,
aoa_comp = age)
regression_data <- regression_data %>%
left_join(input_freq) %>%
left_join(aoa_data, by = "gloss1") %>%
mutate(word_count = ifelse(is.na(word_count), 0, word_count)) %>%
mutate(freq_scaled = c(scale(word_count, center = TRUE, scale = TRUE))) %>%
mutate(age_scaled = c(scale(age, center = T, scale = T)),
Speaker = as.factor(Speaker))
aoa_data <- read_csv("Data/cdi_aoa_freq_eng.csv")
aoa_data <- read_csv("Data/cdi_aoa_freq_eng.csv") %>%
select(uni_lemma, age, lexical_category) %>%
rename(gloss1 = uni_lemma,
aoa_comp = age)
regression_data <- mean_degree_full_CG %>% left_join(global_network) %>%
group_by(Speaker, gloss1) %>%
mutate(learned_next = ifelse(age == AOP-1, 1, 0)) %>%
filter(age != AOP) %>%
left_join(comparison_data) %>%
ungroup() %>%
mutate(AOP_scaled = c(scale(AOP, center = TRUE, scale = TRUE))) %>%
group_by(Speaker, age) %>%
mutate(INT_scaled = c(scale(INT_val, center = TRUE, scale = TRUE)),
INT_scaled_m = c(scale(INT_val_m, center = TRUE, scale = TRUE)),
EXT_scaled = c(scale(EXT_val, center = TRUE, scale = TRUE))) %>%
ungroup()
regression_data <- regression_data %>%
left_join(input_freq) %>%
left_join(aoa_data, by = "gloss1") %>%
mutate(word_count = ifelse(is.na(word_count), 0, word_count)) %>%
mutate(freq_scaled = c(scale(word_count, center = TRUE, scale = TRUE))) %>%
mutate(age_scaled = c(scale(age, center = T, scale = T)),
Speaker = as.factor(Speaker))
regression_data <- mean_degree_full_CG %>% left_join(global_network) %>%
group_by(Speaker, gloss1) %>%
mutate(learned_next = ifelse(age == AOP-1, 1, 0)) %>%
filter(age != AOP) %>%
left_join(comparison_data) %>%
ungroup() %>%
mutate(AOP_scaled = c(scale(AOP, center = TRUE, scale = TRUE))) %>%
group_by(Speaker, age) %>%
mutate(INT_scaled = c(scale(INT_val, center = TRUE, scale = TRUE)),
INT_scaled_m = c(scale(INT_val_m, center = TRUE, scale = TRUE)),
EXT_scaled = c(scale(EXT_val, center = TRUE, scale = TRUE))) %>%
ungroup()
regression_data <- regression_data %>%
left_join(input_freq) %>%
left_join(aoa_data, by = "gloss1") %>%
mutate(word_count = ifelse(is.na(word_count), 0, word_count)) %>%
mutate(freq_scaled = c(scale(word_count, center = TRUE, scale = TRUE))) %>%
mutate(age_scaled = c(scale(age, center = T, scale = T)),
Speaker = as.factor(Speaker),
lexical_category = as.factor(lexical_category))
regression_data$lexical_category = relevel(regression_data$lexical_category, ref="noun")
regression_data$lexical_category = relevel(regression_data$lexical_category, ref="nouns")
feather::write_feather(regression_data, "Data/repofiles/regression_data_CG.feather")
gc()
