"010726", "010707", "010726"), AOP = c(19, 19, 19, 19, 19,
19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19), subj_session = c("Alex_19",
"Alex_19", "Alex_19", "Alex_19", "Alex_19", "Alex_19", "Alex_19",
"Alex_19", "Alex_19", "Alex_19", "Alex_19", "Alex_19", "Alex_19",
"Alex_19", "Alex_19", "Alex_19"), Speaker_AOP = c("Alex_19",
"Alex_19", "Alex_19", "Alex_19", "Alex_19", "Alex_19", "Alex_19",
"Alex_19", "Alex_19", "Alex_19", "Alex_19", "Alex_19", "Alex_19",
"Alex_19", "Alex_19", "Alex_19")), row.names = c(NA, -16L
), class = c("tbl_df", "tbl", "data.frame")), Alex_20 = structure(list(
Speaker = c("Alex", "Alex", "Alex", "Alex", "Alex", "Alex",
"Alex", "Alex", "Alex", "Alex", "Alex", "Alex", "Alex", "Alex"
), age = c(30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,
30, 30), gloss1 = c("boy", "bunny", "bye", "cookie", "eye",
"go", "goose", "meow", "moon", "shh", "sticky", "towel",
"yellow", "yes"), degree = c(118L, 118L, 118L, 11L, 105L,
105L, 105L, 118L, 118L, 137L, 1L, 54L, 98L, 105L), threshold = c("0.25",
"0.25", "0.25", "0.25", "0.25", "0.25", "0.25", "0.25", "0.25",
"0.25", "0.25", "0.25", "0.25", "0.25"), data_type = c("actual",
"actual", "actual", "actual", "actual", "actual", "actual",
"actual", "actual", "actual", "actual", "actual", "actual",
"actual"), Session = c("010811", "010811", "010811", "010811",
"010825", "010811", "010811", "010825", "010825", "010811",
"010811", "010811", "010825", "010811"), AOP = c(20, 20,
20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20), subj_session = c("Alex_20",
"Alex_20", "Alex_20", "Alex_20", "Alex_20", "Alex_20", "Alex_20",
"Alex_20", "Alex_20", "Alex_20", "Alex_20", "Alex_20", "Alex_20",
"Alex_20"), Speaker_AOP = c("Alex_20", "Alex_20", "Alex_20",
"Alex_20", "Alex_20", "Alex_20", "Alex_20", "Alex_20", "Alex_20",
"Alex_20", "Alex_20", "Alex_20", "Alex_20", "Alex_20")), row.names = c(NA,
-14L), class = c("tbl_df", "tbl", "data.frame")))
prepared_data_target <- lapply(AOP_list, FUN = function(element) {
data <- target_data %>% filter(data_type == "target" & Speaker == element$Speaker)
timepoint <- data %>% filter(AOP == element$AOP)
timepoint <- timepoint$AOP
unknown <- data %>% filter(AOP > timepoint)
known <- data %>% filter(AOP <= timepoint)
output <- list(timepoint, known, unknown)
})
dput(globalthresholds_AOP_providence[1:200])
dput(globalthresholds_AOP_providence[1:200])
dput(globalthresholds_AOP_providence[1:200, ])
dput(AOP_list[1:10])
dput(globalthresholds_AOP_providence[1:200, ])
output <- vector("list", length(81)) #Prep a list to store your corr.test results
names <- names(AOP_list)
prepared_data_target <- lapply(AOP_list, FUN = function(element) {
data <- globalthresholds_AOP_providence %>% filter(data_type == "target" & Speaker == element$Speaker)
timepoint <- data %>% filter(AOP == element$AOP)                              # select the timepoint for each network
timepoint <- timepoint$AOP
unknown <- data %>% filter(AOP > timepoint)                                   # filter so that only to-be-learned words are included
known <- data %>% filter(AOP <= timepoint)                 # also create df for known words
output <- list(timepoint, known, unknown)                           # merge into a list for working on further
})
prepared_data_target <- lapply(AOP_list, FUN = function(element) {
data <- globalthresholds_AOP_providence %>% filter(data_type == "target" & Speaker == element$Speaker)
timepoint <- data %>% filter(AOP == element$AOP) %>% distinct(AOP)                           # select the timepoint for each network
timepoint <- timepoint$AOP
unknown <- data %>% filter(AOP > timepoint)                                   # filter so that only to-be-learned words are included
known <- data %>% filter(AOP <= timepoint)                 # also create df for known words
output <- list(timepoint, known, unknown)                           # merge into a list for working on further
})
View(prepared_df_actual)
View(timepoint_df_actual)
listed <- list()
for(i in seq_along(1:length(AOP_list))){
element <- AOP_list[[i]]
# you got a vector as output as element$Speaker: we assume it is always made of equal elements
data <- globalthresholds_AOP_providence %>% filter(data_type == "target" & Speaker == element$Speaker[1])
# you got a vector as output: we assume it is always made of equal elements with [1]
timepoint <- data %>% filter(AOP == element$AOP[1])
if(nrow(timepoint) <1){print(sprintf("problems in %s iteration",i))} else {
# you got a vector as output: we assume it is always made of equal elements with [1]
timepoint <-  (timepoint$AOP[1])
unknown <- data %>% filter(AOP > timepoint)
known <- data %>% filter(AOP <= timepoint)
output <- list(timepoint, known, unknown)
listed[[i]] <- output
print(i)
}
}
View(listed)
prepared_data_target <- setNames(listed, paste0(names))
prepared_df_target <- melt(prepared_data_target)
View(prepared_data_target)
View(prepared_data_actual)
output_list <- list()
for(i in seq_along(1:length(AOP_list))){
element <- AOP_list[[i]]
# you got a vector as output as element$Speaker: we assume it is always made of equal elements
data <- globalthresholds_AOP_providence %>% filter(data_type == "target" & Speaker == element$Speaker[1])
# you got a vector as output: we assume it is always made of equal elements with [1]
timepoint <- data %>% filter(AOP == element$AOP[1])
if(nrow(timepoint) <1){print(sprintf("problems in %s iteration",i))} else {
# you got a vector as output: we assume it is always made of equal elements with [1]
timepoint <-  (timepoint$AOP[1])
unknown <- data %>% filter(AOP > timepoint)
known <- data %>% filter(AOP <= timepoint)
output <- list(timepoint, known, unknown)
output_list[[i]] <- output
print(i)
}
}
names <- names(AOP_list)
output_list <- list()
for(i in seq_along(1:length(AOP_list))){
element <- AOP_list[[i]]
# you got a vector as output as element$Speaker: we assume it is always made of equal elements
data <- globalthresholds_AOP_providence %>% filter(data_type == "target" & Speaker == element$Speaker[1])
# you got a vector as output: we assume it is always made of equal elements with [1]
timepoint <- data %>% filter(AOP == element$AOP[1])
if(nrow(timepoint) <1){print(sprintf("problems in %s iteration",i))} else {
# you got a vector as output: we assume it is always made of equal elements with [1]
timepoint <-  (timepoint$AOP[1])
unknown <- data %>% filter(AOP > timepoint)
known <- data %>% filter(AOP <= timepoint)
output <- list(timepoint, known, unknown)
output_list[[i]] <- output
print(i)
}
}
prepared_data_target <- setNames(output_list, paste0(names))
View(prepared_data_target)
prepared_df_target <- melt(prepared_data_target)
for(i in seq_along(1:length(AOP_list))){
element <- AOP_list[[i]]
# you got a vector as output as element$Speaker: we assume it is always made of equal elements
data <- globalthresholds_AOP_providence %>% filter(data_type == "target" & Speaker == element$Speaker[1])
# you got a vector as output: we assume it is always made of equal elements with [1]
timepoint <- data %>% filter(AOP == element$AOP[1])
if(nrow(timepoint) <1){print(sprintf("problems in %s iteration",i))} else {
# you got a vector as output: we assume it is always made of equal elements with [1]
timepoint <-  (timepoint$AOP[1])
unknown <- data %>% filter(AOP > timepoint)
known <- data %>% filter(AOP <= timepoint)
output <- list(known, unknown)
output_list[[i]] <- output
print(i)
}
}
prepared_data_target <- setNames(output_list, paste0(names))
prepared_df_target <- melt(prepared_data_target)
prepared_data_target <- do.call(rbind.data.frame, output_list)
for(i in seq_along(1:length(AOP_list))){
element <- AOP_list[[i]]
# you got a vector as output as element$Speaker: we assume it is always made of equal elements
data <- globalthresholds_AOP_providence %>% filter(data_type == "target" & Speaker == element$Speaker[1])
# you got a vector as output: we assume it is always made of equal elements with [1]
timepoint <- data %>% filter(AOP == element$AOP[1])
if(nrow(timepoint) <1){print(sprintf("problems in %s iteration",i))} else {
# you got a vector as output: we assume it is always made of equal elements with [1]
timepoint <-  (timepoint$AOP[1])
unknown <- data %>% filter(AOP > timepoint)
known <- data %>% filter(AOP <= timepoint)
output <- list(known, unknown)
output_list[[i]] <- output
print(i)
}
}
prepared_df_target <- melt(output_list)
prepared_data_target <- do.call(rbind.data.frame, output_list)
View(output_list)
names <- names(AOP_list)
output_list <- list()
for(i in seq_along(1:length(AOP_list))){
element <- AOP_list[[i]]
# you got a vector as output as element$Speaker: we assume it is always made of equal elements
data <- globalthresholds_AOP_providence %>% filter(data_type == "target" & Speaker == element$Speaker[1])
# you got a vector as output: we assume it is always made of equal elements with [1]
timepoint <- data %>% filter(AOP == element$AOP[1])
if(nrow(timepoint) <1){print(sprintf("problems in %s iteration",i))} else {
# you got a vector as output: we assume it is always made of equal elements with [1]
timepoint <-  (timepoint$AOP[1])
unknown <- data %>% filter(AOP > timepoint)
known <- data %>% filter(AOP <= timepoint)
output <- list(known, unknown)
output_list[[i]] <- output
print(i)
}
}
prepared_data_target <- setNames(output_list, paste0(names))
prepared_data_target <- do.call(rbind.data.frame, output_list)
test <- data.frame(prepared_data_target = unlist(prepared_data_target))
View(test)
str(prepared_data_target)
test <- do.call(rbind, prepared_data_target)
View(test)
test <- do.call(cbind, prepared_data_target)
View(test)
prepared_data_target <- as.data.frame(matrix(unlist(prepared_data_target), nrow=length(unlist(prepared_data_target[1]))))
View(test)
prepared_data_target <- setNames(output_list, paste0(names))
prepared_df_target <- melt(prepared_data_target)
prepared_df_target <- melt(output_list)
length(output_list)
names(output_list) = "test"
names(output_list)
prepared_df_target <- melt(output_list)
data.table::as.data.table(prepared_data_target)
prepared_df_target <-data.table::as.data.table(prepared_data_target)
View(prepared_df_actual)
View(prepared_df_target)
prepared_df_target <-data.table::as.data.table(prepared_data_target)
prepared_data_target <- setNames(output_list, paste0(names))
prepared_df_target <-data.table::as.data.table(prepared_data_target)
prepared_df_target <-as.data.frame(ftable(prepared_data_target))
prepared_df_target <-as.data.frame(ftable(prepared_data_target))
View(prepared_df_target)
View(prepared_df_target[[2]][[1]])
View(prepared_df_target[[4]][[2]])
prepared_df_target <- as.data.frame(matrix(unlist(prepared_data_target),nrow=length(prepared_data_target),byrow=TRUE)
prepared_df_target <- as.data.frame(matrix(unlist(prepared_data_target),nrow=length(prepared_data_target),byrow=TRUE))
prepared_df_target <- as.data.frame(matrix(unlist(prepared_data_target),nrow=length(prepared_data_target),byrow=TRUE))
View(prepared_df_target)
View(prepared_data_target)
prepared_data_target <- setNames(output_list, paste0(names))
prepared_df_target <- melt(output_list)
View(globalthresholds_providence)
prepared_data_target %>% discard(is.null)
test <- prepared_data_target %>% discard(is.null)
prepared_data_target <- setNames(output_list, paste0(names))
test <- prepared_data_target %>% discard(is.null)
View(test)
prepared_df_target <- melt(test)
View(prepared_df_target)
known_target <- prepared_df_target %>% filter(L2 == 1) %>%
dplyr::select(value, Speaker, gloss1, variable, L1) %>%
pivot_wider(names_from = variable, values_from = value)
View(known_target)
known_target <- prepared_df_target %>% filter(L2 == 1) %>%
dplyr::select(value, Speaker, gloss1, variable, L1) %>%
pivot_wider(names_from = variable, values_from = value) %>%
rename("Speaker_AOP" = "L1")
unknown_target <- prepared_df_target %>% filter(L2 == 2) %>%
dplyr::select(value, Speaker, gloss1, variable, L1) %>%
pivot_wider(names_from = variable, values_from = value) %>%
rename("Speaker_AOP" = "L1")
output_connected_target <- vector("list", length(81)) #Prep a list to store your corr.test results
known_list_target <- vector("list", length(81))
for (i in unique(known_target$Speaker_AOP)) {
connected_words <- global_distance_summ %>%                              # for each known word in each session,
filter(data_type == "target") %>%                                      # which words in the existing lexicon does it connect to and what is the distance?
group_by(Speaker, age) %>%
filter(Speaker == first(global_distance_summ$Speaker[which(global_distance_summ$Speaker_AOP == i)]) &
age ==  first(global_distance_summ$age[which(global_distance_summ$Speaker_AOP == i)])) %>%
filter((gloss1 %in% known_target$gloss1 |                 # find word pairs with the words in it
gloss2 %in% known_target$gloss1) &
distance_norm <= .25) %>%                 # filter out any pairs that don't meet the similarity threshold
distinct(word_pair, .keep_all = T)# %>%             # get rid of repeats
known_list_target[[i]] <- connected_words
}
View(known_list_target)
connected_words_red_target <- known_list_target[c(2:79)]
View(connected_words_red_target)
connected_words_red_target <- known_list_target[c(2:80)]
View(globalthresholds_AOP_providence)
connected_words_red_target <- known_list_target[c(2:81)]
View(connected_words_red_target)
connected_words_melted_target <- melt(connected_words_red_target) %>%
filter(variable == "distance_norm") %>%
mutate(age = as.numeric(age))
View(connected_words_melted_target)
feather::write_feather(connected_words_melted_target, "Data/connected_words_melted_target_providence.feather")
gloss_summ <- globalthresholds_AOP_providence %>%
filter(data_type == "target") %>%
mutate(Speaker_gloss = paste(Speaker, gloss1, sep="_"))
gloss_list <- gloss_summ %>%        # create a list of all words connected to the speaker who produces them
split(., f = .$Speaker_gloss)
connected_degree_list <- vector("list", length(gloss_list))
connected_degree_target <-lapply(gloss_list, FUN = function(element) {
AOP_data <- AOP_summ %>% filter(Speaker == element$Speaker & gloss1 == element$gloss1)
first_prod <- AOP_data$AOP
connections <- global_distance_providence %>%
filter(Speaker == element$Speaker  & data_type == "target" &
(gloss1  == element$gloss1 | gloss2 == element$gloss1) &
distance_norm <= 0.25) %>%
mutate(keep_meA = ifelse(gloss1 != element$gloss1 & (gloss1 %in% AOP_summ$gloss1[which(AOP_summ$AOP < first_prod)]),"y", "n")) %>%
mutate(keep_meB = ifelse(gloss2 != element$gloss1 & (gloss2 %in% AOP_summ$gloss1[which(AOP_summ$AOP < first_prod)]),"y", "n")) %>%
filter(keep_meA == "y" | keep_meB == "y") %>%
distinct(word_pair, Speaker, distance, .keep_all = T) %>%
mutate(known_word = ifelse(gloss1 == element$gloss1, gloss2, gloss1))
connected_degree_list <- list(connections)
})
connected_degree_target_melted <- melt(connected_degree_target) %>%
filter(variable == "distance_norm") %>% rename("Speaker_gloss" = "L1",
"distance_norm" = "value") %>%
dplyr::select(-keep_meA, -keep_meB, -variable, -L2) %>%
mutate(age = as.numeric(age))
View(connected_degree_target_melted)
feather::write_feather(connected_degree_target_melted, "Data/connected_degree_target_melted_providence.feather")
target_global_degree <- globalthresholds_providence %>%
filter(data_type == "target") %>%
dplyr::select(Speaker, age, gloss1, degree) %>%
mutate(age = as.numeric(age))
known_degree_list <- vector("list", length(gloss_list))
known_words_degree_target <-lapply(gloss_list, FUN = function(element) {
connections <- connected_degree_target_melted %>%
filter(Speaker_gloss == element$Speaker_gloss)
min_age <- ages %>% filter(Speaker == element$Speaker & age == min(age))
degrees <- target_global_degree %>%
filter(gloss1 %in% connections$known_word & (age < element$AOP) & Speaker == element$Speaker) %>%
group_by(Speaker, age) %>%
summarise(PAT_val = median(degree),
PAT_val_m = mean(degree))
known_degree_list <- list(degrees)    # should be degrees
})
mean_degree_full_target_init <- melt(known_words_degree_target) %>%      # establish mean degree for each word at each timepoint
group_by(L1, variable) %>%
mutate(rn = row_number()) %>%
pivot_wider(names_from = variable, values_from = value) %>%
separate(L1, into = c("remove", "gloss1"), sep = "_") %>%
dplyr::select(-remove, -L2, -rn)
all_mean_degree_data_target <- vector("list", length(2151))    # create an empty list for the missing datapoints
for (i in unique(mean_degree_full_target_init$Speaker)) {
mean_degree_full_target_missing <- mean_degree_full_target_init %>%
filter(Speaker == i) %>%                                                         # for each speaker
group_by(gloss1) %>%                                                             # identify the words
complete(gloss1, age = (min_ages$min_age[which(min_ages$Speaker == i)]):         # that don't have an initial timepoint at
(AOP_summ$AOP[which(AOP_summ$Speaker == i & AOP_summ$gloss1 == gloss1)])) %>%           # the child's minimum age, and complete the gaps
mutate(remove = ifelse(!(age %in% AOP_summ$AOP[which(AOP_summ$Speaker == i)]), T, F)) %>%  # remove ages that don't have recordings
filter(remove != T) %>%
ungroup() %>%
mutate(PAT_val = ifelse(is.na(PAT_val), 0, PAT_val),                            # create PAT vals for these missing data points
PAT_val_m = ifelse(is.na(PAT_val_m), 0, PAT_val_m)) %>%                  # these are 0 by default as they don't connect to anything
fill(Speaker, .direction = "down") %>%                                          # fill in the Speaker info
fill(Speaker, .direction = "up")
all_mean_degree_data_target[[i]] <- mean_degree_full_target_missing
}
mean_degree_full_target <- bind_rows(all_mean_degree_data_target) %>%
left_join(AOP_summ_red) %>%
dplyr::select(-remove) %>%
mutate(data_type = "target")
View(mean_degree_full_target)
View(mean_degree_full_actual_init)
View(mean_degree_full_actual)
feather::write_feather(mean_degree_full_target, "Data/mean_degree_full_target_providence.feather")
names <- names(AOP_list)
output_list <- list()
for(i in seq_along(1:length(AOP_list))){    # NEED TO CHANGE THIS ABOVE AND IN LYON DATA
element <- AOP_list[[i]]
# you got a vector as output as element$Speaker: we assume it is always made of equal elements
data <- globalthresholds_AOP_providence %>% filter(data_type == "actual" & Speaker == element$Speaker[1])
# you got a vector as output: we assume it is always made of equal elements with [1]
timepoint <- data %>% filter(AOP == element$AOP[1])
if(nrow(timepoint) <1){print(sprintf("problems in %s iteration",i))} else {
# you got a vector as output: we assume it is always made of equal elements with [1]
timepoint <-  (timepoint$AOP[1])
unknown <- data %>% filter(AOP > timepoint)
known <- data %>% filter(AOP <= timepoint)
output <- list(known, unknown)
output_list[[i]] <- output
print(i)
}
}
prepared_data_actual <- setNames(output_list, paste0(names))
View(prepared_data_actual)
prepared_data_actual <- prepared_data_actual %>% discard(is.null)
prepared_df_actual <- melt(prepared_data_actual)
known_actual <- prepared_df_actual %>% filter(L2 == 1) %>%
dplyr::select(value, Speaker, gloss1, variable, L1) %>%
pivot_wider(names_from = variable, values_from = value) %>%
rename("Speaker_AOP" = "L1")
unknown_actual <- prepared_df_actual %>% filter(L2 == 2) %>%
dplyr::select(value, Speaker, gloss1, variable, L1) %>%
pivot_wider(names_from = variable, values_from = value) %>%
rename("Speaker_AOP" = "L1")
known_list_actual <- vector("list", length(81))
View(known_list_actual)
for (i in unique(known_actual$Speaker_AOP)) {
connected_words <- global_distance_summ %>%                              # for each known word in each session,
filter(data_type == "actual") %>%                                      # which words in the existing lexicon does it connect to and what is the distance?
group_by(Speaker, age) %>%
filter(Speaker == first(global_distance_summ$Speaker[which(global_distance_summ$Speaker_AOP == i)]) &
age ==  first(global_distance_summ$age[which(global_distance_summ$Speaker_AOP == i)])) %>%
filter((gloss1 %in% known_actual$gloss1 |                 # find word pairs with the words in it
gloss2 %in% known_actual$gloss1) &
distance_norm <= .25) %>%                 # filter out any pairs that don't meet the similarity threshold
distinct(word_pair, .keep_all = T)# %>%             # get rid of repeats
known_list_actual[[i]] <- connected_words
}
connected_words_red_actual <- known_list_actual[c(2:81)]
connected_words_melted_actual <- melt(connected_words_red_actual) %>%
filter(variable == "distance_norm") %>%
mutate(age = as.numeric(age))
feather::write_feather(connected_words_melted_actual, "Data/connected_words_melted_actual_providence.feather")
gloss_summ <- globalthresholds_AOP_providence %>%
filter(data_type == "actual") %>%
mutate(Speaker_gloss = paste(Speaker, gloss1, sep="_"))
gloss_list <- gloss_summ %>%        # create a list of all words connected to the speaker who produces them
split(., f = .$Speaker_gloss)
connected_degree_list <- vector("list", length(gloss_list))
connected_degree_actual <-lapply(gloss_list, FUN = function(element) {
AOP_data <- AOP_summ %>% filter(Speaker == element$Speaker & gloss1 == element$gloss1)  # select each word produced by each speaker
first_prod <- AOP_data$AOP                                                              # select the age at which it was first produced
connections <- global_distance_providence %>%                                          # select every word pair that contains the selected word
filter(Speaker == element$Speaker  & data_type == "actual" &
(gloss1  == element$gloss1 | gloss2 == element$gloss1) &
distance_norm <= 0.25) %>%
mutate(keep_meA = ifelse(gloss1 != element$gloss1 & (gloss1 %in% AOP_summ$gloss1[which(AOP_summ$AOP < first_prod)]),"y", "n")) %>%
mutate(keep_meB = ifelse(gloss2 != element$gloss1 & (gloss2 %in% AOP_summ$gloss1[which(AOP_summ$AOP < first_prod)]),"y", "n")) %>%
filter(keep_meA == "y" | keep_meB == "y") %>%
distinct(word_pair, Speaker, distance, .keep_all = T) %>%
mutate(known_word = ifelse(gloss1 == element$gloss1, gloss2, gloss1))
connected_degree_list <- list(connections)
})
connected_degree_actual_melted <- melt(connected_degree_actual) %>%
filter(variable == "distance_norm") %>% rename("Speaker_gloss" = "L1",
"distance_norm" = "value") %>%
dplyr::select(-keep_meA, -keep_meB, -variable, -L2) %>%
mutate(age = as.numeric(age))
feather::write_feather(connected_degree_actual_melted, "Data/connected_degree_actual_melted_providence.feather")
actual_global_degree <- globalthresholds_providence %>%
filter(data_type == "actual") %>%
dplyr::select(Speaker, age, gloss1, degree) %>%
mutate(age = as.numeric(age))
known_degree_list <- vector("list", length(gloss_list))
known_words_degree_actual <-lapply(gloss_list, FUN = function(element) {
connections <- connected_degree_actual_melted %>%
filter(Speaker_gloss == element$Speaker_gloss)
min_age <- ages %>% filter(Speaker == element$Speaker & age == min(age))
degrees <- actual_global_degree %>%
filter(gloss1 %in% connections$known_word & (age < element$AOP) & Speaker == element$Speaker) %>%
group_by(Speaker, age) %>%
summarise(PAT_val = median(degree),
PAT_val_m = mean(degree))
known_degree_list <- list(degrees)    # should be degrees
})
AOP_summ_red <- AOP_summ %>% dplyr::select(Speaker, gloss1, AOP)
vocabsize_sub <- vocabsize_providence %>% distinct(Speaker, AOP, vocab_month)
mean_degree_full_actual_init <- melt(known_words_degree_actual) %>%      # establish mean degree for each word at each timepoint
group_by(L1, variable) %>%
mutate(rn = row_number()) %>%
pivot_wider(names_from = variable, values_from = value) %>%
separate(L1, into = c("remove", "gloss1"), sep = "_") %>%
dplyr::select(-remove, -L2, -rn)
min_ages <- ages %>% group_by(Speaker) %>% summarise(min_age = min(age)) %>%    # establish minimum age for each infant in the dataset
mutate(min_age = as.numeric(min_age))
all_mean_degree_data_actual <- vector("list", length(2151))    # create an empty list for the missing datapoints
for (i in unique(mean_degree_full_actual_init$Speaker)) {
mean_degree_full_actual_missing <- mean_degree_full_actual_init %>%
filter(Speaker == i) %>%                                                         # for each speaker
group_by(gloss1) %>%                                                             # identify the words
complete(gloss1, age = (min_ages$min_age[which(min_ages$Speaker == i)]):         # that don't have an initial timepoint at
(AOP_summ$AOP[which(AOP_summ$Speaker == i & AOP_summ$gloss1 == gloss1)])) %>%         # the child's minimum age, and complete the gaps
mutate(remove = ifelse(!(age %in% AOP_summ$AOP[which(AOP_summ$Speaker == i)]), T, F)) %>%  # remove ages that don't have recordings
filter(remove != T) %>%
ungroup() %>%
mutate(PAT_val = ifelse(is.na(PAT_val), 0, PAT_val),                            # create PAT vals for these missing data points
PAT_val_m = ifelse(is.na(PAT_val_m), 0, PAT_val_m)) %>%                  # these are 0 by default as they don't connect to anything
fill(Speaker, .direction = "down") %>%                                          # fill in the Speaker info
fill(Speaker, .direction = "up")
all_mean_degree_data_actual[[i]] <- mean_degree_full_actual_missing
}
mean_degree_full_actual <- bind_rows(all_mean_degree_data_actual) %>%
left_join(AOP_summ_red) %>%
dplyr::select(-remove) %>%
mutate(data_type = "actual")
feather::write_feather(mean_degree_full_actual, "Data/mean_degree_full_actual_providence.feather")
global_network <- globalthresholds_AOP_providence %>%
rename("PAQ_val" = "degree") %>%
dplyr::select(-age, -threshold)
mean_degree_full <- rbind(mean_degree_full_actual, mean_degree_full_target)
comparison_data <- read_csv("Data/comparison_data_providence.csv") %>%
distinct(Gloss, Speaker, .keep_all=T) %>%
dplyr::select(Gloss, Speaker, Targetphon, nsyl_target) %>%
rename("gloss1" = "Gloss")
global_network_split <- global_network %>%
pivot_wider(names_from = data_type, values_from = PAQ_val) %>%
rename("PAQ_target" = "target",
"PAQ_actual" = "actual")
regression_data <- mean_degree_full %>% left_join(global_network_split) %>%
group_by(Speaker, gloss1, data_type) %>%
mutate(learned_next = ifelse(age == AOP-1, 1, 0)) %>%
filter(age != AOP) %>%
left_join(comparison_data) %>%
left_join(vocabsize_sub) %>%
ungroup() %>%
mutate(AOP_scaled = c(scale(AOP, center = TRUE, scale = TRUE)),
length_scaled = c(scale(Targetphon, center = TRUE, scale = TRUE))) %>%
#PAT_weighted = PAT_val/vocab_month) %>%
group_by(Speaker) %>%
mutate(PAT_scaled = c(scale(PAT_val, center = TRUE, scale = TRUE)),
PAT_scaled_m = c(scale(PAT_val_m, center = TRUE, scale = TRUE)),
PAQ_scaled_target = c(scale(PAQ_target, center = TRUE, scale = TRUE)),
PAQ_scaled_actual = c(scale(PAQ_actual, center = TRUE, scale = TRUE)))
chi_freq <- read_csv("Data/freq_providence.csv")
session_data <- read_csv("Data/comparison_data_providence.csv") %>%    # need to add ordinal session numbers for GAMMs
group_by(Speaker, age) %>%
tally() %>%
filter(n > 1) %>%
dplyr::select(Speaker, age) %>%
group_by(Speaker, age) %>%
tally() %>%
mutate(session_ordinal = row_number()) %>%
dplyr::select(-n)
FULLsample_var <- feather::read_feather("Data/FULLsample_Providence.feather") %>%
group_by(Speaker, Gloss) %>%
tally() %>%
rename("gloss1" = "Gloss",
"n_tokens" = "n")   # how many tokens of each word included in the data
regression_data <- regression_data %>%
left_join(chi_freq) %>%
left_join(FULLsample_var) %>%
left_join(session_data) %>%
mutate(total_freq = ifelse(is.na(total_freq), 0, total_freq)) %>%
mutate(freq_scaled = c(scale(total_freq, center = TRUE, scale = TRUE)),
vocab_scaled = c(scale(vocab_month, center = TRUE, scale = TRUE)),
tokens_scaled = c(scale(n_tokens, center = TRUE, scale = TRUE))) %>%
mutate(corpus = "Providence",
age_scaled = c(scale(age, center = T, scale = T)))
feather::write_feather(regression_data, "Data/regression_data_providence.feather")
gc()
source("prelims.R")
