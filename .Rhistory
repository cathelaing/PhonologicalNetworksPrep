filter(gloss1 %in% connections$known_word & (age < element$AOP) & Speaker == element$Speaker) %>%
group_by(Speaker, age) %>%
summarise(PAT_val = median(degree),
PAT_val_m = mean(degree))
known_degree_list <- list(degrees)    # should be degrees
})
mean_degree_full_target_init <- melt(known_words_degree_target) %>%      # establish mean degree for each word at each timepoint
group_by(L1, variable) %>%
mutate(rn = row_number()) %>%
pivot_wider(names_from = variable, values_from = value) %>%
separate(L1, into = c("remove", "gloss1"), sep = "_") %>%
dplyr::select(-remove, -L2, -rn)
all_mean_degree_data_target <- vector("list", length(2151))    # create an empty list for the missing datapoints
for (i in unique(mean_degree_full_target_init$Speaker)) {
mean_degree_full_target_missing <- mean_degree_full_target_init %>%
filter(Speaker == i) %>%                                                         # for each speaker
group_by(gloss1) %>%                                                             # identify the words
complete(gloss1, age = (min_ages$min_age[which(min_ages$Speaker == i)]):         # that don't have an initial timepoint at
(AOP_summ$AOP[which(AOP_summ$Speaker == i & AOP_summ$gloss1 == gloss1)])) %>%           # the child's minimum age, and complete the gaps
mutate(remove = ifelse(!(age %in% AOP_summ$AOP[which(AOP_summ$Speaker == i)]), T, F)) %>%  # remove ages that don't have recordings
filter(remove != T) %>%
ungroup() %>%
mutate(PAT_val = ifelse(is.na(PAT_val), 0, PAT_val),                            # create PAT vals for these missing data points
PAT_val_m = ifelse(is.na(PAT_val_m), 0, PAT_val_m)) %>%                  # these are 0 by default as they don't connect to anything
fill(Speaker, .direction = "down") %>%                                          # fill in the Speaker info
fill(Speaker, .direction = "up")
all_mean_degree_data_target[[i]] <- mean_degree_full_target_missing
}
mean_degree_full_target <- bind_rows(all_mean_degree_data_target) %>%
left_join(AOP_summ_red) %>%
dplyr::select(-remove) %>%
mutate(data_type = "target")
feather::write_feather(mean_degree_full_target, "Data/mean_degree_full_target_providence.feather")
global_network <- globalthresholds_AOP_providence %>%
rename("PAQ_val" = "degree") %>%
dplyr::select(-age, -threshold)
mean_degree_full <- rbind(mean_degree_full_actual, mean_degree_full_target)
comparison_data <- read_csv("Data/comparison_data_providence.csv") %>%
distinct(Gloss, Speaker, .keep_all=T) %>%
dplyr::select(Gloss, Speaker, Targetphon, nsyl_target) %>%
rename("gloss1" = "Gloss")
global_network_split <- global_network %>%
pivot_wider(names_from = data_type, values_from = PAQ_val) %>%
rename("PAQ_target" = "target",
"PAQ_actual" = "actual")
# global_network_split %>% filter(is.na(PAQ_target))   # in some cases there are words which don't have connections in the target/actual data
# these are shown as NA in the df, only 7 datapoints
regression_data <- mean_degree_full %>% left_join(global_network_split) %>%
group_by(Speaker, gloss1, data_type)
View(regression_data)
regression_data <- mean_degree_full %>% left_join(global_network_split) %>%
group_by(Speaker, gloss1, data_type) %>%
mutate(learned_next = ifelse(age == AOP-1, 1, 0)) %>%
left_join(comparison_data) %>%
left_join(vocabsize_sub) %>%
ungroup() %>%
mutate(AOP_scaled = c(scale(AOP, center = TRUE, scale = TRUE)),
length_scaled = c(scale(Targetphon, center = TRUE, scale = TRUE))) %>%
#PAT_weighted = PAT_val/vocab_month) %>%
group_by(Speaker) %>%
mutate(PAT_scaled = c(scale(PAT_val, center = TRUE, scale = TRUE)),
PAT_scaled_m = c(scale(PAT_val_m, center = TRUE, scale = TRUE)),
PAQ_scaled_target = c(scale(PAQ_target, center = TRUE, scale = TRUE)),
PAQ_scaled_actual = c(scale(PAQ_actual, center = TRUE, scale = TRUE)))
regression_data <- mean_degree_full %>% left_join(global_network_split) %>%
group_by(Speaker, gloss1, data_type) %>%
mutate(learned_next = ifelse(age == AOP-1, 1, 0)) %>%
filter(age != AOP) %>%
left_join(comparison_data) %>%
left_join(vocabsize_sub) %>%
ungroup() %>%
mutate(AOP_scaled = c(scale(AOP, center = TRUE, scale = TRUE)),
length_scaled = c(scale(Targetphon, center = TRUE, scale = TRUE))) %>%
#PAT_weighted = PAT_val/vocab_month) %>%
group_by(Speaker) %>%
mutate(PAT_scaled = c(scale(PAT_val, center = TRUE, scale = TRUE)),
PAT_scaled_m = c(scale(PAT_val_m, center = TRUE, scale = TRUE)),
PAQ_scaled_target = c(scale(PAQ_target, center = TRUE, scale = TRUE)),
PAQ_scaled_actual = c(scale(PAQ_actual, center = TRUE, scale = TRUE)))
View(min_ages)
regression_data <- mean_degree_full %>% left_join(global_network_split) %>%
group_by(Speaker, gloss1, data_type) %>%
mutate(learned_next = ifelse(age == AOP-1, 1, 0)) %>%
filter(age != AOP) %>%
left_join(comparison_data) %>%
left_join(vocabsize_sub) %>%
ungroup() %>%
mutate(AOP_scaled = c(scale(AOP, center = TRUE, scale = TRUE)),
length_scaled = c(scale(Targetphon, center = TRUE, scale = TRUE))) %>%
#PAT_weighted = PAT_val/vocab_month) %>%
group_by(Speaker) %>%
mutate(PAT_scaled = c(scale(PAT_val, center = TRUE, scale = TRUE)),
PAT_scaled_m = c(scale(PAT_val_m, center = TRUE, scale = TRUE)),
PAQ_scaled_target = c(scale(PAQ_target, center = TRUE, scale = TRUE)),
PAQ_scaled_actual = c(scale(PAQ_actual, center = TRUE, scale = TRUE)))
chi_freq <- read_csv("Data/freq_providence.csv")
FULLsample_var <- feather::read_feather("Data/FULLsample_Providence.feather") %>%
group_by(Speaker, Gloss) %>%
tally() %>%
rename("gloss1" = "Gloss",
"n_tokens" = "n")   # how many tokens of each word included in the data
regression_data <- regression_data %>%
left_join(chi_freq) %>%
left_join(FULLsample_var) %>%
mutate(total_freq = ifelse(is.na(total_freq), 0, total_freq)) %>%
mutate(freq_scaled = c(scale(total_freq, center = TRUE, scale = TRUE)),
vocab_scaled = c(scale(vocab_month, center = TRUE, scale = TRUE)),
tokens_scaled = c(scale(n_tokens, center = TRUE, scale = TRUE))) %>%
mutate(corpus = "Providence",
age_scaled = c(scale(age, center = T, scale = T)))
feather::write_feather(regression_data, "Data/regression_data_providence.feather")
global_distance_lyon <- feather::read_feather("Data/globaldistance_lyon.feather")
globalthresholds_lyon <- feather::read_feather("Data/globalthresholds_lyon.feather")
globalthresholds_AOP_lyon <- feather::read_feather("Data/globalthresholds_AOP_lyon.feather") %>%
filter(threshold == 0.25)
vocabsize_lyon <- feather::read_feather("Data/globalthresholds_AOP_lyon.feather") %>%
filter(threshold == 0.99, data_type == "target") %>%  # use 0.99 as threshold to make sure all new words are incorporated.
#filter(age == 30) %>%
group_by(Speaker, AOP) %>%
tally() %>%
rename("vocab_month" = "n") %>%
mutate(vocab_agg = cumsum(vocab_month))
ages <- global_distance_lyon %>% filter(data_type == "target") %>% distinct(Speaker, gloss1, age)
AOP_summ_actual <- globalthresholds_AOP_lyon %>%
mutate(Speaker_AOP = paste(Speaker, AOP, sep="_"),
AOP = as.numeric((AOP))) %>%
filter(data_type == "actual")
AOP_summ_target <- globalthresholds_AOP_lyon %>%
mutate(Speaker_AOP = paste(Speaker, AOP, sep="_"),
AOP = as.numeric((AOP))) %>%
filter(data_type == "target")
AOP_summ <- rbind(AOP_summ_actual, AOP_summ_target) %>% distinct(Speaker, gloss1, .keep_all = T)
mean_degree_full_target <- feather::read_feather("Data/mean_degree_full_target_lyon.feather")
mean_degree_full_actual <- feather::read_feather("Data/mean_degree_full_actual_lyon.feather")
global_network <- globalthresholds_AOP_lyon %>%
rename("PAQ_val" = "degree") %>%
dplyr::select(-age, -threshold)
mean_degree_full <- rbind(mean_degree_full_actual, mean_degree_full_target)
comparison_data <- read_csv("Data/comparison_data_lyon.csv") %>%
distinct(Gloss, Speaker, .keep_all=T) %>%
dplyr::select(Gloss, Speaker, Targetphon, nsyl_target) %>%
rename("gloss1" = "Gloss")
global_network_split <- global_network %>%
pivot_wider(names_from = data_type, values_from = PAQ_val) %>%
rename("PAQ_target" = "target",
"PAQ_actual" = "actual")
regression_data <- mean_degree_full %>% left_join(global_network_split) %>%
group_by(Speaker, gloss1, data_type) %>%
mutate(learned_next = ifelse(age == AOP-1, 1, 0)) %>%
filter(age != AOP) %>%
left_join(comparison_data) %>%
left_join(vocabsize_sub) %>%
ungroup() %>%
mutate(AOP_scaled = c(scale(AOP, center = TRUE, scale = TRUE)),
length_scaled = c(scale(Targetphon, center = TRUE, scale = TRUE))) %>%
#PAT_weighted = PAT_val/vocab_month) %>%
group_by(Speaker) %>%
mutate(PAT_scaled = c(scale(PAT_val, center = TRUE, scale = TRUE)),
PAT_scaled_m = c(scale(PAT_val_m, center = TRUE, scale = TRUE)),
PAQ_scaled_target = c(scale(PAQ_target, center = TRUE, scale = TRUE)),
PAQ_scaled_actual = c(scale(PAQ_actual, center = TRUE, scale = TRUE)))
vocabsize_sub <- vocabsize_lyon %>% distinct(Speaker, AOP, vocab_month)
vocabsize_sub <- vocabsize_lyon %>% distinct(Speaker, AOP, vocab_month)
regression_data <- mean_degree_full %>% left_join(global_network_split) %>%
group_by(Speaker, gloss1, data_type) %>%
mutate(learned_next = ifelse(age == AOP-1, 1, 0)) %>%
filter(age != AOP) %>%
left_join(comparison_data) %>%
left_join(vocabsize_sub) %>%
ungroup() %>%
mutate(AOP_scaled = c(scale(AOP, center = TRUE, scale = TRUE)),
length_scaled = c(scale(Targetphon, center = TRUE, scale = TRUE))) %>%
#PAT_weighted = PAT_val/vocab_month) %>%
group_by(Speaker) %>%
mutate(PAT_scaled = c(scale(PAT_val, center = TRUE, scale = TRUE)),
PAT_scaled_m = c(scale(PAT_val_m, center = TRUE, scale = TRUE)),
PAQ_scaled_target = c(scale(PAQ_target, center = TRUE, scale = TRUE)),
PAQ_scaled_actual = c(scale(PAQ_actual, center = TRUE, scale = TRUE)))
freq_lyon <- read_csv("Data/freq_lyon.csv")
FULLsample_var <- feather::read_feather("Data/FULLsample_Lyon.feather") %>%
group_by(Speaker, Gloss) %>%
tally() %>%
rename("gloss1" = "Gloss",
"n_tokens" = "n",)   # how many tokens of each word included in the data
regression_data <- regression_data %>%
left_join(freq_lyon) %>%
left_join(FULLsample_var) %>%
mutate(total_freq = ifelse(is.na(total_freq), 0, total_freq)) %>%
mutate(freq_scaled = c(scale(total_freq, center = TRUE, scale = TRUE)),
vocab_scaled = c(scale(vocab_month, center = TRUE, scale = TRUE)),
tokens_scaled = c(scale(n_tokens, center = TRUE, scale = TRUE))) %>%
mutate(corpus = "Lyon",
age_scaled = c(scale(age, center = T, scale = T)))
feather::write_feather(regression_data, "Data/regression_data_lyon.feather")
# install.packages("stringi")
# install.packages("ggplot2")
# install.packages("stringr")
# install.packages("tibble")
# install.packages("ggpubr")
# install.packages("lmerTest")
# install.packages("papaja")
# install.packages("tidyverse")
# install.packages("dplyr")
# install.packages("tibble")
# install.packages("afex")
# install.packages("citr")
# install.packages("glmmTMB")
# install.packages("janitor")
#install.packages("linguisticsdown")
#install.packages("ggraph")
#install.packages("wesanderson")
# install.packages("effects")
library(tidyverse)
library(stringi)
library(stringr)
library(ggplot2)
library(tibble)
library(lmerTest)
library(papaja)
library(tidyverse)
library(dplyr)
#library(citr)
library(feather)
library(ggthemes)
#library(effects)
library(nlme)
library(glmmTMB)
library(broom)
library(kableExtra)
library(knitr)
library(interactions)
library(janitor)
library(ggraph)
library(data.table)
library(linguisticsdown)
library(ggridges)
library(wesanderson)
library(igraph)
global_distance_providence <- feather::read_feather("Data/globaldistance_Providence.feather")
# global_distance_providence %>%
#   filter(Speaker == "Violet" & (gloss1 == "medicine" | gloss2 == "medicine")) %>%
#   group_by(age) %>% tally()
globalthresholds_providence <- feather::read_feather("Data/globalthresholds_providence.feather")
# globalthresholds_providence %>%
#   filter(Speaker == "Violet" & gloss1 == "medicine") %>%
#   group_by(age) %>% tally()
globalthresholds_AOP_providence <- feather::read_feather("Data/globalthresholds_AOP_providence.feather") %>%
filter(threshold == 0.25)
# globalthresholds_AOP_providence %>%
#   filter(Speaker == "Violet" & gloss1 == "medicine") %>%
#   group_by(age) %>% tally()
vocabsize_providence <- feather::read_feather("Data/globalthresholds_AOP_providence.feather") %>%
filter(threshold == 0.99, data_type == "target") %>%  # use 0.99 as threshold to make sure all new words are incorporated.
#filter(age == 30) %>%
group_by(Speaker, AOP) %>%
tally() %>%
rename("vocab_month" = "n") %>%
mutate(vocab_agg = cumsum(vocab_month))
# need to start with full list of all words by age, global_network$gloss1
ages <- global_distance_providence %>% filter(data_type == "target") %>% distinct(Speaker, gloss1, age)
AOP_summ_actual <- globalthresholds_AOP_providence %>%
mutate(Speaker_AOP = paste(Speaker, AOP, sep="_"),
AOP = as.numeric((AOP))) %>%
filter(data_type == "actual")
AOP_summ_target <- globalthresholds_AOP_providence %>%
mutate(Speaker_AOP = paste(Speaker, AOP, sep="_"),
AOP = as.numeric((AOP))) %>%
filter(data_type == "target")
AOP_summ <- rbind(AOP_summ_actual, AOP_summ_target) %>% distinct(Speaker, gloss1, .keep_all = T)
mean_degree_full_target <- feather::read_feather("Data/mean_degree_full_target_providence.feather")
mean_degree_full_actual <- feather::read_feather("Data/mean_degree_full_actual_providence.feather")
global_network <- globalthresholds_AOP_providence %>%
rename("PAQ_val" = "degree") %>%
dplyr::select(-age, -threshold)
mean_degree_full <- rbind(mean_degree_full_actual, mean_degree_full_target)
comparison_data <- read_csv("Data/comparison_data_providence.csv") %>%
distinct(Gloss, Speaker, .keep_all=T) %>%
dplyr::select(Gloss, Speaker, Targetphon, nsyl_target) %>%
rename("gloss1" = "Gloss")
global_network_split <- global_network %>%
pivot_wider(names_from = data_type, values_from = PAQ_val) %>%
rename("PAQ_target" = "target",
"PAQ_actual" = "actual")
regression_data <- mean_degree_full %>% left_join(global_network_split) %>%
group_by(Speaker, gloss1, data_type) %>%
mutate(learned_next = ifelse(age == AOP-1, 1, 0)) %>%
filter(age != AOP) %>%
left_join(comparison_data) %>%
left_join(vocabsize_sub) %>%
ungroup() %>%
mutate(AOP_scaled = c(scale(AOP, center = TRUE, scale = TRUE)),
length_scaled = c(scale(Targetphon, center = TRUE, scale = TRUE))) %>%
#PAT_weighted = PAT_val/vocab_month) %>%
group_by(Speaker) %>%
mutate(PAT_scaled = c(scale(PAT_val, center = TRUE, scale = TRUE)),
PAT_scaled_m = c(scale(PAT_val_m, center = TRUE, scale = TRUE)),
PAQ_scaled_target = c(scale(PAQ_target, center = TRUE, scale = TRUE)),
PAQ_scaled_actual = c(scale(PAQ_actual, center = TRUE, scale = TRUE)))
vocabsize_sub <- vocabsize_providence %>% distinct(Speaker, AOP, vocab_month)
regression_data <- mean_degree_full %>% left_join(global_network_split) %>%
group_by(Speaker, gloss1, data_type) %>%
mutate(learned_next = ifelse(age == AOP-1, 1, 0)) %>%
filter(age != AOP) %>%
left_join(comparison_data) %>%
left_join(vocabsize_sub) %>%
ungroup() %>%
mutate(AOP_scaled = c(scale(AOP, center = TRUE, scale = TRUE)),
length_scaled = c(scale(Targetphon, center = TRUE, scale = TRUE))) %>%
#PAT_weighted = PAT_val/vocab_month) %>%
group_by(Speaker) %>%
mutate(PAT_scaled = c(scale(PAT_val, center = TRUE, scale = TRUE)),
PAT_scaled_m = c(scale(PAT_val_m, center = TRUE, scale = TRUE)),
PAQ_scaled_target = c(scale(PAQ_target, center = TRUE, scale = TRUE)),
PAQ_scaled_actual = c(scale(PAQ_actual, center = TRUE, scale = TRUE)))
View(regression_data)
regression_data <- mean_degree_full %>% left_join(global_network_split) %>%
group_by(Speaker, gloss1, data_type) %>%
mutate(learned_next = ifelse(age == AOP-1, 1, 0)) %>%
filter(age != AOP) %>%
left_join(comparison_data)
regression_data <- mean_degree_full %>% left_join(global_network_split) %>%
group_by(Speaker, gloss1, data_type) %>%
mutate(learned_next = ifelse(age == AOP-1, 1, 0)) %>%
filter(age != AOP) %>%
left_join(comparison_data) %>%
left_join(vocabsize_sub) %>%
ungroup() %>%
mutate(AOP_scaled = c(scale(AOP, center = TRUE, scale = TRUE)),
length_scaled = c(scale(Targetphon, center = TRUE, scale = TRUE))) %>%
#PAT_weighted = PAT_val/vocab_month) %>%
group_by(Speaker) %>%
mutate(PAT_scaled = c(scale(PAT_val, center = TRUE, scale = TRUE)),
PAT_scaled_m = c(scale(PAT_val_m, center = TRUE, scale = TRUE)),
PAQ_scaled_target = c(scale(PAQ_target, center = TRUE, scale = TRUE)),
PAQ_scaled_actual = c(scale(PAQ_actual, center = TRUE, scale = TRUE)))
chi_freq <- read_csv("Data/freq_providence.csv")
session_data <- comparison_data %>% group_by(Speaker, age) %>%
tally() %>%
filter(n > 1) %>%
dplyr::select(Speaker, age) %>%
group_by(Speaker, age) %>%
tally() %>%
mutate(session_ordinal = row_number()) %>%
dplyr::select(-n)
View(comparison_data)
comparison_data <- read_csv("Data/comparison_data_providence.csv") %>%
distinct(Gloss, Speaker, .keep_all=T) %>%
dplyr::select(Gloss, Speaker, Targetphon, age, nsyl_target) %>%
rename("gloss1" = "Gloss")
regression_data <- mean_degree_full %>% left_join(global_network_split) %>%
group_by(Speaker, gloss1, data_type) %>%
mutate(learned_next = ifelse(age == AOP-1, 1, 0)) %>%
filter(age != AOP) %>%
left_join(comparison_data)
comparison_data <- read_csv("Data/comparison_data_providence.csv") %>%
distinct(Gloss, Speaker, .keep_all=T) %>%
dplyr::select(Gloss, Speaker, Targetphon, nsyl_target) %>%
rename("gloss1" = "Gloss")
regression_data <- mean_degree_full %>% left_join(global_network_split) %>%
group_by(Speaker, gloss1, data_type) %>%
mutate(learned_next = ifelse(age == AOP-1, 1, 0)) %>%
filter(age != AOP) %>%
left_join(comparison_data) %>%
left_join(vocabsize_sub) %>%
ungroup() %>%
mutate(AOP_scaled = c(scale(AOP, center = TRUE, scale = TRUE)),
length_scaled = c(scale(Targetphon, center = TRUE, scale = TRUE))) %>%
#PAT_weighted = PAT_val/vocab_month) %>%
group_by(Speaker) %>%
mutate(PAT_scaled = c(scale(PAT_val, center = TRUE, scale = TRUE)),
PAT_scaled_m = c(scale(PAT_val_m, center = TRUE, scale = TRUE)),
PAQ_scaled_target = c(scale(PAQ_target, center = TRUE, scale = TRUE)),
PAQ_scaled_actual = c(scale(PAQ_actual, center = TRUE, scale = TRUE)))
chi_freq <- read_csv("Data/freq_providence.csv")
session_data <- read_csv("Data/comparison_data_providence.csv") %>%    # need to add ordinal session numbers for GAMMs
group_by(Speaker, age) %>%
tally() %>%
filter(n > 1) %>%
dplyr::select(Speaker, age) %>%
group_by(Speaker, age) %>%
tally() %>%
mutate(session_ordinal = row_number()) %>%
dplyr::select(-n)
View(session_data)
FULLsample_var <- feather::read_feather("Data/FULLsample_Providence.feather") %>%
group_by(Speaker, Gloss) %>%
tally() %>%
rename("gloss1" = "Gloss",
"n_tokens" = "n")   # how many tokens of each word included in the data
regression_data <- regression_data %>%
left_join(chi_freq) %>%
left_join(FULLsample_var)
regression_data <- mean_degree_full %>% left_join(global_network_split) %>%
group_by(Speaker, gloss1, data_type) %>%
mutate(learned_next = ifelse(age == AOP-1, 1, 0)) %>%
filter(age != AOP) %>%
left_join(comparison_data) %>%
left_join(vocabsize_sub) %>%
ungroup() %>%
mutate(AOP_scaled = c(scale(AOP, center = TRUE, scale = TRUE)),
length_scaled = c(scale(Targetphon, center = TRUE, scale = TRUE))) %>%
#PAT_weighted = PAT_val/vocab_month) %>%
group_by(Speaker) %>%
mutate(PAT_scaled = c(scale(PAT_val, center = TRUE, scale = TRUE)),
PAT_scaled_m = c(scale(PAT_val_m, center = TRUE, scale = TRUE)),
PAQ_scaled_target = c(scale(PAQ_target, center = TRUE, scale = TRUE)),
PAQ_scaled_actual = c(scale(PAQ_actual, center = TRUE, scale = TRUE)))
chi_freq <- read_csv("Data/freq_providence.csv")
session_data <- read_csv("Data/comparison_data_providence.csv") %>%    # need to add ordinal session numbers for GAMMs
group_by(Speaker, age) %>%
tally() %>%
filter(n > 1) %>%
dplyr::select(Speaker, age) %>%
group_by(Speaker, age) %>%
tally() %>%
mutate(session_ordinal = row_number()) %>%
dplyr::select(-n)
FULLsample_var <- feather::read_feather("Data/FULLsample_Providence.feather") %>%
group_by(Speaker, Gloss) %>%
tally() %>%
rename("gloss1" = "Gloss",
"n_tokens" = "n")   # how many tokens of each word included in the data
regression_data <- regression_data %>%
left_join(chi_freq) %>%
left_join(FULLsample_var) %>%
left_join(session_data) %>%
mutate(total_freq = ifelse(is.na(total_freq), 0, total_freq)) %>%
mutate(freq_scaled = c(scale(total_freq, center = TRUE, scale = TRUE)),
vocab_scaled = c(scale(vocab_month, center = TRUE, scale = TRUE)),
tokens_scaled = c(scale(n_tokens, center = TRUE, scale = TRUE))) %>%
mutate(corpus = "Providence",
age_scaled = c(scale(age, center = T, scale = T)))
View(regression_data)
feather::write_feather(regression_data, "Data/regression_data_providence.feather")
# need to start with full list of all words by age, global_network$gloss1
global_distance_lyon <- feather::read_feather("Data/globaldistance_lyon.feather")
globalthresholds_lyon <- feather::read_feather("Data/globalthresholds_lyon.feather")
globalthresholds_AOP_lyon <- feather::read_feather("Data/globalthresholds_AOP_lyon.feather") %>%
filter(threshold == 0.25)
vocabsize_lyon <- feather::read_feather("Data/globalthresholds_AOP_lyon.feather") %>%
filter(threshold == 0.99, data_type == "target") %>%  # use 0.99 as threshold to make sure all new words are incorporated.
#filter(age == 30) %>%
group_by(Speaker, AOP) %>%
tally() %>%
rename("vocab_month" = "n") %>%
mutate(vocab_agg = cumsum(vocab_month))
ages <- global_distance_lyon %>% filter(data_type == "target") %>% distinct(Speaker, gloss1, age)
AOP_summ_actual <- globalthresholds_AOP_lyon %>%
mutate(Speaker_AOP = paste(Speaker, AOP, sep="_"),
AOP = as.numeric((AOP))) %>%
filter(data_type == "actual")
AOP_summ_target <- globalthresholds_AOP_lyon %>%
mutate(Speaker_AOP = paste(Speaker, AOP, sep="_"),
AOP = as.numeric((AOP))) %>%
filter(data_type == "target")
AOP_summ <- rbind(AOP_summ_actual, AOP_summ_target) %>% distinct(Speaker, gloss1, .keep_all = T)
vocabsize_sub <- vocabsize_lyon %>% distinct(Speaker, AOP, vocab_month)
mean_degree_full_target <- feather::read_feather("Data/mean_degree_full_target_lyon.feather")
mean_degree_full_actual <- feather::read_feather("Data/mean_degree_full_actual_lyon.feather")
global_network <- globalthresholds_AOP_lyon %>%
rename("PAQ_val" = "degree") %>%
dplyr::select(-age, -threshold)
mean_degree_full <- rbind(mean_degree_full_actual, mean_degree_full_target)
comparison_data <- read_csv("Data/comparison_data_lyon.csv") %>%
distinct(Gloss, Speaker, .keep_all=T) %>%
dplyr::select(Gloss, Speaker, Targetphon, nsyl_target) %>%
rename("gloss1" = "Gloss")
global_network_split <- global_network %>%
pivot_wider(names_from = data_type, values_from = PAQ_val) %>%
rename("PAQ_target" = "target",
"PAQ_actual" = "actual")
regression_data <- mean_degree_full %>% left_join(global_network_split) %>%
group_by(Speaker, gloss1, data_type) %>%
mutate(learned_next = ifelse(age == AOP-1, 1, 0)) %>%
filter(age != AOP) %>%
left_join(comparison_data) %>%
left_join(vocabsize_sub) %>%
ungroup() %>%
mutate(AOP_scaled = c(scale(AOP, center = TRUE, scale = TRUE)),
length_scaled = c(scale(Targetphon, center = TRUE, scale = TRUE))) %>%
#PAT_weighted = PAT_val/vocab_month) %>%
group_by(Speaker) %>%
mutate(PAT_scaled = c(scale(PAT_val, center = TRUE, scale = TRUE)),
PAT_scaled_m = c(scale(PAT_val_m, center = TRUE, scale = TRUE)),
PAQ_scaled_target = c(scale(PAQ_target, center = TRUE, scale = TRUE)),
PAQ_scaled_actual = c(scale(PAQ_actual, center = TRUE, scale = TRUE)))
session_data <- read_csv("Data/comparison_data_lyon.csv") %>%    # need to add ordinal session numbers for GAMMs
group_by(Speaker, age) %>%
tally() %>%
filter(n > 1) %>%
dplyr::select(Speaker, age) %>%
group_by(Speaker, age) %>%
tally() %>%
mutate(session_ordinal = row_number()) %>%
dplyr::select(-n)
freq_lyon <- read_csv("Data/freq_lyon.csv")
FULLsample_var <- feather::read_feather("Data/FULLsample_Lyon.feather") %>%
group_by(Speaker, Gloss) %>%
tally() %>%
rename("gloss1" = "Gloss",
"n_tokens" = "n",)   # how many tokens of each word included in the data
regression_data <- regression_data %>%
left_join(freq_lyon) %>%
left_join(FULLsample_var) %>%
left_join(session_data) %>%
mutate(total_freq = ifelse(is.na(total_freq), 0, total_freq)) %>%
mutate(freq_scaled = c(scale(total_freq, center = TRUE, scale = TRUE)),
vocab_scaled = c(scale(vocab_month, center = TRUE, scale = TRUE)),
tokens_scaled = c(scale(n_tokens, center = TRUE, scale = TRUE))) %>%
mutate(corpus = "Lyon",
age_scaled = c(scale(age, center = T, scale = T)))
feather::write_feather(regression_data, "Data/regression_data_lyon.feather")
