fill(Speaker, .direction = "up") %>%
fill(threshold, .direction = "down") %>%
fill(threshold, .direction = "up")
missing_list <- list(mean_degree_full_actual_missing)
})
mean_degree_full_actual <- bind_rows(missing_checks_actual) %>%
left_join(AOP_summ_red) %>%
dplyr::select(-remove) %>%
mutate(data_type = "actual") %>%
filter(age <= AOP)
feather::write_feather(mean_degree_full_actual, "Data/mean_degree_full_actual_lyon_thresholdstest.feather")
missing_checks_target <-lapply(speaker_threshold_list, FUN = function(element) {
mean_degree_full_target_missing <- mean_degree_full_target_init %>%
filter(Speaker %in% element$Speaker & threshold %in% element$threshold) %>%                                                         # for each speaker
complete(gloss1,
age = (min_ages$min_age[which(min_ages$Speaker %in% element$Speaker)]):         # that don't have an initial timepoint at
(AOP_summ$AOP[which(AOP_summ$Speaker %in% element$Speaker & AOP_summ$gloss1 %in% gloss1)])) %>%         # the child's minimum age, and complete the gaps
mutate(remove = ifelse(!(age %in% AOP_summ$AOP[which(AOP_summ$Speaker %in% element$Speaker)]), T, F)) %>% # remove ages that don't have recordings
filter(remove != T) %>%
ungroup() %>%
mutate(INT_val = ifelse(is.na(INT_val), 0, INT_val),                            # create PAT vals for these missing data points
INT_val_m = ifelse(is.na(INT_val_m), 0, INT_val_m)) %>%                  # these are 0 by default as they don't connect to anything
fill(Speaker, .direction = "down") %>%                                          # fill in the Speaker info
fill(age, .direction = "up") %>%                                          # fill in the Speaker info
fill(Speaker, .direction = "up") %>%
fill(threshold, .direction = "down") %>%
fill(threshold, .direction = "up")
missing_list <- list(mean_degree_full_target_missing)
})
mean_degree_full_target <- bind_rows(missing_checks_target) %>%
left_join(AOP_summ_red) %>%
dplyr::select(-remove) %>%
mutate(data_type = "target") %>%
filter(age <= AOP)
feather::write_feather(mean_degree_full_target, "Data/mean_degree_full_target_lyon_thresholdstest.feather")
#mean_degree_full_target <- feather::read_feather("Data/mean_degree_full_target_lyon.feather")
#mean_degree_full_actual <- feather::read_feather("Data/mean_degree_full_actual_lyon.feather")
global_network <- globalthresholds_AOP_lyon %>%
rename("EXT_val" = "degree") %>%
dplyr::select(-age)
mean_degree_full <- rbind(mean_degree_full_actual, mean_degree_full_target)
comparison_data <- read_csv("Data/comparison_data_lyon.csv") %>%
distinct(Gloss, Speaker, .keep_all=T) %>%
dplyr::select(Gloss, Speaker, Targetphon, nsyl_target) %>%
rename("gloss1" = "Gloss")
global_network_split <- global_network %>%
pivot_wider(names_from = data_type, values_from = EXT_val) %>%
rename("EXT_target" = "target",
"EXT_actual" = "actual")
# global_network_split %>% filter(is.na(PAQ_target))   # in some cases there are words which don't have connections in the target/actual data
# these are shown as NA in the df, only 7 datapoints
regression_data_thresholdstest <- mean_degree_full %>% left_join(global_network_split) %>%
group_by(Speaker, gloss1, data_type, threshold) %>%
mutate(learned_next = ifelse(age == AOP-1, 1, 0)) %>%
filter(age != AOP) %>%
left_join(comparison_data) %>%
left_join(vocabsize_lyon) %>%
ungroup() %>%
mutate(AOP_scaled = c(scale(AOP, center = TRUE, scale = TRUE)),
length_scaled = c(scale(Targetphon, center = TRUE, scale = TRUE))) %>%
group_by(Speaker) %>%
mutate(INT_scaled = c(scale(INT_val, center = TRUE, scale = TRUE)),
INT_scaled_m = c(scale(INT_val_m, center = TRUE, scale = TRUE)),
EXT_scaled_target = c(scale(EXT_target, center = TRUE, scale = TRUE)),
EXT_scaled_actual = c(scale(EXT_actual, center = TRUE, scale = TRUE)))
aoa_comp <- read_csv("additional_files/wordbank_item_data_comp_eng.csv") %>%
select(-downloaded, -item_id) %>%
pivot_longer(cols = `8`:`18`, names_to = "age", values_to = "prop") %>%
filter(prop >= .5) %>%
group_by(item_definition) %>% # for homophones, pick the earliest-acquired version
filter(age == min(age)) %>%
rename(gloss1 = item_definition,
aoa_comp = age) %>%
select(-prop, -category)
input_freq <- read_csv("additional_files/childes_english.csv") %>%
mutate(gloss1 = tolower(word)) %>%
select(gloss1, word_count) %>%
group_by(gloss1) %>%
filter(word_count == max(word_count))
# chi_freq <- read_csv("Data/freq_lyon.csv")
# chi_freq_bychi <- read_csv("Data/chi_freq_bychi.csv")
# chi_freq_byword <- read_csv("Data/chi_freq_byword.csv")
session_data <- read_csv("Data/comparison_data_lyon.csv") %>%    # need to add ordinal session numbers for GAMMs
group_by(Speaker, age) %>%
tally() %>%
filter(n > 1) %>%
dplyr::select(Speaker, age) %>%
group_by(Speaker, age) %>%
tally() %>%
mutate(session_ordinal = row_number()) %>%
dplyr::select(-n)
word_cat <- feather::read_feather("Data/FULLsample_lyon.feather") %>%
distinct(Gloss, .keep_all = T) %>%
dplyr::select(Gloss, category) %>%
rename("gloss1" = "Gloss") %>%
mutate(category = as.factor(category),
category = fct_collapse(category,
object_word = c("animals", "body_parts", "clothing", "food_drink", "furniture_rooms",
"household", "people", "outside", "places", "toys", "vehicles"),
verbs = c("action_words", "helping_verbs")))
FULLsample_var <- feather::read_feather("Data/FULLsample_lyon.feather") %>%
group_by(Speaker, Gloss) %>%
tally() %>%
rename("gloss1" = "Gloss",
"n_tokens" = "n")   # how many tokens of each word included in the data
regression_data_thresholdstest <- regression_data_thresholdstest %>%
left_join(input_freq, by = "gloss1") %>%
left_join(word_cat) %>%
left_join(aoa_comp, by = "gloss1") %>%
left_join(FULLsample_var) %>%
left_join(session_data) %>%
mutate(aoa_comp = as.numeric(aoa_comp),
freq_scaled = c(scale(word_count, center = TRUE, scale = TRUE)),
vocab_scaled = c(scale(vocab_agg, center = TRUE, scale = TRUE)),
tokens_scaled = c(scale(n_tokens, center = TRUE, scale = TRUE)),
aoa_scaled = c(scale(aoa_comp, center= TRUE, scale = TRUE))) %>%
mutate(corpus = "English",
age_scaled = c(scale(age, center = T, scale = T)),
category = as.factor(category),
data_type = as.factor(data_type),
Speaker = as.factor(Speaker),
corpus = as.factor(corpus))
regression_data_thresholdstest$category = relevel(regression_data_thresholdstest$category, ref="object_word")
feather::write_feather(regression_data_thresholdstest, "Data/regression_data_lyon_thresholdstest.feather")
global_network <- globalthresholds_AOP_lyon %>%
rename("EXT_val" = "degree") %>%
dplyr::select(-age)
mean_degree_full <- rbind(mean_degree_full_actual, mean_degree_full_target)
comparison_data <- read_csv("Data/comparison_data_lyon.csv") %>%
distinct(Gloss, Speaker, .keep_all=T) %>%
dplyr::select(Gloss, Speaker, Targetphon, nsyl_target) %>%
rename("gloss1" = "Gloss")
global_network_split <- global_network %>%
pivot_wider(names_from = data_type, values_from = EXT_val) %>%
rename("EXT_target" = "target",
"EXT_actual" = "actual")
regression_data_thresholdstest <- mean_degree_full %>% left_join(global_network_split) %>%
group_by(Speaker, gloss1, data_type, threshold) %>%
mutate(learned_next = ifelse(age == AOP-1, 1, 0)) %>%
filter(age != AOP) %>%
left_join(comparison_data) %>%
left_join(vocabsize_lyon) %>%
ungroup() %>%
mutate(AOP_scaled = c(scale(AOP, center = TRUE, scale = TRUE)),
length_scaled = c(scale(Targetphon, center = TRUE, scale = TRUE))) %>%
group_by(Speaker) %>%
mutate(INT_scaled = c(scale(INT_val, center = TRUE, scale = TRUE)),
INT_scaled_m = c(scale(INT_val_m, center = TRUE, scale = TRUE)),
EXT_scaled_target = c(scale(EXT_target, center = TRUE, scale = TRUE)),
EXT_scaled_actual = c(scale(EXT_actual, center = TRUE, scale = TRUE)))
aoa_comp <- read_csv("additional_files/wordbank_item_data_comp_fr.csv") %>%
select(-downloaded, -item_id) %>%
pivot_longer(cols = `8`:`18`, names_to = "age", values_to = "prop") %>%
filter(prop >= .5) %>%
group_by(item_definition) %>% # for homophones, pick the earliest-acquired version
filter(age == min(age)) %>%
rename(gloss1 = item_definition,
aoa_comp = age) %>%
select(-prop, -category)
aoa_comp <- read_csv("additional_files/wordbank_item_data_comp_fr.csv") %>%
select(-downloaded, -item_id) %>%
pivot_longer(cols = `8`:`16`, names_to = "age", values_to = "prop") %>%
filter(prop >= .5) %>%
group_by(item_definition) %>% # for homophones, pick the earliest-acquired version
filter(age == min(age)) %>%
rename(gloss1 = item_definition,
aoa_comp = age) %>%
select(-prop, -category) %>%
mutate(gloss1 = str_trim(gloss1)) %>%
distinct(gloss1, .keep_all = T) # parc and poisson occur twice with the same
input_freq <- read_csv("additional_files/childes_french.csv") %>%
mutate(gloss1 = tolower(word)) %>%
select(gloss1, word_count) %>%
group_by(gloss1) %>%
filter(word_count == max(word_count))
session_data <- read_csv("Data/comparison_data_lyon.csv") %>%    # need to add ordinal session numbers for GAMMs
group_by(Speaker, age) %>%
tally() %>%
filter(n > 1) %>%
dplyr::select(Speaker, age) %>%
group_by(Speaker, age) %>%
tally() %>%
mutate(session_ordinal = row_number()) %>%
dplyr::select(-n)
word_cat <- feather::read_feather("Data/FULLsample_lyon.feather") %>%
distinct(Gloss, .keep_all = T) %>%
dplyr::select(Gloss, category) %>%
rename("gloss1" = "Gloss") %>%
mutate(category = as.factor(category),
category = fct_collapse(category,
object_word = c("animals", "body_parts", "clothing", "food_drink", "furniture_rooms",
"household", "people", "outside", "places", "toys", "vehicles"),
verbs = c("action_words", "helping_verbs")))
FULLsample_var <- feather::read_feather("Data/FULLsample_lyon.feather") %>%
group_by(Speaker, Gloss) %>%
tally() %>%
rename("gloss1" = "Gloss",
"n_tokens" = "n")   # how many tokens of each word included in the data
regression_data_thresholdstest <- regression_data_thresholdstest %>%
left_join(input_freq, by = "gloss1") %>%
left_join(word_cat) %>%
left_join(aoa_comp, by = "gloss1") %>%
left_join(FULLsample_var) %>%
left_join(session_data) %>%
mutate(aoa_comp = as.numeric(aoa_comp),
freq_scaled = c(scale(word_count, center = TRUE, scale = TRUE)),
vocab_scaled = c(scale(vocab_agg, center = TRUE, scale = TRUE)),
tokens_scaled = c(scale(n_tokens, center = TRUE, scale = TRUE)),
aoa_scaled = c(scale(aoa_comp, center= TRUE, scale = TRUE))) %>%
mutate(corpus = "French",
age_scaled = c(scale(age, center = T, scale = T)),
category = as.factor(category),
data_type = as.factor(data_type),
Speaker = as.factor(Speaker),
corpus = as.factor(corpus))
regression_data_thresholdstest$category = relevel(regression_data_thresholdstest$category, ref="object_word")
feather::write_feather(regression_data_thresholdstest, "Data/regression_data_lyon_thresholdstest.feather")
filter(globaldistance_lyon_actual, distance_norm < t) %>%
group_by(Speaker, age, gloss1) %>%                     # for gloss1 side of the data, otherwise 50% of data is missed (oops)
tally()
# Updated 30th April 2021
# This script prepares the data for analysis from each of the global distance matrices
# It calculates the degree for each word pair across a set of thresholds from E=0.1-1 in relation to age, vocab size, and age of production (global network)
# It then runs correlations between degree and AOP
globaldistance_lyon_actual <- feather::read_feather("Data/globaldistance_Lyon.feather") %>%
filter(data_type == "actual")
################################## INITIAL THRESHOLD DATASET: ACTUAL FORMS ###########################
# Create a new dataframe to show degree of connectivity for a range of thresholds between 0 and 1, as per Amatuni & Bergelson, 2017
thresholds <- seq(from = 0, to = 1, by = 0.01)  # create empty list
names(thresholds) <- paste("threshold", thresholds, sep ="_") # name list object
globaldistance_list_lyon_actual <- lapply(thresholds, function(t) {
filter(globaldistance_lyon_actual, distance_norm < t) %>%
group_by(Speaker, age, gloss1) %>%                     # for gloss1 side of the data, otherwise 50% of data is missed (oops)
tally()
})
globaldistance_list_lyon_actual_melted <- melt(globaldistance_list_lyon_actual)
globaldistance_list_lyon_actual_degree <- globaldistance_list_lyon_actual_melted %>%
rename("degree" = "value") %>%
separate(L1, into = c("remove", "threshold"), sep = "_") %>%
filter(threshold == 0.25) %>%
dplyr::select(-remove, -threshold, -variable)
feather::write_feather(globaldistance_list_lyon_actual_degree, "Data/actual_globaldistance_list_degree_lyon.feather")
#globaldistance_list_lyon_actual_degree %>% filter(Speaker == "Alex" & age == 16) %>% distinct(gloss1)
actual_globalthresholds_base_lyon <- globaldistance_list_lyon_actual_melted %>%
rename("degree" = "value") %>%
separate(L1, c("l1", "threshold"), sep = "_") %>%
dplyr::select(-l1, -variable) %>%
mutate(data_type = "actual")
#data_summ_Lyon <- feather::read_feather("Data/large_files/data_summ_Lyon.feather")
# Now figure out AOP (age of production) data
# first_instance <- data_summ_Lyon %>%
#   group_by(Speaker, Gloss) %>%
#   filter(age == min(age)) %>%
#   slice(1) %>% # takes the first occurrence if there is a tie
#   ungroup()
#
# first_instance_base <- first_instance %>%    # first instance of each word in the data
#   select(Speaker, age, Gloss) %>%
#   rename("gloss1" = "Gloss",
#          "AOP" = "age")
#
# feather::write_feather(first_instance_base, "Data/first_instance_base_Lyon.feather")
first_instance_base_Lyon <- read_csv("Data/first_instance_Lyon.csv")
actual_globalthresholds_l <- actual_globalthresholds_base_lyon %>%
left_join(first_instance_base_Lyon) %>%
distinct(Speaker, AOP, gloss1, threshold, .keep_all = TRUE)
actual_globalthresholds_lyon <- actual_globalthresholds_base_lyon %>%
left_join(first_instance_base_Lyon)
actual_globalthresholds_AOP_lyon <- actual_globalthresholds_base_lyon %>%
left_join(first_instance_base_Lyon)  %>%
group_by(Speaker) %>%
filter(age == max(age))
##### ACTUAL GLOBAL NETWORK: degree ~ AOP correlations across thresholds ########
threshold_names <- seq(0.01, 1, by = 0.01)
thresholds_corr <- vector("list", length(101)) #Prep a list to store your corr.test results
names <- names(threshold_names)
counter = 0 # To store your corr.test into list through iterating
for (i in unique(actual_globalthresholds_AOP_lyon$threshold)){
counter = counter + 1
# Creating new variables makes the code clearer
x = as.numeric(actual_globalthresholds_AOP_lyon[actual_globalthresholds_AOP_lyon$threshold == i,]$degree)
y = as.numeric(actual_globalthresholds_AOP_lyon[actual_globalthresholds_AOP_lyon$threshold == i,]$AOP)
thresholds_corr[[counter]] <-cor.test(x,y,method="spearman")
}
actual_globalthresholds_corr <- setNames(thresholds_corr, paste0("threshold", threshold_names))
actual_globalthresholds_corr_df <- data.frame(t(sapply(actual_globalthresholds_corr,c)))
actual_globalthresholds_corr_df <- actual_globalthresholds_corr_df %>%
tibble::rownames_to_column(var = "threshold")
actual_globalthresholds_corr_df$threshold <-gsub("[a-zA-Z]", "", actual_globalthresholds_corr_df$threshold)
actual_globalthresholds_corr_df$estimate <-gsub("[c(rho = )]", "", actual_globalthresholds_corr_df$estimate)
actual_globalthresholds_corr_df$threshold <-as.numeric(actual_globalthresholds_corr_df$threshold)
actual_globalthresholds_corr_df$estimate <-as.numeric(actual_globalthresholds_corr_df$estimate)
actual_globalthresholds_corr_df$p.value <-as.numeric(actual_globalthresholds_corr_df$p.value)
actual_globalthresholds_corr_df$p.value <- format(round(actual_globalthresholds_corr_df$p.value, 2), nsmall = 2)
actual_globalthresholds_corr_df$estimate <- format(round(actual_globalthresholds_corr_df$estimate, 3), nsmall = 2)
actual_globalthresholds_corr_df <- actual_globalthresholds_corr_df %>% dplyr::select(threshold, p.value, estimate)
ggplot(actual_globalthresholds_corr_df, aes(x = threshold, y = as.numeric(estimate))) +
geom_point() +
#ylim(0, 1) +
theme_bw()
actual_globalthresholds_corr_df <-actual_globalthresholds_corr_df %>%
mutate(data_type = "actual")
################################## INITIAL THRESHOLD DATASET: TARGET FORMS ###########################
# Do all the same again for Target forms
globaldistance_lyon_target <- feather::read_feather("Data/globaldistance_lyon.feather") %>% filter(data_type == "target")
thresholds <- seq(from = 0, to = 1, by = 0.01)  # create empty list
names(thresholds) <- paste("threshold", thresholds, sep ="_") # name list object
target_globaldistance_lyon_list <- lapply(thresholds, function(t) {
filter(globaldistance_lyon_target, distance_norm < t) %>%
group_by(Speaker, age, gloss1) %>%                     # for gloss1 side of the data, otherwise 50% of data is missed (oops)
tally()
})
target_globaldistance_lyon_list_melted <- melt(target_globaldistance_lyon_list)
#target_globaldistance_lyon_list_melted %>% filter(Speaker == "Alex" & age == 17) %>% distinct(gloss1)
target_globalthresholds_lyon_base <- target_globaldistance_lyon_list_melted %>%
rename("degree" = "value") %>%
separate(L1, c("l1", "threshold"), sep = "_") %>%
dplyr::select(-l1, -variable) %>%
mutate(data_type = "target")
target_globalthresholds_l <- target_globalthresholds_lyon_base %>%
left_join(first_instance_base_Lyon) %>%
distinct(Speaker, AOP, gloss1, threshold, .keep_all = TRUE)
target_globalthresholds_lyon <- target_globalthresholds_lyon_base %>%
left_join(first_instance_base_Lyon)
target_globalthresholds_AOP_lyon <- target_globalthresholds_lyon_base %>%
left_join(first_instance_base_Lyon)  %>%
group_by(Speaker) %>%
filter(age == max(age))
##### target GLOBAL NETWORK: degree ~ AOP correlations across thresholds ########
threshold_names <- seq(0.01, 1, by = 0.01)
thresholds_corr <- vector("list", length(101)) #Prep a list to store your corr.test results
names <- names(threshold_names)
counter = 0 # To store your corr.test into list through iterating
for (i in unique(target_globalthresholds_AOP_lyon$threshold)){
counter = counter + 1
# Creating new variables makes the code clearer
x = as.numeric(target_globalthresholds_AOP_lyon[target_globalthresholds_AOP_lyon$threshold == i,]$degree)
y = as.numeric(target_globalthresholds_AOP_lyon[target_globalthresholds_AOP_lyon$threshold == i,]$AOP)
thresholds_corr[[counter]] <-cor.test(x,y,method="spearman")
}
target_globalthresholds_corr <- setNames(thresholds_corr, paste0("threshold", threshold_names))
target_globalthresholds_corr_df <- data.frame(t(sapply(target_globalthresholds_corr,c)))
target_globalthresholds_corr_df <- target_globalthresholds_corr_df %>%
tibble::rownames_to_column(var = "threshold")
target_globalthresholds_corr_df$threshold <-gsub("[a-zA-Z]", "", target_globalthresholds_corr_df$threshold)
target_globalthresholds_corr_df$estimate <-gsub("[c(rho = )]", "", target_globalthresholds_corr_df$estimate)
target_globalthresholds_corr_df$threshold <-as.numeric(target_globalthresholds_corr_df$threshold)
target_globalthresholds_corr_df$estimate <-as.numeric(target_globalthresholds_corr_df$estimate)
target_globalthresholds_corr_df$p.value <-as.numeric(target_globalthresholds_corr_df$p.value)
target_globalthresholds_corr_df$p.value <- format(round(target_globalthresholds_corr_df$p.value, 2), nsmall = 2)
target_globalthresholds_corr_df$estimate <- format(round(target_globalthresholds_corr_df$estimate, 3), nsmall = 2)
target_globalthresholds_corr_df <- target_globalthresholds_corr_df %>% dplyr::select(threshold, p.value, estimate)
ggplot(target_globalthresholds_corr_df, aes(x = threshold, y = as.numeric(estimate))) +
geom_point() +
#ylim(0, 1) +
theme_bw()
target_globalthresholds_corr_df <-target_globalthresholds_corr_df %>%
mutate(data_type = "target")
##################################
globalthresholds_corr_lyon <- rbind(target_globalthresholds_corr_df, actual_globalthresholds_corr_df)
globalthresholds_lyon <- rbind(target_globalthresholds_lyon, actual_globalthresholds_lyon)
globalthresholds_AOP_lyon <- rbind(target_globalthresholds_AOP_lyon, actual_globalthresholds_AOP_lyon) %>%
mutate(corpus = "French")
feather::write_feather(globalthresholds_corr_lyon, "Data/globalthresholds_corr_lyon.feather") # correlation output data
feather::write_feather(globalthresholds_lyon, "Data/globalthresholds_lyon.feather") # all types at all ages, plus AOP data
feather::write_feather(globalthresholds_AOP_lyon, "Data/globalthresholds_AOP_lyon.feather") # AOP for full network, taken at last month of data (30 months)
# Updated 24th February 2023
# This script prepares the data for analysis from each of the global distance matrices
# It calculates the degree for each word pair across a set of thresholds from E=0.1-1 in relation to age, vocab size, and age of production (global network)
# It then runs correlations between degree and AOP
globaldistance_Providence_actual <- feather::read_feather("Data/globaldistance_Providence.feather") %>% filter(data_type == "actual")
################################## INITIAL THRESHOLD DATASET: ACTUAL FORMS ###########################
# Create a new dataframe to show degree of connectivity for a range of thresholds between 0 and 1, as per Amatuni & Bergelson, 2017
thresholds <- seq(from = 0, to = 1, by = 0.01)  # create empty list
names(thresholds) <- paste("threshold", thresholds, sep ="_") # name list object
globaldistance_list_providence_actual <- lapply(thresholds, function(t) {
filter(globaldistance_Providence_actual, distance_norm < t) %>%
group_by(Speaker, age, gloss1) %>%                     # for gloss1 side of the data, otherwise 50% of data is missed (oops)
tally()
})
globaldistance_list_providence_actual_melted <- melt(globaldistance_list_providence_actual)
globaldistance_list_providence_actual_degree <- globaldistance_list_providence_actual_melted %>%
rename("degree" = "value") %>%
separate(L1, into = c("remove", "threshold"), sep = "_") %>%
filter(threshold == 0.25) %>%
dplyr::select(-remove, -threshold, -variable)
#feather::write_feather(globaldistance_list_providence_actual_degree, "Data/actual_globaldistance_list_degree_providence.feather")
#globaldistance_list_providence_actual_degree <- feather::read_feather("Data/actual_globaldistance_list_degree_providence.feather")
#globaldistance_list_providence_actual_degree %>% filter(Speaker == "Alex" & age == 16) %>% distinct(gloss1)
actual_globalthresholds_base_providence <- globaldistance_list_providence_actual_melted %>%
rename("degree" = "value") %>%
separate(L1, c("l1", "threshold"), sep = "_") %>%
dplyr::select(-l1, -variable) %>%
mutate(data_type = "actual",
age = as.numeric(age)) %>%
feather::write_feather("Data/actual_globalthresholds_base_providence.feather")
first_instance_base <- read_csv("Data/first_instance_Providence.csv")
actual_globalthresholds_providence <- actual_globalthresholds_base_providence %>%
filter(threshold == .25) %>%
left_join(first_instance_base)
actual_globalthresholds_AOP_providence <- actual_globalthresholds_base_providence %>%
#filter(threshold == .25) %>%
left_join(first_instance_base)  %>%
group_by(Speaker) %>%
filter(age == max(age))
##### ACTUAL GLOBAL NETWORK: degree ~ AOP correlations across thresholds ########
threshold_names <- seq(0.01, 1, by = 0.01)
thresholds_corr <- vector("list", length(101)) #Prep a list to store your corr.test results
names <- names(threshold_names)
counter = 0 # To store your corr.test into list through iterating
for (i in unique(actual_globalthresholds_AOP_providence$threshold)){
counter = counter + 1
# Creating new variables makes the code clearer
x = as.numeric(actual_globalthresholds_AOP_providence[actual_globalthresholds_AOP_providence$threshold == i,]$degree)
y = as.numeric(actual_globalthresholds_AOP_providence[actual_globalthresholds_AOP_providence$threshold == i,]$AOP)
thresholds_corr[[counter]] <-cor.test(x,y,method="spearman")
}
actual_globalthresholds_corr <- setNames(thresholds_corr, paste0("threshold", threshold_names))
actual_globalthresholds_corr_df <- data.frame(t(sapply(actual_globalthresholds_corr,c)))
actual_globalthresholds_corr_df <- actual_globalthresholds_corr_df %>%
tibble::rownames_to_column(var = "threshold")
actual_globalthresholds_corr_df$threshold <-gsub("[a-zA-Z]", "", actual_globalthresholds_corr_df$threshold)
actual_globalthresholds_corr_df$estimate <-gsub("[c(rho = )]", "", actual_globalthresholds_corr_df$estimate)
actual_globalthresholds_corr_df$threshold <-as.numeric(actual_globalthresholds_corr_df$threshold)
actual_globalthresholds_corr_df$estimate <-as.numeric(actual_globalthresholds_corr_df$estimate)
actual_globalthresholds_corr_df$p.value <-as.numeric(actual_globalthresholds_corr_df$p.value)
actual_globalthresholds_corr_df$p.value <- format(round(actual_globalthresholds_corr_df$p.value, 2), nsmall = 2)
actual_globalthresholds_corr_df$estimate <- format(round(actual_globalthresholds_corr_df$estimate, 3), nsmall = 2)
actual_globalthresholds_corr_df <- actual_globalthresholds_corr_df %>% dplyr::select(threshold, p.value, estimate)
# ggplot(actual_globalthresholds_corr_df, aes(x = threshold, y = as.numeric(estimate))) +
#   geom_point() +
#   #ylim(0, 1) +
#   theme_bw()
actual_globalthresholds_corr_df <-actual_globalthresholds_corr_df %>%
mutate(data_type = "actual")
################################## INITIAL THRESHOLD DATASET: TARGET FORMS ###########################
# Do all the same again for Target forms
globaldistance_Providence_target <- feather::read_feather("Data/globaldistance_Providence.feather") %>% filter(data_type == "target")
thresholds <- seq(from = 0, to = 1, by = 0.01)  # create empty list
names(thresholds) <- paste("threshold", thresholds, sep ="_") # name list object
target_globaldistance_providence_list <- lapply(thresholds, function(t) {
filter(globaldistance_Providence_target, distance_norm < t) %>%
group_by(Speaker, age, gloss1) %>%                     # for gloss1 side of the data, otherwise 50% of data is missed (oops)
tally()
})
target_globaldistance_providence_list_melted <- melt(target_globaldistance_providence_list)
target_globalthresholds_providence_base <- target_globaldistance_providence_list_melted %>%
rename("degree" = "value") %>%
separate(L1, c("l1", "threshold"), sep = "_") %>%
dplyr::select(-l1, -variable) %>%
mutate(data_type = "target",
age = as.numeric(age))
target_globalthresholds_providence <- target_globalthresholds_providence_base %>%
filter(threshold == .25) %>%
left_join(first_instance_base) #%>%
#distinct(Speaker, AOP, gloss1, threshold, .keep_all = TRUE)
target_globalthresholds_AOP_providence <- target_globalthresholds_providence_base %>%
left_join(first_instance_base)  %>%
group_by(Speaker) %>%
filter(age == max(age))
##### target GLOBAL NETWORK: degree ~ AOP correlations across thresholds ########
threshold_names <- seq(0.01, 1, by = 0.01)
thresholds_corr <- vector("list", length(101)) #Prep a list to store your corr.test results
names <- names(threshold_names)
counter = 0 # To store your corr.test into list through iterating
for (i in unique(target_globalthresholds_AOP_providence$threshold)){
counter = counter + 1
# Creating new variables makes the code clearer
x = as.numeric(target_globalthresholds_AOP_providence[target_globalthresholds_AOP_providence$threshold == i,]$degree)
y = as.numeric(target_globalthresholds_AOP_providence[target_globalthresholds_AOP_providence$threshold == i,]$AOP)
thresholds_corr[[counter]] <-cor.test(x,y,method="spearman")
}
target_globalthresholds_corr <- setNames(thresholds_corr, paste0("threshold", threshold_names))
target_globalthresholds_corr_df <- data.frame(t(sapply(target_globalthresholds_corr,c)))
target_globalthresholds_corr_df <- target_globalthresholds_corr_df %>%
tibble::rownames_to_column(var = "threshold")
target_globalthresholds_corr_df$threshold <-gsub("[a-zA-Z]", "", target_globalthresholds_corr_df$threshold)
target_globalthresholds_corr_df$estimate <-gsub("[c(rho = )]", "", target_globalthresholds_corr_df$estimate)
target_globalthresholds_corr_df$threshold <-as.numeric(target_globalthresholds_corr_df$threshold)
target_globalthresholds_corr_df$estimate <-as.numeric(target_globalthresholds_corr_df$estimate)
target_globalthresholds_corr_df$p.value <-as.numeric(target_globalthresholds_corr_df$p.value)
target_globalthresholds_corr_df$p.value <- format(round(target_globalthresholds_corr_df$p.value, 2), nsmall = 2)
target_globalthresholds_corr_df$estimate <- format(round(target_globalthresholds_corr_df$estimate, 3), nsmall = 2)
target_globalthresholds_corr_df <- target_globalthresholds_corr_df %>% dplyr::select(threshold, p.value, estimate)
ggplot(target_globalthresholds_corr_df, aes(x = threshold, y = as.numeric(estimate))) +
geom_point() +
#ylim(0, 1) +
theme_bw()
target_globalthresholds_corr_df <-target_globalthresholds_corr_df %>%
mutate(data_type = "target")
##################################
globalthresholds_corr_providence <- rbind(target_globalthresholds_corr_df, actual_globalthresholds_corr_df)
globalthresholds_providence <- rbind(target_globalthresholds_providence, actual_globalthresholds_providence)
globalthresholds_AOP_providence <- rbind(target_globalthresholds_AOP_providence, actual_globalthresholds_AOP_providence) %>%
mutate(corpus = "English")
feather::write_feather(globalthresholds_corr_providence, "Data/globalthresholds_corr_providence.feather") # correlation output data
feather::write_feather(globalthresholds_providence, "Data/globalthresholds_providence.feather") # all types at all ages, plus AOP data
feather::write_feather(globalthresholds_AOP_providence, "Data/globalthresholds_AOP_providence.feather") # AOP for full network, taken at last month of data (30 months)
globalthresholds_AOP_lyon <- feather::read_feather("Data/globalthresholds_AOP_lyon.feather") %>%
filter(threshold == 0.25)
globalthresholds_AOP_providence <- feather::read_feather("Data/globalthresholds_AOP_providence.feather") %>%
filter(threshold == 0.25) %>%
mutate(corpus = "English")  ## added to prep data, re-run and then remove in final script (don't remove threshold filter)
globalthresholds_AOP <- rbind(globalthresholds_AOP_lyon, globalthresholds_AOP_providence)
feather::write_feather(globalthresholds_AOP, "Data/repofiles/globalthresholds_AOP.feather")
full_lyon <- feather::read_feather("Data/globalthresholds_AOP_lyon.feather") %>%
filter(threshold == .99)
full_providence <- feather::read_feather("Data/globalthresholds_AOP_providence.feather") %>%
filter(threshold == .99)
full_thresholds <- rbind(full_lyon, full_providence)
feather::write_feather(full_thresholds, "Data/repofiles/full_thresholds.feather")
gc()
