# PhonologicalNetworksPrep - Updated 26th May 2023

This repo includes all the code needed to generate the data for the project in the [link](PhonologicalNetworks) Git repo. As two corpora are used in the project, scripts are run for each of these separately.

These corpora are drawn from [link](Phon):

* Providence (US English); 5 infants (3 females) from Demuth et al, 2006
* Lyon (French); 4 infants (2 females) from Demuth & Tremblay, 2008

To get started, download the two corpora from Phon using the instructions in the script **1_data_cleaning**, and save in a folder called 'Data'. Then run the files in order as per the instructions below.

In case of any issues, please contact [link](catherine.laing@york.ac.uk). 

Scripts saved in the repo are as follows:

**0_prelims**: packages and encoding needed to run the rest of the scripts

**1_data_cleaning**: this script takes all the .csv files generated by Phon and cleans them of any confusing diacritics and fonts (these are language-specific), to create a base dataset. It also joins the Phon data with the language-specific CDI data (downloaded from wordbank, but see *Additional files* below)

**2_distance_scoring**: this script takes every word in the dataset and translates it into a set of numerical values using a distinctive feature matrix. Distances between Actual and Target productions are also calculated, though these are not used in the associated analysis.

**3_matrix_script_globalnetwork**: this script creates a distance matrix for the full dataset (global network) comparing the distance between each word and each other word in each child's data.

**4_thresholds**: this script calculates the degree for each word pair across a set of thresholds from *E*=0.1-1 in relation to age, vocab size, and age of production (global network). It then runs correlations between degree and AOP. This generates a dataset that allows for re-analysis of the data using different connectivity thresholds (in the current paper *E*=0.25).

**5_network_graphs_globalnetwork**: this script generates network graphs using the *igraph()* package, for future analyses using clustering coefficient and path length as variables.

**6_regression_model_prep**: this script prepares the data for the regression models, following analyses by Siew & Vitevitch (2021). It also generates measures used in the GAMMs.

**7_full_data_prep**: this script joins the datasets generated above, ready for analysis.

### Additional files
There are some additional files in the repo, saved in the folder **additional_files**.

**french/english_CDI**: these are dataframes that include all word tokens produced in each dataset, according to whether or not the word is in the CDI (TRUE or FALSE). CDI word category and word class is also included. Note that some words are counted in multiple categories/word classes, but these are collapsed in the main dataset to include only one category.

To generate these datasets:

1. Data was downloaded in raw form from http://wordbank.stanford.edu/.
2. For the French data only, all word types in Fullsample_Lyon$Gloss were translated, first using a script in Google translate, and then checked by the researcher, with any errors or missing datapoints manually translated by the researcher (a French speaker).
3. The list of word types was then manually coded for its 'basic level' form (e.g. "wouf wouf wouf" was coded as "wouf" to match the CDI form).
4. Any word that did not match a a CDI word was coded as blank.

**freq_lyon/providence**: these datasets were generated in Phon using the word frequency function, deriving frequency of each word in each child's own mother's speech.